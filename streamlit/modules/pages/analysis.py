"""
PandasAI Demo Page Module
Contains the PandasAI demo page implementation for the smart meeting system
"""

import streamlit as st
import pandas as pd
import plotly.express as px
from datetime import datetime
import os
import sys

# Add the parent directory to the path to import modules
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Import DashScopeOpenAI for AI-powered analysis
try:
    from modules.llm import DashScopeOpenAI

    DASHSCOPE_AVAILABLE = True
except ImportError:
    DASHSCOPE_AVAILABLE = False
    st.warning("DashScopeOpenAI not available. Using mock analysis.")


class AnalysisPage:
    """PandasAI demo page implementation with enhanced functionality"""

    def __init__(self, data_manager, auth_manager, ui_components):
        self.data_manager = data_manager
        self.auth_manager = auth_manager
        self.ui = ui_components

    def setup_dashscope_llm(self):
        """Setup DashScope LLM for AI analysis"""
        if not DASHSCOPE_AVAILABLE:
            return None

        try:
            api_key = os.getenv("DASHSCOPE_API_KEY")
            if not api_key:
                st.warning(
                    "DASHSCOPE_API_KEY environment variable not set. Using mock analysis."
                )
                return None

            llm = DashScopeOpenAI(api_token=api_key, model="qwen-plus")
            return llm
        except Exception as e:
            st.error(f"Failed to setup DashScope LLM: {e}")
            return None

    def perform_ai_analysis(self, query, sample_data, llm):
        """Perform AI-powered analysis using DashScope"""
        try:
            # Create a context about the data
            data_info = f"""
            æ•°æ®é›†ä¿¡æ¯:
            - è®°å½•æ•°: {len(sample_data)}
            - å­—æ®µæ•°: {len(sample_data.columns)}
            - å­—æ®µåˆ—è¡¨: {', '.join(sample_data.columns.tolist())}
            - æ•°æ®ç±»åž‹: {dict(sample_data.dtypes)}
            """

            # Try to get AI insights using the LLM
            ai_insights = self._get_ai_insights(query, sample_data, llm)

            # Basic analysis based on query keywords
            analysis_result = ""

            if "ç»Ÿè®¡" in query or "æ¦‚è§ˆ" in query or "ç»Ÿè®¡ä¿¡æ¯" in query:
                analysis_result = self._generate_statistical_analysis(sample_data)
            elif "å›¾è¡¨" in query or "å¯è§†åŒ–" in query or "å›¾å½¢" in query:
                analysis_result = self._generate_visualization_analysis(sample_data)
            elif "è¶‹åŠ¿" in query or "å˜åŒ–" in query:
                analysis_result = self._generate_trend_analysis(sample_data)
            elif "åˆ†å¸ƒ" in query:
                analysis_result = self._generate_distribution_analysis(sample_data)
            else:
                analysis_result = self._generate_general_analysis(sample_data, query)

            # Add AI insights if available
            if ai_insights:
                analysis_result += f"\n\n## ðŸ¤– AI æ™ºèƒ½æ´žå¯Ÿ\n\n{ai_insights}"

            return analysis_result

        except Exception as e:
            st.error(f"AI analysis failed: {e}")
            return None

    def _get_ai_insights(self, query, data, llm):
        """Get AI insights using DashScope LLM"""
        try:
            # Prepare data summary for the LLM
            data_summary = self._prepare_data_summary(data)

            # Create a prompt for the LLM
            prompt = f"""
            ä½œä¸ºä¸€ä¸ªæ•°æ®åˆ†æžä¸“å®¶ï¼Œè¯·åˆ†æžä»¥ä¸‹æ•°æ®å¹¶æä¾›æ´žå¯Ÿï¼š

            ç”¨æˆ·æŸ¥è¯¢: {query}
            
            æ•°æ®æ‘˜è¦:
            {data_summary}
            
            è¯·æä¾›ï¼š
            1. æ•°æ®çš„å…³é”®ç‰¹å¾
            2. å¯èƒ½çš„ä¸šåŠ¡æ´žå¯Ÿ
            3. å»ºè®®çš„è¿›ä¸€æ­¥åˆ†æžæ–¹å‘
            
            è¯·ç”¨ä¸­æ–‡å›žç­”ï¼Œç®€æ´æ˜Žäº†ã€‚
            """

            # For now, we'll return a structured analysis
            # In a full implementation, you would call the LLM here
            # response = llm.chat(prompt)

            # Return structured insights based on data characteristics
            return self._generate_structured_insights(data, query)

        except Exception as e:
            st.warning(f"AI insights generation failed: {e}")
            return None

    def _prepare_data_summary(self, data):
        """Prepare a summary of the data for AI analysis"""
        summary = f"""
        - æ•°æ®é›†å¤§å°: {len(data)} è¡Œ x {len(data.columns)} åˆ—
        - å­—æ®µåç§°: {', '.join(data.columns.tolist())}
        """

        # Add data type information
        numeric_cols = data.select_dtypes(include=["number"]).columns
        categorical_cols = data.select_dtypes(include=["object"]).columns

        if len(numeric_cols) > 0:
            summary += f"\n- æ•°å€¼åž‹å­—æ®µ: {', '.join(numeric_cols)}"

        if len(categorical_cols) > 0:
            summary += f"\n- åˆ†ç±»åž‹å­—æ®µ: {', '.join(categorical_cols)}"

        # Add basic statistics for numeric columns
        if len(numeric_cols) > 0:
            stats = data[numeric_cols].describe()
            summary += f"\n- æ•°å€¼å­—æ®µç»Ÿè®¡: å¹³å‡å€¼èŒƒå›´ {stats.loc['mean'].min():.2f} - {stats.loc['mean'].max():.2f}"

        return summary

    def _generate_structured_insights(self, data, query):
        """Generate structured insights based on data characteristics"""
        insights = ""

        # Analyze data patterns
        numeric_cols = data.select_dtypes(include=["number"]).columns
        categorical_cols = data.select_dtypes(include=["object"]).columns

        # Key characteristics
        insights += "### ðŸ” æ•°æ®ç‰¹å¾åˆ†æž\n"
        insights += f"- **æ•°æ®è§„æ¨¡**: ä¸­ç­‰è§„æ¨¡æ•°æ®é›† ({len(data)} æ¡è®°å½•)\n"
        insights += f"- **å­—æ®µå¤šæ ·æ€§**: {len(numeric_cols)} ä¸ªæ•°å€¼å­—æ®µ, {len(categorical_cols)} ä¸ªåˆ†ç±»å­—æ®µ\n"

        # Identify potential insights
        if len(numeric_cols) > 0:
            insights += "\n### ðŸ“Š æ•°å€¼åž‹æ•°æ®æ´žå¯Ÿ\n"
            for col in numeric_cols[:2]:  # Focus on first 2 numeric columns
                stats = data[col].describe()
                insights += f"- **{col}**: å‡å€¼ {stats['mean']:.2f}, æ ‡å‡†å·® {stats['std']:.2f}\n"
                if stats["std"] > stats["mean"] * 0.5:
                    insights += f"  - æ•°æ®å˜å¼‚è¾ƒå¤§ï¼Œå¯èƒ½å­˜åœ¨å¼‚å¸¸å€¼\n"
                else:
                    insights += f"  - æ•°æ®åˆ†å¸ƒç›¸å¯¹é›†ä¸­\n"

        if len(categorical_cols) > 0:
            insights += "\n### ðŸ·ï¸ åˆ†ç±»åž‹æ•°æ®æ´žå¯Ÿ\n"
            for col in categorical_cols[:2]:  # Focus on first 2 categorical columns
                value_counts = data[col].value_counts()
                insights += f"- **{col}**: {len(value_counts)} ä¸ªç±»åˆ«\n"
                insights += f"  - ä¸»è¦ç±»åˆ«: {value_counts.index[0]} ({value_counts.iloc[0]} æ¬¡)\n"
                if len(value_counts) > 5:
                    insights += f"  - ç±»åˆ«è¾ƒå¤šï¼Œå»ºè®®è¿›è¡Œåˆ†ç»„åˆ†æž\n"

        # Business insights
        insights += "\n### ðŸ’¡ ä¸šåŠ¡æ´žå¯Ÿå»ºè®®\n"
        if "ä¼šè®®" in str(data.columns):
            insights += "- å…³æ³¨ä¼šè®®æ—¶é•¿å’Œé¢‘çŽ‡çš„åˆ†å¸ƒæ¨¡å¼\n"
            insights += "- åˆ†æžä¸åŒéƒ¨é—¨çš„ä¼šè®®ä½¿ç”¨æƒ…å†µ\n"
        elif "ä»»åŠ¡" in str(data.columns):
            insights += "- ç›‘æŽ§ä»»åŠ¡å®ŒæˆçŽ‡å’Œä¼˜å…ˆçº§åˆ†å¸ƒ\n"
            insights += "- è¯†åˆ«ä»»åŠ¡å¤„ç†çš„ç“¶é¢ˆçŽ¯èŠ‚\n"
        elif "ç”¨æˆ·" in str(data.columns):
            insights += "- åˆ†æžç”¨æˆ·æ´»è·ƒåº¦å’Œéƒ¨é—¨åˆ†å¸ƒ\n"
            insights += "- å…³æ³¨ç”¨æˆ·è§’è‰²å’Œæƒé™åˆ†é…\n"
        elif "æˆ¿é—´" in str(data.columns):
            insights += "- è¯„ä¼°ä¼šè®®å®¤ä½¿ç”¨æ•ˆçŽ‡å’Œå®¹é‡åˆ†å¸ƒ\n"
            insights += "- ä¼˜åŒ–ä¼šè®®å®¤èµ„æºé…ç½®\n"

        return insights

    def _generate_statistical_analysis(self, data):
        """Generate statistical analysis of the data"""
        analysis = "## ðŸ“Š æ•°æ®ç»Ÿè®¡åˆ†æž\n\n"

        # Basic statistics
        analysis += f"- **æ€»è®°å½•æ•°:** {len(data)}\n"
        analysis += f"- **å­—æ®µæ•°:** {len(data.columns)}\n\n"

        # Numeric columns analysis
        numeric_cols = data.select_dtypes(include=["number"]).columns
        if len(numeric_cols) > 0:
            analysis += "### æ•°å€¼åž‹å­—æ®µç»Ÿè®¡\n"
            stats = data[numeric_cols].describe()
            analysis += f"- æ•°å€¼å­—æ®µ: {', '.join(numeric_cols)}\n"
            analysis += f"- å¹³å‡å€¼èŒƒå›´: {stats.loc['mean'].min():.2f} - {stats.loc['mean'].max():.2f}\n"
            analysis += f"- æ ‡å‡†å·®èŒƒå›´: {stats.loc['std'].min():.2f} - {stats.loc['std'].max():.2f}\n\n"

        # Categorical columns analysis
        categorical_cols = data.select_dtypes(include=["object"]).columns
        if len(categorical_cols) > 0:
            analysis += "### åˆ†ç±»åž‹å­—æ®µç»Ÿè®¡\n"
            for col in categorical_cols[:3]:  # Limit to first 3 columns
                unique_count = data[col].nunique()
                analysis += f"- **{col}:** {unique_count} ä¸ªå”¯ä¸€å€¼\n"

        return analysis

    def _generate_visualization_analysis(self, data):
        """Generate visualization recommendations"""
        analysis = "## ðŸ“ˆ æ•°æ®å¯è§†åŒ–åˆ†æž\n\n"

        # Recommend visualizations based on data types
        numeric_cols = data.select_dtypes(include=["number"]).columns
        categorical_cols = data.select_dtypes(include=["object"]).columns

        if len(numeric_cols) > 0:
            analysis += "### æ•°å€¼åž‹æ•°æ®å¯è§†åŒ–å»ºè®®\n"
            analysis += "- ç›´æ–¹å›¾: æŸ¥çœ‹æ•°å€¼åˆ†å¸ƒ\n"
            analysis += "- ç®±çº¿å›¾: è¯†åˆ«å¼‚å¸¸å€¼\n"
            if len(numeric_cols) >= 2:
                analysis += "- æ•£ç‚¹å›¾: åˆ†æžå˜é‡å…³ç³»\n"

        if len(categorical_cols) > 0:
            analysis += "\n### åˆ†ç±»åž‹æ•°æ®å¯è§†åŒ–å»ºè®®\n"
            analysis += "- æŸ±çŠ¶å›¾: æ˜¾ç¤ºç±»åˆ«é¢‘æ¬¡\n"
            analysis += "- é¥¼å›¾: æ˜¾ç¤ºæ¯”ä¾‹åˆ†å¸ƒ\n"

        return analysis

    def _generate_trend_analysis(self, data):
        """Generate trend analysis"""
        analysis = "## ðŸ“ˆ è¶‹åŠ¿åˆ†æž\n\n"

        # Look for date/time columns
        date_cols = []
        for col in data.columns:
            if (
                "date" in col.lower()
                or "time" in col.lower()
                or "created" in col.lower()
            ):
                date_cols.append(col)

        if date_cols:
            analysis += f"å‘çŽ°æ—¶é—´ç›¸å…³å­—æ®µ: {', '.join(date_cols)}\n"
            analysis += "å»ºè®®è¿›è¡Œæ—¶é—´åºåˆ—åˆ†æž:\n"
            analysis += "- æ—¶é—´è¶‹åŠ¿å›¾\n"
            analysis += "- å‘¨æœŸæ€§åˆ†æž\n"
            analysis += "- å­£èŠ‚æ€§æ¨¡å¼è¯†åˆ«\n"
        else:
            analysis += "æœªå‘çŽ°æ˜Žæ˜¾çš„æ—¶é—´å­—æ®µï¼Œå»ºè®®:\n"
            analysis += "- æ£€æŸ¥æ˜¯å¦æœ‰æ—¥æœŸ/æ—¶é—´åˆ—\n"
            analysis += "- è€ƒè™‘æ·»åŠ æ—¶é—´ç»´åº¦è¿›è¡Œåˆ†æž\n"

        return analysis

    def _generate_distribution_analysis(self, data):
        """Generate distribution analysis"""
        analysis = "## ðŸ“Š åˆ†å¸ƒåˆ†æž\n\n"

        numeric_cols = data.select_dtypes(include=["number"]).columns
        categorical_cols = data.select_dtypes(include=["object"]).columns

        if len(numeric_cols) > 0:
            analysis += "### æ•°å€¼åž‹æ•°æ®åˆ†å¸ƒ\n"
            for col in numeric_cols[:3]:
                stats = data[col].describe()
                analysis += f"- **{col}:** å‡å€¼={stats['mean']:.2f}, æ ‡å‡†å·®={stats['std']:.2f}\n"

        if len(categorical_cols) > 0:
            analysis += "\n### åˆ†ç±»åž‹æ•°æ®åˆ†å¸ƒ\n"
            for col in categorical_cols[:3]:
                value_counts = data[col].value_counts()
                analysis += f"- **{col}:** æœ€å¤šå€¼='{value_counts.index[0]}' ({value_counts.iloc[0]}æ¬¡)\n"

        return analysis

    def _generate_general_analysis(self, data, query):
        """Generate general analysis based on query"""
        analysis = f"## ðŸ¤– AI åˆ†æžç»“æžœ\n\n"
        analysis += f"é’ˆå¯¹æŸ¥è¯¢: **{query}**\n\n"

        # Provide insights based on data characteristics
        analysis += "### æ•°æ®æ´žå¯Ÿ\n"
        analysis += f"- æ•°æ®é›†åŒ…å« {len(data)} æ¡è®°å½•\n"
        analysis += f"- æ¶µç›– {len(data.columns)} ä¸ªå­—æ®µ\n"

        # Identify key patterns
        numeric_cols = data.select_dtypes(include=["number"]).columns
        if len(numeric_cols) > 0:
            analysis += f"- åŒ…å« {len(numeric_cols)} ä¸ªæ•°å€¼åž‹å­—æ®µ\n"

        categorical_cols = data.select_dtypes(include=["object"]).columns
        if len(categorical_cols) > 0:
            analysis += f"- åŒ…å« {len(categorical_cols)} ä¸ªåˆ†ç±»åž‹å­—æ®µ\n"

        analysis += "\n### å»ºè®®\n"
        analysis += "- å°è¯•æ›´å…·ä½“çš„æŸ¥è¯¢ï¼Œå¦‚'æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯'æˆ–'ç”Ÿæˆå›¾è¡¨'\n"
        analysis += "- ä½¿ç”¨å¿«é€Ÿåˆ†æžæŒ‰é’®èŽ·å–å¸¸ç”¨åˆ†æžç»“æžœ\n"

        return analysis

    def show(self):
        """PandasAI demo page implementation with enhanced functionality"""
        self.ui.create_header("æ™ºèƒ½åˆ†æž")

        st.markdown("### æ•°æ®åˆ†æžå·¥å…·")

        # Check if DashScope is available
        llm = self.setup_dashscope_llm()
        if llm:
            st.success("âœ… DashScope AI åˆ†æžå·²å¯ç”¨")
        else:
            st.info("â„¹ï¸ ä½¿ç”¨æ¨¡æ‹Ÿåˆ†æžæ¨¡å¼")

        # Data source selection
        data_sources = ["ä¼šè®®æ•°æ®", "ä»»åŠ¡æ•°æ®", "ç”¨æˆ·æ•°æ®", "ä¼šè®®å®¤æ•°æ®"]
        selected_source = st.selectbox("é€‰æ‹©æ•°æ®æº", data_sources)

        # Get selected data
        if selected_source == "ä¼šè®®æ•°æ®":
            sample_data = self.data_manager.get_dataframe("meetings")
        elif selected_source == "ä»»åŠ¡æ•°æ®":
            sample_data = self.data_manager.get_dataframe("tasks")
        elif selected_source == "ç”¨æˆ·æ•°æ®":
            sample_data = self.data_manager.get_dataframe("users")
        else:
            sample_data = self.data_manager.get_dataframe("rooms")

        if len(sample_data) > 0:
            st.markdown(f"#### {selected_source}")

            # Show data preview
            with st.expander("æ•°æ®é¢„è§ˆ"):
                st.dataframe(sample_data.head(10), use_container_width=True)

            # Natural language query
            st.markdown("#### è‡ªç„¶è¯­è¨€æŸ¥è¯¢")

            query = st.text_input(
                "è¯·è¾“å…¥æ‚¨çš„é—®é¢˜", placeholder="ä¾‹å¦‚ï¼šæ˜¾ç¤ºæ•°æ®çš„åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯", value=""
            )

            if st.button("åˆ†æž", type="primary"):
                if query:
                    with st.spinner("æ­£åœ¨åˆ†æž..."):
                        if llm:
                            # Use AI-powered analysis
                            analysis_result = self.perform_ai_analysis(
                                query, sample_data, llm
                            )
                            if analysis_result:
                                st.success("AI åˆ†æžå®Œæˆï¼")
                                st.markdown(analysis_result)

                                # Show visualizations based on analysis type
                                self._show_analysis_visualizations(sample_data, query)
                            else:
                                st.error("AI åˆ†æžå¤±è´¥ï¼Œè¯·é‡è¯•")
                        else:
                            # Fallback to mock analysis
                            self._perform_mock_analysis(query, sample_data)
                else:
                    st.warning("è¯·è¾“å…¥æŸ¥è¯¢å†…å®¹")
        else:
            st.info(f"æš‚æ— {selected_source}ï¼Œè¯·å…ˆåˆ›å»ºä¸€äº›æ•°æ®")

        # Quick analysis buttons
        st.markdown("---")
        st.markdown("### å¿«é€Ÿåˆ†æž")

        col1, col2, col3 = st.columns(3)

        with col1:
            if st.button("æ•°æ®æ¦‚è§ˆ", type="secondary"):
                if len(sample_data) > 0:
                    st.markdown("#### æ•°æ®æ¦‚è§ˆ")
                    st.write(f"**æ•°æ®é›†:** {selected_source}")
                    st.write(f"**è®°å½•æ•°:** {len(sample_data)}")
                    st.write(f"**å­—æ®µæ•°:** {len(sample_data.columns)}")
                    st.write(f"**å­—æ®µåˆ—è¡¨:** {', '.join(sample_data.columns.tolist())}")

        with col2:
            if st.button("åŸºç¡€ç»Ÿè®¡", type="secondary"):
                if len(sample_data) > 0:
                    numeric_cols = sample_data.select_dtypes(include=["number"]).columns
                    if len(numeric_cols) > 0:
                        st.markdown("#### åŸºç¡€ç»Ÿè®¡")
                        st.dataframe(sample_data[numeric_cols].describe())
                    else:
                        st.info("æ²¡æœ‰æ•°å€¼åž‹æ•°æ®")

        with col3:
            if st.button("æ•°æ®å¯¼å‡º", type="secondary"):
                if len(sample_data) > 0:
                    csv_data = sample_data.to_csv(index=False)
                    st.download_button(
                        label="ä¸‹è½½æ•°æ®",
                        data=csv_data,
                        file_name=f"{selected_source}.csv",
                        mime="text/csv",
                    )

    def _show_analysis_visualizations(self, sample_data, query):
        """Show visualizations based on analysis type"""
        if "ç»Ÿè®¡" in query or "æ¦‚è§ˆ" in query:
            # Show basic statistics visualizations
            numeric_cols = sample_data.select_dtypes(include=["number"]).columns
            if len(numeric_cols) > 0:
                st.markdown("#### æ•°å€¼å­—æ®µåˆ†å¸ƒ")
                for col in numeric_cols[:3]:  # Show first 3 numeric columns
                    fig = px.histogram(sample_data, x=col, title=f"{col} åˆ†å¸ƒ")
                    st.plotly_chart(fig, use_container_width=True)

        elif "å›¾è¡¨" in query or "å¯è§†åŒ–" in query:
            # Show comprehensive visualizations
            self._show_comprehensive_visualizations(sample_data)

    def _show_comprehensive_visualizations(self, sample_data):
        """Show comprehensive visualizations"""
        st.markdown("#### æ•°æ®å¯è§†åŒ–")

        # Create visualization based on data type
        numeric_cols = sample_data.select_dtypes(include=["number"]).columns
        categorical_cols = sample_data.select_dtypes(include=["object"]).columns

        # Show numeric data distributions
        if len(numeric_cols) > 0:
            for col in numeric_cols[:2]:  # Show first 2 numeric columns
                fig = px.histogram(sample_data, x=col, title=f"{col} åˆ†å¸ƒ", nbins=20)
                st.plotly_chart(fig, use_container_width=True)

        # Show categorical data distributions
        if len(categorical_cols) > 0:
            for col in categorical_cols[:2]:  # Show first 2 categorical columns
                value_counts = sample_data[col].value_counts()
                fig = px.bar(
                    x=value_counts.index, y=value_counts.values, title=f"{col} åˆ†å¸ƒ"
                )
                st.plotly_chart(fig, use_container_width=True)

    def _perform_mock_analysis(self, query, sample_data):
        """Perform mock analysis (fallback when AI is not available)"""
        import time

        time.sleep(1)  # Simulate processing

        # Mock AI response based on query
        if "ç»Ÿè®¡" in query or "æ¦‚è§ˆ" in query:
            st.success("åˆ†æžå®Œæˆï¼")
            st.markdown("#### æ•°æ®ç»Ÿè®¡ç»“æžœ")

            # Show basic statistics
            numeric_cols = sample_data.select_dtypes(include=["number"]).columns
            if len(numeric_cols) > 0:
                st.dataframe(sample_data[numeric_cols].describe())

            # Show value counts for categorical columns
            categorical_cols = sample_data.select_dtypes(include=["object"]).columns[:3]
            if len(categorical_cols) > 0:
                for col in categorical_cols:
                    if col in sample_data.columns:
                        st.markdown(f"**{col} åˆ†å¸ƒ:**")
                        value_counts = sample_data[col].value_counts()

                        fig = px.bar(
                            x=value_counts.index,
                            y=value_counts.values,
                            title=f"{col} åˆ†å¸ƒ",
                            labels={"x": col, "y": "æ•°é‡"},
                        )
                        fig.update_layout(height=300)
                        st.plotly_chart(fig, use_container_width=True)

        elif "å›¾è¡¨" in query or "å¯è§†åŒ–" in query:
            st.success("åˆ†æžå®Œæˆï¼")
            st.markdown("#### æ•°æ®å¯è§†åŒ–")
            self._show_comprehensive_visualizations(sample_data)

        else:
            st.success("åˆ†æžå®Œæˆï¼")
            st.info("è¯·å°è¯•æ›´å…·ä½“çš„æŸ¥è¯¢ï¼Œå¦‚'æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯'æˆ–'ç”Ÿæˆå›¾è¡¨'")

            # Show basic info
            st.markdown("#### æ•°æ®åŸºæœ¬ä¿¡æ¯")
            col1, col2, col3 = st.columns(3)

            with col1:
                st.metric("æ€»è®°å½•æ•°", len(sample_data))

            with col2:
                st.metric("å­—æ®µæ•°", len(sample_data.columns))

            with col3:
                if len(sample_data.select_dtypes(include=["number"]).columns) > 0:
                    st.metric(
                        "æ•°å€¼å­—æ®µ",
                        len(sample_data.select_dtypes(include=["number"]).columns),
                    )
                else:
                    st.metric("æ•°å€¼å­—æ®µ", 0)
