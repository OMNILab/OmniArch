"""
AI Booking Page Module
Contains the AI-powered booking page implementation for the smart meeting system
"""

import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
import os
import sys
import uuid
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.types import Command

from smartmeeting.agent import create_graph
from smartmeeting.data_manager import DataManager


class BookingPage:
    """AI-powered booking page implementation with enhanced functionality"""

    def __init__(self, data_manager, auth_manager, ui_components):
        self.data_manager = data_manager
        self.auth_manager = auth_manager
        self.ui = ui_components

    def check_login(self):
        """æ£€æŸ¥ç”¨æˆ·ç™»å½•çŠ¶æ€"""
        if not self.auth_manager.is_authenticated():
            st.warning("âš ï¸ è¯·å…ˆç™»å½•ä»¥è®¿é—®æ­¤é¡µé¢")
            st.stop()

    def initialize_graph(self):
        """åˆå§‹åŒ–æˆ–è·å–ç¼“å­˜çš„å›¾å®ä¾‹"""
        if "graph" not in st.session_state:
            try:
                # ä½¿ç”¨å†…å­˜å­˜å‚¨å™¨ä»¥åœ¨é¡µé¢åˆ·æ–°é—´ä¿æŒçŠ¶æ€
                memory = InMemorySaver()
                st.session_state.graph = create_graph(checkpointer=memory)
                st.success("âœ… AIåŠ©æ‰‹å·²å°±ç»ª")
            except Exception as e:
                st.error(f"âŒ åˆå§‹åŒ–AIåŠ©æ‰‹å¤±è´¥: {e}")
                st.stop()

        if "thread_id" not in st.session_state:
            st.session_state.thread_id = str(uuid.uuid4())

        # åˆå§‹åŒ–ç”¨æˆ·ä¿¡æ¯åˆ°session state
        if "user_id" not in st.session_state or "username" not in st.session_state:
            current_user = self.auth_manager.get_current_user()
            if current_user:
                st.session_state.user_id = current_user.get("id", 1)
                st.session_state.username = current_user.get("name", "ç”¨æˆ·")
            else:
                st.session_state.user_id = 1
                st.session_state.username = "ç”¨æˆ·"

        # åˆå§‹åŒ–å·¥å…·çŠ¶æ€å®¹å™¨
        if "tool_status_containers" not in st.session_state:
            st.session_state.tool_status_containers = {}

    def get_config(self):
        """è·å–å›¾é…ç½®"""
        return {"configurable": {"thread_id": st.session_state.thread_id}}

    def render_message(self, message):
        """æ¸²æŸ“å•æ¡æ¶ˆæ¯"""
        if isinstance(message, HumanMessage):
            with st.chat_message("human"):
                st.markdown(message.content)

        elif isinstance(message, AIMessage):
            # è·³è¿‡åŒ…å«tool_callsçš„AIMessageï¼Œå› ä¸ºå®ƒä»¬ä¼šè¢«st.statusæ˜¾ç¤º
            if not message.tool_calls:
                with st.chat_message("assistant"):
                    st.markdown(message.content)

    def render_message_history(self):
        """æ¸²æŸ“å†å²æ¶ˆæ¯"""
        graph = st.session_state.graph
        config = self.get_config()

        try:
            current_state = graph.get_state(config)
            messages = current_state.values.get("messages", [])

            for message in messages:
                self.render_message(message)

        except Exception as e:
            st.error(f"âŒ è·å–æ¶ˆæ¯å†å²å¤±è´¥: {e}")

    def render_hitl_confirmation(self):
        """æ¸²æŸ“äººå·¥ä»‹å…¥ç¡®è®¤å¡ç‰‡"""
        graph = st.session_state.graph
        config = self.get_config()

        try:
            current_state = graph.get_state(config)

            # æ£€æŸ¥æ˜¯å¦æœ‰ä¸­æ–­
            if current_state.next and len(current_state.next) > 0:
                messages = current_state.values.get("messages", [])
                if messages:
                    last_message = messages[-1]

                    if isinstance(last_message, AIMessage) and last_message.tool_calls:
                        tool_call = last_message.tool_calls[0]
                        tool_name = tool_call["name"]
                        tool_args = tool_call["args"]

                        # åˆ›å»ºç¡®è®¤å¡ç‰‡
                        with st.status(
                            f"âš ï¸ éœ€è¦ç¡®è®¤: {tool_name}", state="running", expanded=True
                        ):
                            st.markdown("### ğŸ› ï¸ å¾…æ‰§è¡Œæ“ä½œ")

                            # æ ¹æ®ä¸åŒå·¥å…·æ˜¾ç¤ºä¸åŒçš„è¯¦æƒ…
                            if tool_name == "book_room":
                                self.render_booking_confirmation(tool_args)
                            elif tool_name == "cancel_bookings":
                                self.render_cancellation_confirmation(tool_args)
                            elif tool_name == "alter_booking":
                                self.render_alteration_confirmation(tool_args)
                            else:
                                st.json(tool_args)

                            # ç¡®è®¤æŒ‰é’®
                            col1, col2 = st.columns(2)

                            with col1:
                                if st.button(
                                    "âœ… æ‰¹å‡†æ‰§è¡Œ",
                                    use_container_width=True,
                                    type="primary",
                                ):
                                    # åˆ›å»ºstreamingå±•ç¤ºå®¹å™¨
                                    streaming_container = st.empty()

                                    with streaming_container.container():
                                        st.markdown("### ğŸ”„ æ‰§è¡Œè¿‡ç¨‹")
                                        progress_placeholder = st.empty()
                                        response_placeholder = st.empty()

                                        try:
                                            progress_text = ""
                                            final_response = ""

                                            # ä½¿ç”¨æ­£ç¡®çš„streamingæ–¹å¼ - ä¿®å¤ï¼šresumeåº”è¯¥æ¥å—åˆ—è¡¨
                                            for chunk in graph.stream(
                                                Command(resume=[{"type": "accept"}]),
                                                config,
                                                stream_mode="updates",
                                            ):
                                                # chunkçš„æ ¼å¼æ˜¯ {node_name: node_data}
                                                for (
                                                    node_name,
                                                    node_data,
                                                ) in chunk.items():
                                                    progress_text += f"ğŸ“ **{node_name}**: å¤„ç†ä¸­...\n"
                                                    progress_placeholder.markdown(
                                                        progress_text
                                                    )

                                                    # å¦‚æœnode_dataåŒ…å«messagesï¼Œæå–AIå“åº”
                                                    if (
                                                        isinstance(node_data, dict)
                                                        and "messages" in node_data
                                                    ):
                                                        messages = node_data["messages"]
                                                        if messages:
                                                            for message in messages:
                                                                if (
                                                                    isinstance(
                                                                        message,
                                                                        AIMessage,
                                                                    )
                                                                    and message.content
                                                                ):
                                                                    final_response = (
                                                                        message.content
                                                                    )
                                                                    response_placeholder.markdown(
                                                                        f"**ğŸ¤– AIå“åº”**:\n{final_response}"
                                                                    )

                                            st.success("âœ… æ“ä½œå·²å®Œæˆ")
                                            st.rerun()

                                        except Exception as e:
                                            st.error(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")

                            with col2:
                                if st.button("âŒ æ‹’ç»æ“ä½œ", use_container_width=True):
                                    # åˆ›å»ºstreamingå±•ç¤ºå®¹å™¨
                                    streaming_container = st.empty()

                                    with streaming_container.container():
                                        st.markdown("### ğŸš« å–æ¶ˆè¿‡ç¨‹")
                                        progress_placeholder = st.empty()
                                        response_placeholder = st.empty()

                                        try:
                                            progress_text = ""
                                            final_response = ""

                                            # ä½¿ç”¨æ­£ç¡®çš„streamingæ–¹å¼ - ä¿®å¤ï¼šresumeåº”è¯¥æ¥å—åˆ—è¡¨
                                            for chunk in graph.stream(
                                                Command(resume=[{"type": "ignore"}]),
                                                config,
                                                stream_mode="updates",
                                            ):
                                                # chunkçš„æ ¼å¼æ˜¯ {node_name: node_data}
                                                for (
                                                    node_name,
                                                    node_data,
                                                ) in chunk.items():
                                                    progress_text += f"ğŸ“ **{node_name}**: å¤„ç†ä¸­...\n"
                                                    progress_placeholder.markdown(
                                                        progress_text
                                                    )

                                                    # å¦‚æœnode_dataåŒ…å«messagesï¼Œæå–AIå“åº”
                                                    if (
                                                        isinstance(node_data, dict)
                                                        and "messages" in node_data
                                                    ):
                                                        messages = node_data["messages"]
                                                        if messages:
                                                            for message in messages:
                                                                if (
                                                                    isinstance(
                                                                        message,
                                                                        AIMessage,
                                                                    )
                                                                    and message.content
                                                                ):
                                                                    final_response = (
                                                                        message.content
                                                                    )
                                                                    response_placeholder.markdown(
                                                                        f"**ğŸ¤– AIå“åº”**:\n{final_response}"
                                                                    )

                                            st.warning("ğŸš« æ“ä½œå·²å–æ¶ˆ")
                                            st.rerun()

                                        except Exception as e:
                                            st.error(f"âŒ å–æ¶ˆå¤±è´¥: {e}")

        except Exception as e:
            st.error(f"âŒ æ£€æŸ¥ä¸­æ–­çŠ¶æ€å¤±è´¥: {e}")

    def render_booking_confirmation(self, tool_args):
        """æ¸²æŸ“é¢„è®¢ç¡®è®¤è¯¦æƒ…"""
        st.markdown("**ğŸ“… ä¼šè®®å®¤é¢„è®¢**")

        # è·å–æˆ¿é—´è¯¦æƒ…
        room_id = tool_args.get("room_id")
        if room_id:
            rooms_df = self.data_manager.get_dataframe("rooms")
            room = rooms_df[rooms_df["room_id"] == room_id]
            if not room.empty:
                room = room.iloc[0]
                st.markdown(
                    f"ğŸ¢ **ä¼šè®®å®¤**: {room['room_name']} ({room.get('building_id', 'æœªçŸ¥')}-{room.get('floor', 'æœªçŸ¥')}æ¥¼)"
                )
                st.markdown(f"ğŸ‘¥ **å®¹é‡**: {room['capacity']}äºº")
                if room.get("equipment"):
                    st.markdown(f"ğŸ”§ **è®¾å¤‡**: {room['equipment']}")
            else:
                st.markdown(f"ğŸ¢ **ä¼šè®®å®¤ID**: {room_id}")

        # å…¶ä»–é¢„è®¢ä¿¡æ¯
        if "start_time" in tool_args:
            st.markdown(f"â° **å¼€å§‹æ—¶é—´**: {tool_args['start_time']}")
        if "end_time" in tool_args:
            st.markdown(f"â° **ç»“æŸæ—¶é—´**: {tool_args['end_time']}")
        if "title" in tool_args:
            st.markdown(f"ğŸ“ **ä¼šè®®æ ‡é¢˜**: {tool_args['title']}")

    def render_cancellation_confirmation(self, tool_args):
        """æ¸²æŸ“å–æ¶ˆç¡®è®¤è¯¦æƒ…"""
        st.markdown("**ğŸ—‘ï¸ å–æ¶ˆé¢„è®¢**")

        if "booking_ids" in tool_args:
            booking_ids = tool_args["booking_ids"]
            if isinstance(booking_ids, list):
                st.markdown(
                    f"ğŸ“‹ **å¾…å–æ¶ˆçš„é¢„è®¢ID**: {', '.join(map(str, booking_ids))}"
                )
            else:
                st.markdown(f"ğŸ“‹ **å¾…å–æ¶ˆçš„é¢„è®¢ID**: {booking_ids}")

        st.warning("âš ï¸ æ­¤æ“ä½œä¸å¯æ’¤é”€")

    def render_alteration_confirmation(self, tool_args):
        """æ¸²æŸ“ä¿®æ”¹ç¡®è®¤è¯¦æƒ…"""
        st.markdown("**âœï¸ ä¿®æ”¹é¢„è®¢**")

        if "booking_id" in tool_args:
            st.markdown(f"ğŸ“‹ **é¢„è®¢ID**: {tool_args['booking_id']}")

        st.markdown("**ğŸ“ ä¿®æ”¹å†…å®¹**:")
        for key, value in tool_args.items():
            if key != "booking_id" and value is not None:
                if key == "new_room_id":
                    st.markdown(f"- **æ–°ä¼šè®®å®¤ID**: {value}")
                elif key == "new_start_time":
                    st.markdown(f"- **æ–°å¼€å§‹æ—¶é—´**: {value}")
                elif key == "new_end_time":
                    st.markdown(f"- **æ–°ç»“æŸæ—¶é—´**: {value}")

    def process_stream_events(self, events):
        """å¤„ç†æµå¼äº‹ä»¶"""
        ai_placeholder = st.empty()
        full_response = ""

        for chunk in events:
            # LangGraphæµå¼ è¾“å‡ºæ ¼å¼æ˜¯ {node_name: node_data}
            for node_name, node_data in chunk.items():
                if isinstance(node_data, dict) and "messages" in node_data:
                    messages = node_data["messages"]
                    for message in messages:
                        if isinstance(message, AIMessage):
                            if message.tool_calls:
                                # ä¸ºå·¥å…·è°ƒç”¨åˆ›å»ºçŠ¶æ€å®¹å™¨
                                for tool_call in message.tool_calls:
                                    tool_call_id = tool_call["id"]
                                    tool_name = tool_call["name"]

                                    if (
                                        tool_call_id
                                        not in st.session_state.tool_status_containers
                                    ):
                                        status_container = st.status(
                                            f"ğŸ”§ æ‰§è¡Œå·¥å…·: {tool_name}",
                                            state="running",
                                            expanded=True,
                                        )
                                        st.session_state.tool_status_containers[
                                            tool_call_id
                                        ] = status_container

                                        with status_container:
                                            st.json(tool_call["args"])
                            else:
                                # ç´¯ç§¯AIå›å¤æ–‡æœ¬
                                full_response += message.content
                                ai_placeholder.markdown(full_response + "â–Œ")

                        elif isinstance(message, ToolMessage):
                            tool_call_id = message.tool_call_id
                            if tool_call_id in st.session_state.tool_status_containers:
                                status_container = (
                                    st.session_state.tool_status_containers[
                                        tool_call_id
                                    ]
                                )
                                status_container.update(state="complete")

                                with status_container:
                                    st.success("âœ… å·¥å…·æ‰§è¡Œå®Œæˆ")
                                    if message.content:
                                        st.text(message.content)

        # æ˜¾ç¤ºæœ€ç»ˆå›å¤
        if full_response:
            ai_placeholder.markdown(full_response)

        # æ¸…ç©ºå·¥å…·çŠ¶æ€å®¹å™¨
        st.session_state.tool_status_containers = {}

    def handle_user_input(self):
        """å¤„ç†ç”¨æˆ·è¾“å…¥"""
        # æ£€æŸ¥æ˜¯å¦æœ‰ç¤ºä¾‹æŸ¥è¯¢
        if (
            hasattr(st.session_state, "example_query")
            and st.session_state.example_query
        ):
            user_input = st.session_state.example_query
            del st.session_state.example_query  # æ¸…é™¤ç¤ºä¾‹æŸ¥è¯¢

            # ç«‹å³æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
            with st.chat_message("human"):
                st.markdown(user_input)

            # å¤„ç†AIå›å¤
            with st.chat_message("assistant"):
                graph = st.session_state.graph
                config = self.get_config()

                try:
                    with st.spinner("ğŸ¤” AIæ­£åœ¨æ€è€ƒ..."):
                        # æ„å»ºè¾“å…¥çŠ¶æ€ï¼ŒåŒ…å«ç”¨æˆ·ä¿¡æ¯
                        input_state = {
                            "messages": [HumanMessage(content=user_input)],
                            "current_user_id": st.session_state.user_id,
                            "current_username": st.session_state.username,
                        }

                        # ä½¿ç”¨æµå¼è°ƒç”¨
                        events = graph.stream(
                            input_state, config, stream_mode="updates"
                        )
                        self.process_stream_events(events)

                    # åˆ·æ–°é¡µé¢ä»¥æ˜¾ç¤ºå¯èƒ½çš„æ–°ä¸­æ–­
                    st.rerun()

                except Exception as e:
                    st.error(f"âŒ å¤„ç†å¤±è´¥: {e}")

        # å¤„ç†ç”¨æˆ·æ‰‹åŠ¨è¾“å…¥
        if user_input := st.chat_input("è¯·è¾“å…¥æ‚¨çš„éœ€æ±‚..."):
            # ç«‹å³æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
            with st.chat_message("human"):
                st.markdown(user_input)

            # å¤„ç†AIå›å¤
            with st.chat_message("assistant"):
                graph = st.session_state.graph
                config = self.get_config()

                try:
                    with st.spinner("ğŸ¤” AIæ­£åœ¨æ€è€ƒ..."):
                        # æ„å»ºè¾“å…¥çŠ¶æ€ï¼ŒåŒ…å«ç”¨æˆ·ä¿¡æ¯
                        input_state = {
                            "messages": [HumanMessage(content=user_input)],
                            "current_user_id": st.session_state.user_id,
                            "current_username": st.session_state.username,
                        }

                        # ä½¿ç”¨æµå¼è°ƒç”¨
                        events = graph.stream(
                            input_state, config, stream_mode="updates"
                        )
                        self.process_stream_events(events)

                    # åˆ·æ–°é¡µé¢ä»¥æ˜¾ç¤ºå¯èƒ½çš„æ–°ä¸­æ–­
                    st.rerun()

                except Exception as e:
                    st.error(f"âŒ å¤„ç†å¤±è´¥: {e}")

    def show_welcome_message(self):
        """æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯å’Œä½¿ç”¨æç¤º"""
        # æ£€æŸ¥æ˜¯å¦æ˜¯é¦–æ¬¡è®¿é—®æˆ–æ²¡æœ‰å†å²æ¶ˆæ¯
        graph = st.session_state.graph
        config = self.get_config()

        try:
            current_state = graph.get_state(config)
            messages = current_state.values.get("messages", [])

            # å¦‚æœæ²¡æœ‰å†å²æ¶ˆæ¯ï¼Œæ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯
            if not messages:
                # æ¬¢è¿ä¿¡æ¯å¡ç‰‡
                with st.container():
                    st.markdown(
                        """
                    <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                                padding: 2rem; 
                                border-radius: 16px; 
                                color: white; 
                                margin-bottom: 2rem;">
                        <h2 style="color: white; margin-bottom: 1rem;">ğŸ‰ æ¬¢è¿ä½¿ç”¨AIä¼šè®®é¢„è®¢åŠ©æ‰‹ï¼</h2>
                        <p style="font-size: 1.1rem; margin-bottom: 1.5rem;">
                            æˆ‘æ˜¯æ‚¨çš„æ™ºèƒ½ä¼šè®®ç®¡ç†åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©æ‚¨å¿«é€Ÿé¢„è®¢ã€ç®¡ç†å’ŒæŸ¥è¯¢ä¼šè®®å®¤ã€‚
                        </p>
                        <p style="font-size: 1rem; opacity: 0.9;">
                            è¯·åœ¨ä¸‹æ–¹çš„èŠå¤©æ¡†ä¸­å‘Šè¯‰æˆ‘æ‚¨çš„éœ€æ±‚ï¼Œæˆ‘ä¼šä¸ºæ‚¨æä¾›æœ€åˆé€‚çš„è§£å†³æ–¹æ¡ˆã€‚
                        </p>
                    </div>
                    """,
                        unsafe_allow_html=True,
                    )

                # ä½¿ç”¨æç¤ºå¡ç‰‡
                col1, col2 = st.columns(2)

                with col1:
                    st.markdown(
                        """
                    <div style="background: white; 
                                padding: 1.5rem; 
                                border-radius: 12px; 
                                border: 1px solid #e5e7eb; 
                                box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                        <h4 style="color: #1f2937; margin-bottom: 1rem;">ğŸ’¡ å¸¸ç”¨åŠŸèƒ½</h4>
                        <ul style="color: #6b7280; line-height: 1.6;">
                            <li>ğŸ” <strong>æŸ¥æ‰¾ä¼šè®®å®¤</strong><br>
                            "å¸®æˆ‘æ‰¾ä¸ªæ˜å¤©ä¸‹åˆ2ç‚¹çš„ä¼šè®®å®¤ï¼Œéœ€è¦10ä¸ªäºº"</li>
                            <li>ğŸ“… <strong>é¢„è®¢ä¼šè®®å®¤</strong><br>
                            "é¢„è®¢ä¼šè®®å®¤Aï¼Œæ˜å¤©ä¸Šåˆ9ç‚¹åˆ°11ç‚¹"</li>
                            <li>ğŸ“‹ <strong>æŸ¥çœ‹é¢„è®¢</strong><br>
                            "æŸ¥çœ‹æˆ‘çš„æ‰€æœ‰é¢„è®¢"</li>
                            <li>âŒ <strong>å–æ¶ˆé¢„è®¢</strong><br>
                            "å–æ¶ˆæ˜å¤©çš„ä¼šè®®é¢„è®¢"</li>
                        </ul>
                    </div>
                    """,
                        unsafe_allow_html=True,
                    )

                with col2:
                    st.markdown(
                        """
                    <div style="background: white; 
                                padding: 1.5rem; 
                                border-radius: 12px; 
                                border: 1px solid #e5e7eb; 
                                box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                        <h4 style="color: #1f2937; margin-bottom: 1rem;">âš¡ æ™ºèƒ½ç‰¹æ€§</h4>
                        <ul style="color: #6b7280; line-height: 1.6;">
                            <li>ğŸ¤– <strong>è‡ªç„¶è¯­è¨€ç†è§£</strong><br>
                            æ”¯æŒä¸­æ–‡è‡ªç„¶è¯­è¨€è¾“å…¥</li>
                            <li>ğŸ”§ <strong>æ™ºèƒ½æ¨è</strong><br>
                            æ ¹æ®éœ€æ±‚è‡ªåŠ¨æ¨èæœ€ä½³ä¼šè®®å®¤</li>
                            <li>ğŸ›¡ï¸ <strong>å®‰å…¨ç¡®è®¤</strong><br>
                            é‡è¦æ“ä½œéœ€è¦ç”¨æˆ·ç¡®è®¤</li>
                            <li>ğŸ“Š <strong>å®æ—¶çŠ¶æ€</strong><br>
                            å®æ—¶æ˜¾ç¤ºä¼šè®®å®¤å¯ç”¨çŠ¶æ€</li>
                        </ul>
                    </div>
                    """,
                        unsafe_allow_html=True,
                    )

                # å¿«é€Ÿå¼€å§‹ç¤ºä¾‹
                st.markdown("### ğŸš€ å¿«é€Ÿå¼€å§‹")

                # åˆ›å»ºç¤ºä¾‹æŒ‰é’®
                col1, col2, col3 = st.columns(3)

                with col1:
                    if st.button(
                        "ğŸ” æŸ¥æ‰¾ä¼šè®®å®¤", use_container_width=True, type="secondary"
                    ):
                        st.session_state.example_query = (
                            "å¸®æˆ‘æ‰¾ä¸ªæ˜å¤©ä¸‹åˆ2ç‚¹çš„ä¼šè®®å®¤ï¼Œéœ€è¦10ä¸ªäººï¼Œæœ€å¥½æœ‰æŠ•å½±ä»ª"
                        )
                        st.rerun()

                with col2:
                    if st.button(
                        "ğŸ“… é¢„è®¢ä¼šè®®å®¤", use_container_width=True, type="secondary"
                    ):
                        st.session_state.example_query = (
                            "é¢„è®¢ä¸€ä¸ªä¼šè®®å®¤ï¼Œæ˜å¤©ä¸Šåˆ9ç‚¹åˆ°11ç‚¹ï¼Œä¼šè®®ä¸»é¢˜æ˜¯é¡¹ç›®è®¨è®º"
                        )
                        st.rerun()

                with col3:
                    if st.button(
                        "ğŸ“‹ æŸ¥çœ‹é¢„è®¢", use_container_width=True, type="secondary"
                    ):
                        st.session_state.example_query = "æŸ¥çœ‹æˆ‘çš„æ‰€æœ‰ä¼šè®®é¢„è®¢"
                        st.rerun()

                st.markdown("---")

        except Exception as e:
            # å¦‚æœè·å–çŠ¶æ€å¤±è´¥ï¼Œä»ç„¶æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯
            st.info("ğŸ¤– AIåŠ©æ‰‹æ­£åœ¨åˆå§‹åŒ–ï¼Œè¯·ç¨å€™...")

    def show(self):
        """AI-powered booking page implementation"""
        # æ£€æŸ¥ç™»å½•çŠ¶æ€
        self.check_login()

        # åˆå§‹åŒ–å›¾
        self.initialize_graph()

        # æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯å’Œä½¿ç”¨æç¤º
        self.show_welcome_message()

        # æ¸²æŸ“äººå·¥ä»‹å…¥ç¡®è®¤ - ä¼˜å…ˆæ£€æŸ¥å¹¶æ˜¾ç¤º
        self.render_hitl_confirmation()

        # æ¸²æŸ“å†å²æ¶ˆæ¯
        self.render_message_history()

        # å¤„ç†ç”¨æˆ·è¾“å…¥
        self.handle_user_input()

        # ä¾§è¾¹æ åŠŸèƒ½è¯´æ˜
        st.sidebar.markdown("### ğŸ› ï¸ åŠŸèƒ½è¯´æ˜")
        st.sidebar.markdown(
            """
        **ğŸ” æŸ¥æ‰¾ä¼šè®®å®¤**
        - æ ¹æ®æ—¶é—´ã€äººæ•°ã€è®¾å¤‡éœ€æ±‚æ™ºèƒ½æ¨è
        - æ”¯æŒè‡ªç„¶è¯­è¨€æè¿°éœ€æ±‚
        
        **ğŸ“… é¢„è®¢ä¼šè®®å®¤**
        - ä¸€é”®é¢„è®¢ï¼Œè‡ªåŠ¨å¤„ç†æ—¶é—´å†²çª
        - æ”¯æŒä¿®æ”¹å’Œå–æ¶ˆæ“ä½œ
        
        **ğŸ“‹ ç®¡ç†é¢„è®¢**
        - æŸ¥çœ‹ä¸ªäººæ‰€æœ‰é¢„è®¢è®°å½•
        - å®æ—¶çŠ¶æ€æ›´æ–°
        
        **ğŸ›¡ï¸ å®‰å…¨ç‰¹æ€§**
        - é‡è¦æ“ä½œéœ€è¦ç”¨æˆ·ç¡®è®¤
        - é˜²æ­¢è¯¯æ“ä½œå’Œé‡å¤é¢„è®¢
        """
        )

        st.sidebar.markdown("### ğŸ’¡ ä½¿ç”¨æŠ€å·§")
        st.sidebar.markdown(
            """
        **ğŸ¯ ç²¾ç¡®æè¿°éœ€æ±‚**
        - "æ˜å¤©ä¸‹åˆ2ç‚¹ï¼Œ10ä¸ªäººï¼Œéœ€è¦æŠ•å½±ä»ª"
        - "æœ¬å‘¨äº”ä¸Šåˆ9-11ç‚¹ï¼Œé¡¹ç›®è®¨è®º"
        
        **ğŸ”§ çµæ´»æŸ¥è¯¢**
        - "æŸ¥çœ‹æˆ‘æ˜å¤©çš„ä¼šè®®"
        - "å–æ¶ˆä¸‹å‘¨ä¸‰çš„é¢„è®¢"
        
        **âš¡ å¿«é€Ÿæ“ä½œ**
        - ç‚¹å‡»ç¤ºä¾‹æŒ‰é’®å¿«é€Ÿå¼€å§‹
        - æ”¯æŒä¸­æ–‡è‡ªç„¶è¯­è¨€è¾“å…¥
        """
        )

        if st.sidebar.button("ğŸ”„ é‡ç½®å¯¹è¯"):
            if "graph" in st.session_state:
                del st.session_state.graph
            if "thread_id" in st.session_state:
                del st.session_state.thread_id
            st.rerun()
