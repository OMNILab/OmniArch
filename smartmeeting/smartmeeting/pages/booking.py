"""
AI Booking Page Module
Contains the AI-powered booking page implementation for the smart meeting system
"""

import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
import os
import sys
import uuid
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.types import Command

from smartmeeting.agent import create_graph
from smartmeeting.data_manager import DataManager


class BookingPage:
    """AI-powered booking page implementation with enhanced functionality"""

    def __init__(self, data_manager, auth_manager, ui_components):
        self.data_manager = data_manager
        self.auth_manager = auth_manager
        self.ui = ui_components

    def check_login(self):
        """æ£€æŸ¥ç”¨æˆ·ç™»å½•çŠ¶æ€"""
        if not self.auth_manager.is_authenticated():
            st.warning("âš ï¸ è¯·å…ˆç™»å½•ä»¥è®¿é—®æ­¤é¡µé¢")
            st.stop()

    def initialize_graph(self):
        """åˆå§‹åŒ–æˆ–è·å–ç¼“å­˜çš„å›¾å®ä¾‹"""
        if "graph" not in st.session_state:
            try:
                # ä½¿ç”¨å†…å­˜å­˜å‚¨å™¨ä»¥åœ¨é¡µé¢åˆ·æ–°é—´ä¿æŒçŠ¶æ€
                memory = InMemorySaver()
                st.session_state.graph = create_graph(checkpointer=memory)
                st.success("âœ… AIåŠ©æ‰‹å·²å°±ç»ª")
            except Exception as e:
                st.error(f"âŒ åˆå§‹åŒ–AIåŠ©æ‰‹å¤±è´¥: {e}")
                st.stop()

        if "thread_id" not in st.session_state:
            st.session_state.thread_id = str(uuid.uuid4())

        # åˆå§‹åŒ–ç”¨æˆ·ä¿¡æ¯åˆ°session state
        if "user_id" not in st.session_state or "username" not in st.session_state:
            current_user = self.auth_manager.get_current_user()
            if current_user:
                st.session_state.user_id = current_user.get("id", 1)
                st.session_state.username = current_user.get("name", "ç”¨æˆ·")
            else:
                st.session_state.user_id = 1
                st.session_state.username = "ç”¨æˆ·"

        # åˆå§‹åŒ–å·¥å…·çŠ¶æ€å®¹å™¨
        if "tool_status_containers" not in st.session_state:
            st.session_state.tool_status_containers = {}

    def get_config(self):
        """è·å–å›¾é…ç½®"""
        return {"configurable": {"thread_id": st.session_state.thread_id}}

    def render_message(self, message):
        """æ¸²æŸ“å•æ¡æ¶ˆæ¯"""
        if isinstance(message, HumanMessage):
            with st.chat_message("human"):
                st.markdown(message.content)

        elif isinstance(message, AIMessage):
            # è·³è¿‡åŒ…å«tool_callsçš„AIMessageï¼Œå› ä¸ºå®ƒä»¬ä¼šè¢«st.statusæ˜¾ç¤º
            if not message.tool_calls:
                with st.chat_message("assistant"):
                    st.markdown(message.content)

    def render_message_history(self):
        """æ¸²æŸ“å†å²æ¶ˆæ¯"""
        graph = st.session_state.graph
        config = self.get_config()

        try:
            current_state = graph.get_state(config)
            messages = current_state.values.get("messages", [])

            for message in messages:
                self.render_message(message)

        except Exception as e:
            st.error(f"âŒ è·å–æ¶ˆæ¯å†å²å¤±è´¥: {e}")

    def render_hitl_confirmation(self):
        """æ¸²æŸ“äººå·¥ä»‹å…¥ç¡®è®¤å¡ç‰‡"""
        graph = st.session_state.graph
        config = self.get_config()

        try:
            current_state = graph.get_state(config)

            # æ£€æŸ¥æ˜¯å¦æœ‰ä¸­æ–­
            if current_state.next and len(current_state.next) > 0:
                messages = current_state.values.get("messages", [])
                if messages:
                    last_message = messages[-1]

                    if isinstance(last_message, AIMessage) and last_message.tool_calls:
                        tool_call = last_message.tool_calls[0]
                        tool_name = tool_call["name"]
                        tool_args = tool_call["args"]

                        # åˆ›å»ºç¡®è®¤å¡ç‰‡
                        with st.status(
                            f"âš ï¸ éœ€è¦ç¡®è®¤: {tool_name}", state="running", expanded=True
                        ):
                            st.markdown("### ğŸ› ï¸ å¾…æ‰§è¡Œæ“ä½œ")

                            # æ ¹æ®ä¸åŒå·¥å…·æ˜¾ç¤ºä¸åŒçš„è¯¦æƒ…
                            if tool_name == "book_room":
                                self.render_booking_confirmation(tool_args)
                            elif tool_name == "cancel_bookings":
                                self.render_cancellation_confirmation(tool_args)
                            elif tool_name == "alter_booking":
                                self.render_alteration_confirmation(tool_args)
                            else:
                                st.json(tool_args)

                            # ç¡®è®¤æŒ‰é’®
                            col1, col2 = st.columns(2)

                            with col1:
                                if st.button(
                                    "âœ… æ‰¹å‡†æ‰§è¡Œ",
                                    use_container_width=True,
                                    type="primary",
                                ):
                                    # åˆ›å»ºstreamingå±•ç¤ºå®¹å™¨
                                    streaming_container = st.empty()

                                    with streaming_container.container():
                                        st.markdown("### ğŸ”„ æ‰§è¡Œè¿‡ç¨‹")
                                        progress_placeholder = st.empty()
                                        response_placeholder = st.empty()

                                        try:
                                            progress_text = ""
                                            final_response = ""

                                            # ä½¿ç”¨æ­£ç¡®çš„streamingæ–¹å¼ - ä¿®å¤ï¼šresumeåº”è¯¥æ¥å—åˆ—è¡¨
                                            for chunk in graph.stream(
                                                Command(resume=[{"type": "accept"}]),
                                                config,
                                                stream_mode="updates",
                                            ):
                                                # chunkçš„æ ¼å¼æ˜¯ {node_name: node_data}
                                                for (
                                                    node_name,
                                                    node_data,
                                                ) in chunk.items():
                                                    progress_text += f"ğŸ“ **{node_name}**: å¤„ç†ä¸­...\n"
                                                    progress_placeholder.markdown(
                                                        progress_text
                                                    )

                                                    # å¦‚æœnode_dataåŒ…å«messagesï¼Œæå–AIå“åº”
                                                    if (
                                                        isinstance(node_data, dict)
                                                        and "messages" in node_data
                                                    ):
                                                        messages = node_data["messages"]
                                                        if messages:
                                                            for message in messages:
                                                                if (
                                                                    isinstance(
                                                                        message,
                                                                        AIMessage,
                                                                    )
                                                                    and message.content
                                                                ):
                                                                    final_response = (
                                                                        message.content
                                                                    )
                                                                    response_placeholder.markdown(
                                                                        f"**ğŸ¤– AIå“åº”**:\n{final_response}"
                                                                    )

                                            st.success("âœ… æ“ä½œå·²å®Œæˆ")
                                            st.rerun()

                                        except Exception as e:
                                            st.error(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")

                            with col2:
                                if st.button("âŒ æ‹’ç»æ“ä½œ", use_container_width=True):
                                    # åˆ›å»ºstreamingå±•ç¤ºå®¹å™¨
                                    streaming_container = st.empty()

                                    with streaming_container.container():
                                        st.markdown("### ğŸš« å–æ¶ˆè¿‡ç¨‹")
                                        progress_placeholder = st.empty()
                                        response_placeholder = st.empty()

                                        try:
                                            progress_text = ""
                                            final_response = ""

                                            # ä½¿ç”¨æ­£ç¡®çš„streamingæ–¹å¼ - ä¿®å¤ï¼šresumeåº”è¯¥æ¥å—åˆ—è¡¨
                                            for chunk in graph.stream(
                                                Command(resume=[{"type": "ignore"}]),
                                                config,
                                                stream_mode="updates",
                                            ):
                                                # chunkçš„æ ¼å¼æ˜¯ {node_name: node_data}
                                                for (
                                                    node_name,
                                                    node_data,
                                                ) in chunk.items():
                                                    progress_text += f"ğŸ“ **{node_name}**: å¤„ç†ä¸­...\n"
                                                    progress_placeholder.markdown(
                                                        progress_text
                                                    )

                                                    # å¦‚æœnode_dataåŒ…å«messagesï¼Œæå–AIå“åº”
                                                    if (
                                                        isinstance(node_data, dict)
                                                        and "messages" in node_data
                                                    ):
                                                        messages = node_data["messages"]
                                                        if messages:
                                                            for message in messages:
                                                                if (
                                                                    isinstance(
                                                                        message,
                                                                        AIMessage,
                                                                    )
                                                                    and message.content
                                                                ):
                                                                    final_response = (
                                                                        message.content
                                                                    )
                                                                    response_placeholder.markdown(
                                                                        f"**ğŸ¤– AIå“åº”**:\n{final_response}"
                                                                    )

                                            st.warning("ğŸš« æ“ä½œå·²å–æ¶ˆ")
                                            st.rerun()

                                        except Exception as e:
                                            st.error(f"âŒ å–æ¶ˆå¤±è´¥: {e}")

        except Exception as e:
            st.error(f"âŒ æ£€æŸ¥ä¸­æ–­çŠ¶æ€å¤±è´¥: {e}")

    def render_booking_confirmation(self, tool_args):
        """æ¸²æŸ“é¢„è®¢ç¡®è®¤è¯¦æƒ…"""
        st.markdown("**ğŸ“… ä¼šè®®å®¤é¢„è®¢**")

        # è·å–æˆ¿é—´è¯¦æƒ…
        room_id = tool_args.get("room_id")
        if room_id:
            rooms_df = self.data_manager.get_dataframe("rooms")
            room = rooms_df[rooms_df["id"] == room_id]
            if not room.empty:
                room = room.iloc[0]
                st.markdown(
                    f"ğŸ¢ **ä¼šè®®å®¤**: {room['name']} ({room.get('building', 'æœªçŸ¥')}-{room.get('floor', 'æœªçŸ¥')}æ¥¼)"
                )
                st.markdown(f"ğŸ‘¥ **å®¹é‡**: {room['capacity']}äºº")
                if room.get("equipment"):
                    st.markdown(f"ğŸ”§ **è®¾å¤‡**: {room['equipment']}")
            else:
                st.markdown(f"ğŸ¢ **ä¼šè®®å®¤ID**: {room_id}")

        # å…¶ä»–é¢„è®¢ä¿¡æ¯
        if "start_time" in tool_args:
            st.markdown(f"â° **å¼€å§‹æ—¶é—´**: {tool_args['start_time']}")
        if "end_time" in tool_args:
            st.markdown(f"â° **ç»“æŸæ—¶é—´**: {tool_args['end_time']}")
        if "title" in tool_args:
            st.markdown(f"ğŸ“ **ä¼šè®®æ ‡é¢˜**: {tool_args['title']}")

    def render_cancellation_confirmation(self, tool_args):
        """æ¸²æŸ“å–æ¶ˆç¡®è®¤è¯¦æƒ…"""
        st.markdown("**ğŸ—‘ï¸ å–æ¶ˆé¢„è®¢**")

        if "booking_ids" in tool_args:
            booking_ids = tool_args["booking_ids"]
            if isinstance(booking_ids, list):
                st.markdown(
                    f"ğŸ“‹ **å¾…å–æ¶ˆçš„é¢„è®¢ID**: {', '.join(map(str, booking_ids))}"
                )
            else:
                st.markdown(f"ğŸ“‹ **å¾…å–æ¶ˆçš„é¢„è®¢ID**: {booking_ids}")

        st.warning("âš ï¸ æ­¤æ“ä½œä¸å¯æ’¤é”€")

    def render_alteration_confirmation(self, tool_args):
        """æ¸²æŸ“ä¿®æ”¹ç¡®è®¤è¯¦æƒ…"""
        st.markdown("**âœï¸ ä¿®æ”¹é¢„è®¢**")

        if "booking_id" in tool_args:
            st.markdown(f"ğŸ“‹ **é¢„è®¢ID**: {tool_args['booking_id']}")

        st.markdown("**ğŸ“ ä¿®æ”¹å†…å®¹**:")
        for key, value in tool_args.items():
            if key != "booking_id" and value is not None:
                if key == "new_room_id":
                    st.markdown(f"- **æ–°ä¼šè®®å®¤ID**: {value}")
                elif key == "new_start_time":
                    st.markdown(f"- **æ–°å¼€å§‹æ—¶é—´**: {value}")
                elif key == "new_end_time":
                    st.markdown(f"- **æ–°ç»“æŸæ—¶é—´**: {value}")

    def process_stream_events(self, events):
        """å¤„ç†æµå¼äº‹ä»¶"""
        ai_placeholder = st.empty()
        full_response = ""

        for chunk in events:
            # LangGraphæµå¼ è¾“å‡ºæ ¼å¼æ˜¯ {node_name: node_data}
            for node_name, node_data in chunk.items():
                if isinstance(node_data, dict) and "messages" in node_data:
                    messages = node_data["messages"]
                    for message in messages:
                        if isinstance(message, AIMessage):
                            if message.tool_calls:
                                # ä¸ºå·¥å…·è°ƒç”¨åˆ›å»ºçŠ¶æ€å®¹å™¨
                                for tool_call in message.tool_calls:
                                    tool_call_id = tool_call["id"]
                                    tool_name = tool_call["name"]

                                    if (
                                        tool_call_id
                                        not in st.session_state.tool_status_containers
                                    ):
                                        status_container = st.status(
                                            f"ğŸ”§ æ‰§è¡Œå·¥å…·: {tool_name}",
                                            state="running",
                                            expanded=True,
                                        )
                                        st.session_state.tool_status_containers[
                                            tool_call_id
                                        ] = status_container

                                        with status_container:
                                            st.json(tool_call["args"])
                            else:
                                # ç´¯ç§¯AIå›å¤æ–‡æœ¬
                                full_response += message.content
                                ai_placeholder.markdown(full_response + "â–Œ")

                        elif isinstance(message, ToolMessage):
                            tool_call_id = message.tool_call_id
                            if tool_call_id in st.session_state.tool_status_containers:
                                status_container = (
                                    st.session_state.tool_status_containers[
                                        tool_call_id
                                    ]
                                )
                                status_container.update(state="complete")

                                with status_container:
                                    st.success("âœ… å·¥å…·æ‰§è¡Œå®Œæˆ")
                                    if message.content:
                                        st.text(message.content)

        # æ˜¾ç¤ºæœ€ç»ˆå›å¤
        if full_response:
            ai_placeholder.markdown(full_response)

        # æ¸…ç©ºå·¥å…·çŠ¶æ€å®¹å™¨
        st.session_state.tool_status_containers = {}

    def handle_user_input(self):
        """å¤„ç†ç”¨æˆ·è¾“å…¥"""
        if user_input := st.chat_input("è¯·è¾“å…¥æ‚¨çš„éœ€æ±‚..."):
            # ç«‹å³æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
            with st.chat_message("human"):
                st.markdown(user_input)

            # å¤„ç†AIå›å¤
            with st.chat_message("assistant"):
                graph = st.session_state.graph
                config = self.get_config()

                try:
                    with st.spinner("ğŸ¤” AIæ­£åœ¨æ€è€ƒ..."):
                        # æ„å»ºè¾“å…¥çŠ¶æ€ï¼ŒåŒ…å«ç”¨æˆ·ä¿¡æ¯
                        input_state = {
                            "messages": [HumanMessage(content=user_input)],
                            "current_user_id": st.session_state.user_id,
                            "current_username": st.session_state.username,
                        }

                        # ä½¿ç”¨æµå¼è°ƒç”¨
                        events = graph.stream(
                            input_state, config, stream_mode="updates"
                        )
                        self.process_stream_events(events)

                    # åˆ·æ–°é¡µé¢ä»¥æ˜¾ç¤ºå¯èƒ½çš„æ–°ä¸­æ–­
                    st.rerun()

                except Exception as e:
                    st.error(f"âŒ å¤„ç†å¤±è´¥: {e}")

    def show(self):
        """AI-powered booking page implementation"""
        self.ui.create_header("ğŸ¤– AIä¼šè®®é¢„è®¢åŠ©æ‰‹")

        # æ£€æŸ¥ç™»å½•çŠ¶æ€
        self.check_login()

        # åˆå§‹åŒ–å›¾
        self.initialize_graph()

        # æ¸²æŸ“äººå·¥ä»‹å…¥ç¡®è®¤ - ä¼˜å…ˆæ£€æŸ¥å¹¶æ˜¾ç¤º
        self.render_hitl_confirmation()

        # æ¸²æŸ“å†å²æ¶ˆæ¯
        self.render_message_history()

        # å¤„ç†ç”¨æˆ·è¾“å…¥
        self.handle_user_input()

        # ä¾§è¾¹æ åŠŸèƒ½è¯´æ˜
        st.sidebar.markdown("### ğŸ› ï¸ åŠŸèƒ½è¯´æ˜")
        st.sidebar.markdown(
            """
        **å®‰å…¨å·¥å…·** (æ— éœ€ç¡®è®¤):
        - ğŸ” æŸ¥æ‰¾å¯ç”¨ä¼šè®®å®¤
        - ğŸ“‹ æŸ¥çœ‹æˆ‘çš„é¢„è®¢
        
        **å±é™©å·¥å…·** (éœ€è¦ç¡®è®¤):
        - ğŸ“… é¢„è®¢ä¼šè®®å®¤
        - âŒ å–æ¶ˆé¢„è®¢
        - âœï¸ ä¿®æ”¹é¢„è®¢
        """
        )

        if st.sidebar.button("ğŸ”„ é‡ç½®å¯¹è¯"):
            if "graph" in st.session_state:
                del st.session_state.graph
            if "thread_id" in st.session_state:
                del st.session_state.thread_id
            st.rerun()
