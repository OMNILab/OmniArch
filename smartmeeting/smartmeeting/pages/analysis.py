"""
PandasAI Demo Page Module
Contains the PandasAI demo page implementation for the smart meeting system
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
from datetime import datetime, timedelta
import calendar
from collections import defaultdict
import json
import os
import logging
import time
from typing import Optional, Dict, Any, Callable
from smartmeeting.tools import setup_pandasai_llm, create_pandasai_agent

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Localization dictionary for easy text management
TEXTS = {
    "header": "æ™ºèƒ½åˆ†æ",
    "ai_enabled": "âœ… AI åˆ†æå·²å¯ç”¨",
    "ai_init_failed": "âŒ AI Agentåˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•",
    "no_data": "ğŸ“­ æš‚æ— æ•°æ®ï¼Œè¯·å…ˆåˆ›å»ºä¸€äº›æ•°æ®",
    "data_overview": "#### ğŸ“Š æ•°æ®æ¦‚è§ˆ",
    "data_preview": "#### ğŸ“‹ æ•°æ®é¢„è§ˆ",
    "analysis_query": "#### ğŸ¤– æ™ºèƒ½åˆ†ææŸ¥è¯¢",
    "select_query": "è¯·é€‰æ‹©...",
    "built_in_query": "**ğŸ“ å†…ç½®æŸ¥è¯¢ï¼ˆæ¨èï¼‰**",
    "custom_query": "**âœï¸ è‡ªå®šä¹‰æŸ¥è¯¢**",
    "query_placeholder": "ä¾‹å¦‚ï¼šåˆ†æä¼šè®®æ—¶é•¿åˆ†å¸ƒã€ç»Ÿè®¡ä»»åŠ¡å®Œæˆç‡ã€æŸ¥çœ‹ç”¨æˆ·æ´»è·ƒåº¦ç­‰",
    "query_help": "ç”¨è‡ªç„¶è¯­è¨€æè¿°æ‚¨æƒ³è¦çš„åˆ†æå†…å®¹",
    "start_analysis": "ğŸš€ å¼€å§‹åˆ†æ",
    "no_query": "âš ï¸ è¯·é€‰æ‹©å†…ç½®æŸ¥è¯¢æˆ–è¾“å…¥è‡ªå®šä¹‰æŸ¥è¯¢",
    "analysis_running": "âš ï¸ åˆ†ææ­£åœ¨è¿›è¡Œä¸­ï¼Œè¯·ç¨å€™...",
    "ai_analyzing": "ğŸ¤– AIæ­£åœ¨åˆ†ææ•°æ®...",
    "ai_executing": "ğŸ¤– æ­£åœ¨æ‰§è¡ŒAIåˆ†æ...",
    "generating_visuals": "ğŸ¤– æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–...",
    "analysis_complete": "âœ… AI åˆ†æå®Œæˆï¼",
    "analysis_failed": "âŒ AI åˆ†æå¤±è´¥ï¼Œè¯·é‡è¯•",
    "ai_not_initialized": "âŒ AI Agentæœªåˆå§‹åŒ–ï¼Œè¯·è”ç³»ç®¡ç†å‘˜",
    "error_occurred": "âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {error}",
    "fallback_info": "åˆ›å»ºåŸºç¡€å¯è§†åŒ–å›¾è¡¨...",
    "no_visualizable_cols": "æ•°æ®ä¸­æ²¡æœ‰å¯ç”¨çš„æ•°å€¼æˆ–åˆ†ç±»å­—æ®µæ¥åˆ›å»ºå›¾è¡¨",
}


class AnalysisPage:
    """PandasAI demo page implementation with enhanced functionality for smart meeting system analysis"""

    def __init__(self, data_manager, auth_manager, ui_components):
        """Initialize the AnalysisPage with required components.

        Args:
            data_manager: Data manager instance for accessing data sources.
            auth_manager: Authentication manager instance.
            ui_components: UI components for rendering the interface.
        """
        self.data_manager = data_manager
        self.auth_manager = auth_manager
        self.ui = ui_components
        # Initialize session state
        if "analysis_running" not in st.session_state:
            st.session_state.analysis_running = False

    def perform_ai_analysis(
        self, query: str, sample_data: pd.DataFrame, llm: Any
    ) -> Optional[str]:
        """Perform AI-powered analysis using PandasAI with fallback to basic analysis.

        Args:
            query: User query for analysis.
            sample_data: DataFrame containing the data to analyze.
            llm: Initialized LLM instance for PandasAI.

        Returns:
            Analysis result as a string or None if both AI and basic analysis fail.
        """
        if not isinstance(sample_data, pd.DataFrame) or sample_data.empty:
            st.error("æ— æ•ˆçš„æ•°æ®é›†ï¼Œè¯·æ£€æŸ¥æ•°æ®æº")
            return None

        try:
            if llm:
                result = self._perform_pandasai_analysis(query, sample_data, llm)
                if result:
                    return result
                st.info("AIåˆ†ææ— ç»“æœï¼Œä½¿ç”¨åŸºç¡€åˆ†æ")
                return self._perform_basic_analysis(query, sample_data)
            return self._perform_basic_analysis(query, sample_data)
        except Exception as e:
            logger.error(f"AI analysis failed: {e}")
            st.error(TEXTS["error_occurred"].format(error=str(e)))
            try:
                return self._perform_basic_analysis(query, sample_data)
            except Exception as fallback_error:
                logger.error(f"Basic analysis failed: {fallback_error}")
                st.error(f"åŸºç¡€åˆ†æä¹Ÿå¤±è´¥: {fallback_error}")
                return None

    def _perform_pandasai_analysis(
        self, query: str, sample_data: pd.DataFrame, llm: Any
    ) -> Optional[str]:
        """Perform intelligent analysis using PandasAI.

        Args:
            query: User query for analysis.
            sample_data: DataFrame containing the data to analyze.
            llm: Initialized LLM instance for PandasAI.

        Returns:
            Analysis result as a string or None if analysis fails.
        """
        try:
            agent = create_pandasai_agent(sample_data, llm)
            if not agent:
                st.warning("AIæ™ºèƒ½ä½“åˆ›å»ºå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ")
                return self._perform_basic_analysis(query, sample_data)

            prompt = f"""è¯·ç”¨ä¸­æ–‡åˆ†æä»¥ä¸‹æ•°æ®ï¼š{query}

è¦æ±‚ï¼š
1. åˆ†æç»“æœå¿…é¡»ç”¨ä¸­æ–‡å±•ç¤º
2. æä¾›ç®€æ´æ˜äº†çš„æ´å¯Ÿ
3. ç”Ÿæˆ1ä¸ªæœ€ç›¸å…³çš„plotlyå›¾è¡¨
4. å›¾è¡¨æ ‡é¢˜å’Œæ ‡ç­¾ä½¿ç”¨ä¸­æ–‡
5. è¿”å›plotlyå›¾è¡¨å¯¹è±¡ï¼Œä¸ä½¿ç”¨.show()æˆ–write_html()
6. ç¤ºä¾‹ï¼š
   import plotly.express as px
   fig = px.bar(data, x='column', y='value', title='æ ‡é¢˜')
   return fig"""

            start_time = time.time()
            timeout = 60  # 60 seconds timeout
            response = agent.chat(prompt)

            if time.time() - start_time > timeout:
                st.warning("AIåˆ†æè¶…æ—¶ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ")
                return self._perform_basic_analysis(query, sample_data)

            charts_displayed = self._handle_pandasai_response(
                response, sample_data, query
            )
            if not charts_displayed:
                st.info("AIæœªç”Ÿæˆå›¾è¡¨ï¼Œåˆ›å»ºåŸºç¡€å¯è§†åŒ–")
                self._create_fallback_charts(sample_data, query)

            return str(response) if response else None

        except Exception as e:
            logger.warning(f"PandasAI analysis failed: {e}")
            st.warning(f"AIåˆ†æå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ: {e}")
            return self._perform_basic_analysis(query, sample_data)

    def _perform_basic_analysis(
        self, query: str, sample_data: pd.DataFrame
    ) -> Optional[str]:
        """Perform basic analysis when PandasAI is unavailable.

        Args:
            query: User query for analysis.
            sample_data: DataFrame containing the data to analyze.

        Returns:
            Analysis result as a string or None if analysis fails.
        """
        try:
            query_lower = query.lower()
            if any(k in query_lower for k in ["ç»Ÿè®¡", "æ¦‚è§ˆ", "ç»Ÿè®¡ä¿¡æ¯"]):
                return self._generate_statistical_analysis(sample_data)
            elif any(k in query_lower for k in ["å›¾è¡¨", "å¯è§†åŒ–", "å›¾å½¢"]):
                return self._generate_visualization_analysis(sample_data)
            elif any(k in query_lower for k in ["è¶‹åŠ¿", "å˜åŒ–"]):
                return self._generate_trend_analysis(sample_data)
            elif "åˆ†å¸ƒ" in query_lower:
                return self._generate_distribution_analysis(sample_data)
            elif any(k in query_lower for k in ["å…³è”", "å…³ç³»"]):
                return self._generate_correlation_analysis(sample_data)
            elif any(k in query_lower for k in ["æ•ˆç‡", "æ€§èƒ½"]):
                return self._generate_efficiency_analysis(sample_data)
            return self._generate_general_analysis(sample_data, query)
        except Exception as e:
            logger.error(f"Basic analysis failed: {e}")
            st.error(f"åŸºç¡€åˆ†æå¤±è´¥: {e}")
            return None

    def _generate_statistical_analysis(self, data: pd.DataFrame) -> str:
        """Generate statistical analysis in Chinese.

        Args:
            data: DataFrame to analyze.

        Returns:
            Statistical analysis as a markdown string.
        """
        analysis = "## ğŸ“Š æ•°æ®ç»Ÿè®¡åˆ†æ\n\n"
        analysis += f"- **æ€»è®°å½•æ•°**: {len(data)}\n"
        analysis += f"- **å­—æ®µæ•°**: {len(data.columns)}\n\n"

        numeric_cols = data.select_dtypes(include=["number"]).columns
        if numeric_cols.any():
            analysis += "### æ•°å€¼å‹å­—æ®µç»Ÿè®¡\n"
            stats = data[numeric_cols].describe()
            analysis += f"- æ•°å€¼å­—æ®µ: {', '.join(numeric_cols)}\n"
            analysis += f"- å¹³å‡å€¼èŒƒå›´: {stats.loc['mean'].min():.2f} - {stats.loc['mean'].max():.2f}\n"
            analysis += f"- æ ‡å‡†å·®èŒƒå›´: {stats.loc['std'].min():.2f} - {stats.loc['std'].max():.2f}\n\n"

        categorical_cols = data.select_dtypes(include=["object"]).columns
        if categorical_cols.any():
            analysis += "### åˆ†ç±»å‹å­—æ®µç»Ÿè®¡\n"
            for col in categorical_cols[:3]:
                unique_count = data[col].nunique()
                analysis += f"- **{col}**: {unique_count} ä¸ªå”¯ä¸€å€¼\n"

        return analysis

    def _generate_visualization_analysis(self, data: pd.DataFrame) -> str:
        """Generate visualization analysis suggestions in Chinese.

        Args:
            data: DataFrame to analyze.

        Returns:
            Visualization suggestions as a markdown string.
        """
        analysis = "## ğŸ“ˆ æ•°æ®å¯è§†åŒ–åˆ†æ\n\n"
        numeric_cols = data.select_dtypes(include=["number"]).columns
        categorical_cols = data.select_dtypes(include=["object"]).columns

        if numeric_cols.any():
            analysis += "### æ•°å€¼å‹æ•°æ®å¯è§†åŒ–å»ºè®®\n"
            analysis += "- ç›´æ–¹å›¾: æŸ¥çœ‹æ•°å€¼åˆ†å¸ƒ\n"
            analysis += "- ç®±çº¿å›¾: è¯†åˆ«å¼‚å¸¸å€¼\n"
            if len(numeric_cols) >= 2:
                analysis += "- æ•£ç‚¹å›¾: åˆ†æå˜é‡å…³ç³»\n"

        if categorical_cols.any():
            analysis += "\n### åˆ†ç±»å‹æ•°æ®å¯è§†åŒ–å»ºè®®\n"
            analysis += "- æŸ±çŠ¶å›¾: æ˜¾ç¤ºç±»åˆ«é¢‘æ¬¡\n"
            analysis += "- é¥¼å›¾: æ˜¾ç¤ºæ¯”ä¾‹åˆ†å¸ƒ\n"

        return analysis

    def _generate_trend_analysis(self, data: pd.DataFrame) -> str:
        """Generate trend analysis in Chinese.

        Args:
            data: DataFrame to analyze.

        Returns:
            Trend analysis as a markdown string.
        """
        analysis = "## ğŸ“ˆ è¶‹åŠ¿åˆ†æ\n\n"
        time_cols = self._find_time_columns(data)

        if time_cols:
            analysis += f"å‘ç°æ—¶é—´ç›¸å…³å­—æ®µ: {', '.join(time_cols)}\n"
            analysis += "å»ºè®®è¿›è¡Œæ—¶é—´åºåˆ—åˆ†æ:\n"
            analysis += "- æ—¶é—´è¶‹åŠ¿å›¾\n"
            analysis += "- å‘¨æœŸæ€§åˆ†æ\n"
            analysis += "- å­£èŠ‚æ€§æ¨¡å¼è¯†åˆ«\n"
        else:
            analysis += "æœªå‘ç°æ˜æ˜¾çš„æ—¶é—´å­—æ®µï¼Œå»ºè®®:\n"
            analysis += "- æ£€æŸ¥æ˜¯å¦æœ‰æ—¥æœŸ/æ—¶é—´åˆ—\n"
            analysis += "- è€ƒè™‘æ·»åŠ æ—¶é—´ç»´åº¦è¿›è¡Œåˆ†æ\n"

        return analysis

    def _generate_distribution_analysis(self, data: pd.DataFrame) -> str:
        """Generate distribution analysis in Chinese.

        Args:
            data: DataFrame to analyze.

        Returns:
            Distribution analysis as a markdown string.
        """
        analysis = "## ğŸ“Š åˆ†å¸ƒåˆ†æ\n\n"
        numeric_cols = data.select_dtypes(include=["number"]).columns
        categorical_cols = data.select_dtypes(include=["object"]).columns

        if numeric_cols.any():
            analysis += "### æ•°å€¼å‹æ•°æ®åˆ†å¸ƒ\n"
            for col in numeric_cols[:3]:
                stats = data[col].describe()
                analysis += f"- **{col}**: å‡å€¼={stats['mean']:.2f}, æ ‡å‡†å·®={stats['std']:.2f}\n"

        if categorical_cols.any():
            analysis += "\n### åˆ†ç±»å‹æ•°æ®åˆ†å¸ƒ\n"
            for col in categorical_cols[:3]:
                value_counts = data[col].value_counts()
                analysis += f"- **{col}**: æœ€å¤šå€¼='{value_counts.index[0]}' ({value_counts.iloc[0]}æ¬¡)\n"

        return analysis

    def _generate_correlation_analysis(self, data: pd.DataFrame) -> str:
        """Generate correlation analysis in Chinese.

        Args:
            data: DataFrame to analyze.

        Returns:
            Correlation analysis as a markdown string.
        """
        analysis = "## ğŸ”— å…³è”å…³ç³»åˆ†æ\n\n"
        numeric_cols = data.select_dtypes(include=["number"]).columns

        if len(numeric_cols) >= 2:
            corr_matrix = data[numeric_cols].corr()
            fig = self._create_plotly_chart(
                px.imshow,
                corr_matrix,
                title="æ•°å€¼å­—æ®µç›¸å…³æ€§çƒ­åŠ›å›¾",
                color_continuous_scale="RdBu",
                aspect="auto",
                height=500,
            )
            st.plotly_chart(fig, use_container_width=True)

            analysis += "### ç›¸å…³æ€§åˆ†æç»“æœ\n"
            analysis += f"- åˆ†æäº† {len(numeric_cols)} ä¸ªæ•°å€¼å­—æ®µä¹‹é—´çš„ç›¸å…³æ€§\n"
            strong_corr = [
                (corr_matrix.columns[i], corr_matrix.columns[j], corr_matrix.iloc[i, j])
                for i in range(len(corr_matrix.columns))
                for j in range(i + 1, len(corr_matrix.columns))
                if abs(corr_matrix.iloc[i, j]) > 0.7
            ]

            if strong_corr:
                analysis += "- **å¼ºç›¸å…³æ€§å‘ç°**:\n"
                for var1, var2, corr in strong_corr:
                    analysis += f"  - {var1} ä¸ {var2}: {corr:.3f}\n"
            else:
                analysis += "- æœªå‘ç°å¼ºç›¸å…³æ€§å…³ç³»\n"
        else:
            analysis += "æ•°å€¼å­—æ®µä¸è¶³ï¼Œæ— æ³•è¿›è¡Œç›¸å…³æ€§åˆ†æ\n"

        return analysis

    def _generate_efficiency_analysis(self, data: pd.DataFrame) -> str:
        """Generate efficiency analysis in Chinese.

        Args:
            data: DataFrame to analyze.

        Returns:
            Efficiency analysis as a markdown string.
        """
        analysis = "## âš¡ æ•ˆç‡æ€§èƒ½åˆ†æ\n\n"

        if "æ•°æ®æº" in data.columns:
            source_counts = data["æ•°æ®æº"].value_counts()
            fig = self._create_plotly_chart(
                px.bar,
                x=source_counts.index,
                y=source_counts.values,
                title="å„æ•°æ®æºè®°å½•åˆ†å¸ƒ",
                labels={"x": "æ•°æ®æº", "y": "è®°å½•æ•°"},
                color=source_counts.values,
                color_continuous_scale="viridis",
                height=400,
            )
            st.plotly_chart(fig, use_container_width=True)

            analysis += "### æ•°æ®æºæ•ˆç‡åˆ†æ\n"
            analysis += f"- æ€»è®°å½•æ•°: {len(data)}\n"
            analysis += f"- æ•°æ®æºåˆ†å¸ƒ: {', '.join([f'{k}({v})' for k, v in source_counts.items()])}\n"
            for source, count in source_counts.items():
                percentage = (count / len(data)) * 100
                analysis += f"- {source}: {count} æ¡è®°å½• ({percentage:.1f}%)\n"

        elif "æ—¶é•¿" in data.columns:
            duration_stats = data["æ—¶é•¿"].describe()
            fig = self._create_plotly_chart(
                px.histogram,
                data,
                x="æ—¶é•¿",
                title="ä¼šè®®æ—¶é•¿åˆ†å¸ƒ",
                nbins=20,
                color_discrete_sequence=["#1f77b4"],
                height=400,
            )
            st.plotly_chart(fig, use_container_width=True)

            analysis += "### ä¼šè®®æ—¶é•¿æ•ˆç‡åˆ†æ\n"
            analysis += f"- å¹³å‡æ—¶é•¿: {duration_stats['mean']:.1f} åˆ†é’Ÿ\n"
            analysis += f"- æœ€çŸ­æ—¶é•¿: {duration_stats['min']:.1f} åˆ†é’Ÿ\n"
            analysis += f"- æœ€é•¿æ—¶é•¿: {duration_stats['max']:.1f} åˆ†é’Ÿ\n"
            analysis += f"- æ—¶é•¿æ ‡å‡†å·®: {duration_stats['std']:.1f} åˆ†é’Ÿ\n"
            analysis += "- **æ•ˆç‡å»ºè®®**: " + (
                "å¹³å‡ä¼šè®®æ—¶é•¿è¾ƒé•¿ï¼Œå»ºè®®ä¼˜åŒ–ä¼šè®®æµç¨‹\n"
                if duration_stats["mean"] > 60
                else "ä¼šè®®æ—¶é•¿åˆç†ï¼Œæ•ˆç‡è‰¯å¥½\n"
            )

        elif "çŠ¶æ€" in data.columns:
            status_counts = data["çŠ¶æ€"].value_counts()
            fig = self._create_plotly_chart(
                px.pie,
                values=status_counts.values,
                names=status_counts.index,
                title="ä»»åŠ¡çŠ¶æ€åˆ†å¸ƒ",
                color_discrete_sequence=px.colors.qualitative.Set3,
                height=400,
            )
            st.plotly_chart(fig, use_container_width=True)

            total_tasks = len(data)
            completed_tasks = status_counts.get("å®Œæˆ", 0)
            completion_rate = (
                (completed_tasks / total_tasks) * 100 if total_tasks > 0 else 0
            )
            analysis += "### ä»»åŠ¡å®Œæˆæ•ˆç‡åˆ†æ\n"
            analysis += f"- æ€»ä»»åŠ¡æ•°: {total_tasks}\n"
            analysis += f"- å·²å®Œæˆä»»åŠ¡: {completed_tasks}\n"
            analysis += f"- å®Œæˆç‡: {completion_rate:.1f}%\n"
            analysis += "- **æ•ˆç‡è¯„ä¼°**: " + (
                "ä»»åŠ¡å®Œæˆç‡ä¼˜ç§€\n"
                if completion_rate >= 80
                else (
                    "ä»»åŠ¡å®Œæˆç‡è‰¯å¥½\n"
                    if completion_rate >= 60
                    else "ä»»åŠ¡å®Œæˆç‡éœ€è¦æ”¹è¿›\n"
                )
            )

        return analysis

    def _generate_general_analysis(self, data: pd.DataFrame, query: str) -> str:
        """Generate general analysis based on query.

        Args:
            data: DataFrame to analyze.
            query: User query for analysis.

        Returns:
            General analysis as a markdown string.
        """
        analysis = f"### ğŸ¤– AI åˆ†æç»“æœ\n\né’ˆå¯¹æŸ¥è¯¢: **{query}**\n\n"
        analysis += "### æ•°æ®æ´å¯Ÿ\n"
        analysis += f"- æ•°æ®é›†åŒ…å« {len(data)} æ¡è®°å½•\n"
        analysis += f"- æ¶µç›– {len(data.columns)} ä¸ªå­—æ®µ\n"

        numeric_cols = data.select_dtypes(include=["number"]).columns
        if numeric_cols.any():
            analysis += f"- åŒ…å« {len(numeric_cols)} ä¸ªæ•°å€¼å‹å­—æ®µ\n"
            st.markdown("#### ğŸ“Š æ•°å€¼å­—æ®µåˆ†å¸ƒ")
            for col in numeric_cols[:2]:
                fig = self._create_plotly_chart(
                    px.histogram, data, x=col, title=f"{col} åˆ†å¸ƒ", nbins=20
                )
                st.plotly_chart(fig, use_container_width=True)

        categorical_cols = data.select_dtypes(include=["object"]).columns
        if categorical_cols.any():
            analysis += f"- åŒ…å« {len(categorical_cols)} ä¸ªåˆ†ç±»å‹å­—æ®µ\n"
            st.markdown("#### ğŸ“ˆ åˆ†ç±»å­—æ®µåˆ†å¸ƒ")
            for col in categorical_cols[:2]:
                value_counts = data[col].value_counts()
                fig = self._create_plotly_chart(
                    px.bar,
                    x=value_counts.index,
                    y=value_counts.values,
                    title=f"{col} åˆ†å¸ƒ",
                    labels={"x": col, "y": "æ•°é‡"},
                    color=value_counts.values,
                    color_continuous_scale="viridis",
                )
                st.plotly_chart(fig, use_container_width=True)

        analysis += "\n### å»ºè®®\n"
        analysis += "- å°è¯•æ›´å…·ä½“çš„æŸ¥è¯¢ï¼Œå¦‚'æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯'æˆ–'ç”Ÿæˆå›¾è¡¨'\n"
        analysis += "- ä½¿ç”¨å†…ç½®æŸ¥è¯¢è·å–å¸¸ç”¨åˆ†æç»“æœ\n"

        return analysis

    def show(self) -> None:
        """Display the main analysis page."""
        self.ui.create_header(TEXTS["header"])

        # ä¾§è¾¹æ åŠŸèƒ½è¯´æ˜
        st.sidebar.markdown("### ğŸ” åŠŸèƒ½è¯´æ˜")
        st.sidebar.markdown(
            """
        **ğŸ“Š æ™ºèƒ½åˆ†æ**:
        - å¤šæ•°æ®æºç»¼åˆåˆ†æ
        - AIé©±åŠ¨çš„æ•°æ®æ´å¯Ÿ
        - è‡ªåŠ¨ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        - ä¸šåŠ¡æ•ˆç‡æ·±åº¦åˆ†æ
        
        **ğŸ¯ åˆ†æç±»å‹**:
        - ç»Ÿè®¡åˆ†æï¼šåŸºç¡€æ•°æ®ç»Ÿè®¡
        - è¶‹åŠ¿åˆ†æï¼šæ—¶é—´åºåˆ—åˆ†æ
        - å…³è”åˆ†æï¼šæ•°æ®å…³è”æŒ–æ˜
        - æ•ˆç‡åˆ†æï¼šä¸šåŠ¡æ•ˆç‡è¯„ä¼°
        """
        )

        llm = setup_pandasai_llm()

        if llm:
            st.success(TEXTS["ai_enabled"])
        else:
            st.error(TEXTS["ai_init_failed"])
            return

        data_sources = ["ä¼šè®®æ•°æ®", "ä»»åŠ¡æ•°æ®", "ç”¨æˆ·æ•°æ®", "ä¼šè®®å®¤æ•°æ®", "å…¨éƒ¨æ•°æ®"]
        selected_source = st.selectbox("é€‰æ‹©æ•°æ®æº", data_sources, index=0)

        sample_data = self._get_selected_data(selected_source)
        if sample_data.empty:
            st.info(TEXTS["no_data"])
            return

        self._show_data_overview(sample_data)
        self._show_data_preview(sample_data)
        self._show_analysis_interface(sample_data, llm, selected_source)

    def _get_selected_data(self, selected_source: str) -> pd.DataFrame:
        """Get data based on selected source.

        Args:
            selected_source: Selected data source name.

        Returns:
            DataFrame containing the selected data.
        """
        data_mapping = {
            "å…¨éƒ¨æ•°æ®": self._get_merged_data,
            "ä¼šè®®æ•°æ®": lambda: self.data_manager.get_dataframe("meetings"),
            "ä»»åŠ¡æ•°æ®": lambda: self.data_manager.get_dataframe("tasks"),
            "ç”¨æˆ·æ•°æ®": lambda: self.data_manager.get_dataframe("users"),
            "ä¼šè®®å®¤æ•°æ®": lambda: self.data_manager.get_dataframe("rooms"),
        }
        return data_mapping.get(selected_source, lambda: pd.DataFrame())()

    def _get_merged_data(self) -> pd.DataFrame:
        """Get merged dataset from all sources.

        Returns:
            Merged DataFrame.
        """
        meetings_df = self.data_manager.get_dataframe("meetings")
        tasks_df = self.data_manager.get_dataframe("tasks")
        users_df = self.data_manager.get_dataframe("users")
        rooms_df = self.data_manager.get_dataframe("rooms")
        return self._create_merged_dataset(meetings_df, tasks_df, users_df, rooms_df)

    def _show_data_overview(self, sample_data: pd.DataFrame) -> None:
        """Display data overview.

        Args:
            sample_data: DataFrame to display overview for.
        """
        st.markdown(TEXTS["data_overview"])
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("æ€»è®°å½•æ•°", len(sample_data))
        with col2:
            st.metric("å­—æ®µæ•°", len(sample_data.columns))
        with col3:
            st.metric(
                "æ•°å€¼å­—æ®µ", len(sample_data.select_dtypes(include=["number"]).columns)
            )
        with col4:
            st.metric(
                "åˆ†ç±»å­—æ®µ", len(sample_data.select_dtypes(include=["object"]).columns)
            )

        st.markdown("---")

    def _show_data_preview(self, sample_data: pd.DataFrame) -> None:
        """Display data preview.

        Args:
            sample_data: DataFrame to display preview for.
        """
        st.markdown(TEXTS["data_preview"])
        with st.expander("æŸ¥çœ‹æ•°æ®è¯¦æƒ…", expanded=True):
            st.dataframe(sample_data.head(8), use_container_width=True)
        st.markdown("---")

    def _show_analysis_interface(
        self, sample_data: pd.DataFrame, llm: Any, selected_source: str
    ) -> None:
        """Display analysis query interface.

        Args:
            sample_data: DataFrame to analyze.
            llm: Initialized LLM instance.
            selected_source: Selected data source.
        """
        st.markdown(TEXTS["analysis_query"])
        query = self._get_user_query(selected_source)

        if st.button(TEXTS["start_analysis"], type="primary", use_container_width=True):
            self._execute_analysis(query, sample_data, llm)

    def _get_user_query(self, selected_source: str) -> str:
        """Get user query from built-in or custom input.

        Args:
            selected_source: Selected data source.

        Returns:
            User query string.
        """
        built_in_queries = self._get_built_in_queries(selected_source)
        col1, col2 = st.columns([1, 1])

        with col1:
            st.markdown(TEXTS["built_in_query"])
            selected_built_in = st.selectbox(
                TEXTS["select_query"],
                [TEXTS["select_query"]] + list(built_in_queries.keys()),
                help=TEXTS["query_help"],
            )
            query = (
                built_in_queries.get(selected_built_in, "")
                if selected_built_in != TEXTS["select_query"]
                else ""
            )
            if query:
                st.markdown(f"**æŸ¥è¯¢å†…å®¹ï¼š** {query}")

        with col2:
            st.markdown(TEXTS["custom_query"])
            custom_query = st.text_area(
                TEXTS["custom_query"],
                placeholder=TEXTS["query_placeholder"],
                height=100,
                help=TEXTS["query_help"],
            )
            if custom_query:
                query = custom_query

        return query

    def _execute_analysis(
        self, query: str, sample_data: pd.DataFrame, llm: Any
    ) -> None:
        """Execute analysis with progress indicators.

        Args:
            query: User query for analysis.
            sample_data: DataFrame to analyze.
            llm: Initialized LLM instance.
        """
        if not query:
            st.warning(TEXTS["no_query"])
            return

        if st.session_state.analysis_running:
            st.warning(TEXTS["analysis_running"])
            return

        st.session_state.analysis_running = True
        progress_bar = st.progress(0)
        status_text = st.empty()

        try:
            status_text.text(TEXTS["ai_analyzing"])
            progress_bar.progress(25)

            if llm:
                status_text.text(TEXTS["ai_executing"])
                progress_bar.progress(50)
                analysis_result = self.perform_ai_analysis(query, sample_data, llm)
                progress_bar.progress(75)
                status_text.text(TEXTS["generating_visuals"])

                if analysis_result:
                    progress_bar.progress(100)
                    status_text.text(TEXTS["analysis_complete"])
                    progress_bar.empty()
                    status_text.empty()
                    st.success(TEXTS["analysis_complete"])
                    self._display_analysis_results(analysis_result, sample_data, query)
                else:
                    progress_bar.empty()
                    status_text.empty()
                    st.error(TEXTS["analysis_failed"])
            else:
                progress_bar.empty()
                status_text.empty()
                st.error(TEXTS["ai_not_initialized"])
        except Exception as e:
            progress_bar.empty()
            status_text.empty()
            st.error(TEXTS["error_occurred"].format(error=str(e)))
        finally:
            st.session_state.analysis_running = False

    def _display_analysis_results(
        self, analysis_result: str, sample_data: pd.DataFrame, query: str
    ) -> None:
        """Display analysis results and appropriate visualizations.

        Args:
            analysis_result: Analysis result as a string.
            sample_data: DataFrame analyzed.
            query: User query.
        """
        st.markdown(analysis_result)
        self._show_appropriate_visualizations(sample_data, query)

    def _show_appropriate_visualizations(
        self, sample_data: pd.DataFrame, query: str
    ) -> None:
        """Display visualizations based on query type.

        Args:
            sample_data: DataFrame to visualize.
            query: User query.
        """
        query_lower = query.lower()
        visualization_mapping: Dict[str, Callable] = {
            "ç»Ÿè®¡": self._show_statistical_visualizations,
            "æ¦‚è§ˆ": self._show_statistical_visualizations,
            "åˆ†å¸ƒ": self._show_statistical_visualizations,
            "åˆ†æ": self._show_statistical_visualizations,
            "æ•ˆç‡": self._show_efficiency_visualizations,
            "æ€§èƒ½": self._show_efficiency_visualizations,
            "å®Œæˆç‡": self._show_efficiency_visualizations,
            "åˆ©ç”¨ç‡": self._show_efficiency_visualizations,
            "å…³è”": self._show_correlation_visualizations,
            "å…³ç³»": self._show_correlation_visualizations,
            "ç›¸å…³æ€§": self._show_correlation_visualizations,
            "å½±å“": self._show_correlation_visualizations,
            "è¶‹åŠ¿": self._show_temporal_visualizations,
            "æ—¶é—´": self._show_temporal_visualizations,
            "æ¨¡å¼": self._show_temporal_visualizations,
            "å˜åŒ–": self._show_temporal_visualizations,
            "å¯¹æ¯”": self._show_comparison_visualizations,
            "æ¯”è¾ƒ": self._show_comparison_visualizations,
            "å·®å¼‚": self._show_comparison_visualizations,
            "æ’å": self._show_comparison_visualizations,
        }

        executed_methods = set()
        chart_count = 0
        max_charts = 2

        for keyword, method in visualization_mapping.items():
            if (
                keyword in query_lower
                and method not in executed_methods
                and chart_count < max_charts
            ):
                method(sample_data, query)
                executed_methods.add(method)
                chart_count += 1

    def _show_statistical_visualizations(
        self, sample_data: pd.DataFrame, query: str
    ) -> None:
        """Display statistical visualizations.

        Args:
            sample_data: DataFrame to visualize.
            query: User query.
        """
        st.markdown("#### ğŸ“ˆ ç»Ÿè®¡å¯è§†åŒ–")
        numeric_cols = sample_data.select_dtypes(include=["number"]).columns
        categorical_cols = sample_data.select_dtypes(include=["object"]).columns

        if numeric_cols.any():
            self._create_plotly_chart(
                px.histogram,
                sample_data,
                x=numeric_cols[0],
                title=f"{numeric_cols[0]} åˆ†å¸ƒ",
                nbins=20,
                color_discrete_sequence=["#1f77b4"],
            )
            st.plotly_chart(st.session_state.last_chart, use_container_width=True)
        elif categorical_cols.any():
            value_counts = sample_data[categorical_cols[0]].value_counts()
            self._create_plotly_chart(
                px.bar,
                x=value_counts.index,
                y=value_counts.values,
                title=f"{categorical_cols[0]} åˆ†å¸ƒ",
                labels={"x": categorical_cols[0], "y": "æ•°é‡"},
                color=value_counts.values,
                color_continuous_scale="viridis",
            )
            st.plotly_chart(st.session_state.last_chart, use_container_width=True)

    def _show_efficiency_visualizations(
        self, sample_data: pd.DataFrame, query: str
    ) -> None:
        """Display efficiency visualizations.

        Args:
            sample_data: DataFrame to visualize.
            query: User query.
        """
        st.markdown("#### âš¡ æ•ˆç‡åˆ†æå¯è§†åŒ–")
        if "æ•°æ®æº" in sample_data.columns:
            self._show_data_source_efficiency(sample_data)
        elif "æ—¶é•¿" in sample_data.columns:
            self._show_duration_efficiency(sample_data)
        elif "çŠ¶æ€" in sample_data.columns:
            self._show_status_efficiency(sample_data)
        else:
            numeric_cols = sample_data.select_dtypes(include=["number"]).columns
            if numeric_cols.any():
                self._create_plotly_chart(
                    px.histogram,
                    sample_data,
                    x=numeric_cols[0],
                    title=f"{numeric_cols[0]} æ•ˆç‡åˆ†å¸ƒ",
                    nbins=20,
                )
                st.plotly_chart(st.session_state.last_chart, use_container_width=True)

    def _show_data_source_efficiency(self, sample_data: pd.DataFrame) -> None:
        """Display data source efficiency visualization.

        Args:
            sample_data: DataFrame containing data source information.
        """
        source_efficiency = sample_data["æ•°æ®æº"].value_counts()
        self._create_plotly_chart(
            px.pie,
            values=source_efficiency.values,
            names=source_efficiency.index,
            title="å„æ•°æ®æºè®°å½•åˆ†å¸ƒ",
            color_discrete_sequence=px.colors.qualitative.Set3,
        )
        st.plotly_chart(st.session_state.last_chart, use_container_width=True)

    def _show_duration_efficiency(self, sample_data: pd.DataFrame) -> None:
        """Display duration efficiency visualization and metrics.

        Args:
            sample_data: DataFrame containing duration information.
        """
        duration_stats = sample_data["æ—¶é•¿"].describe()
        efficiency_score = min(100, max(0, 100 - (duration_stats["mean"] - 30) * 2))
        col1, col2 = st.columns(2)

        with col1:
            st.metric("å¹³å‡æ—¶é•¿", f"{duration_stats['mean']:.1f} åˆ†é’Ÿ")
            st.metric("æ•ˆç‡è¯„åˆ†", f"{efficiency_score:.1f}/100")
        with col2:
            st.metric("æœ€çŸ­æ—¶é•¿", f"{duration_stats['min']:.1f} åˆ†é’Ÿ")
            st.metric("æœ€é•¿æ—¶é•¿", f"{duration_stats['max']:.1f} åˆ†é’Ÿ")

        self._create_plotly_chart(
            px.histogram,
            sample_data,
            x="æ—¶é•¿",
            title="ä¼šè®®æ—¶é•¿åˆ†å¸ƒ",
            nbins=20,
            color_discrete_sequence=["#1f77b4"],
        )
        st.plotly_chart(st.session_state.last_chart, use_container_width=True)

    def _show_status_efficiency(self, sample_data: pd.DataFrame) -> None:
        """Display status efficiency visualization and metrics.

        Args:
            sample_data: DataFrame containing status information.
        """
        status_counts = sample_data["çŠ¶æ€"].value_counts()
        completion_rate = (status_counts.get("å®Œæˆ", 0) / len(sample_data)) * 100
        col1, col2 = st.columns(2)

        with col1:
            st.metric("æ€»ä»»åŠ¡æ•°", len(sample_data))
            st.metric("å®Œæˆç‡", f"{completion_rate:.1f}%")
        with col2:
            st.metric("å·²å®Œæˆ", status_counts.get("å®Œæˆ", 0))
            st.metric("è¿›è¡Œä¸­", status_counts.get("è¿›è¡Œä¸­", 0))

        self._create_plotly_chart(
            px.pie,
            values=status_counts.values,
            names=status_counts.index,
            title="ä»»åŠ¡çŠ¶æ€åˆ†å¸ƒ",
            color_discrete_sequence=px.colors.qualitative.Set3,
        )
        st.plotly_chart(st.session_state.last_chart, use_container_width=True)

    def _show_correlation_visualizations(
        self, sample_data: pd.DataFrame, query: str
    ) -> None:
        """Display correlation visualizations.

        Args:
            sample_data: DataFrame to visualize.
            query: User query.
        """
        st.markdown("#### ğŸ”— å…³è”å…³ç³»å¯è§†åŒ–")
        numeric_cols = sample_data.select_dtypes(include=["number"]).columns

        if len(numeric_cols) >= 2:
            self._create_plotly_chart(
                px.imshow,
                sample_data[numeric_cols].corr(),
                title="æ•°å€¼å­—æ®µç›¸å…³æ€§çƒ­åŠ›å›¾",
                color_continuous_scale="RdBu",
                aspect="auto",
                height=500,
            )
            st.plotly_chart(st.session_state.last_chart, use_container_width=True)
        else:
            categorical_cols = sample_data.select_dtypes(include=["object"]).columns
            if categorical_cols.any():
                value_counts = sample_data[categorical_cols[0]].value_counts()
                self._create_plotly_chart(
                    px.bar,
                    x=value_counts.index,
                    y=value_counts.values,
                    title=f"{categorical_cols[0]} åˆ†å¸ƒ",
                    labels={"x": categorical_cols[0], "y": "æ•°é‡"},
                )
                st.plotly_chart(st.session_state.last_chart, use_container_width=True)

    def _show_temporal_visualizations(
        self, sample_data: pd.DataFrame, query: str
    ) -> None:
        """Display temporal visualizations.

        Args:
            sample_data: DataFrame to visualize.
            query: User query.
        """
        st.markdown("#### ğŸ“… æ—¶é—´æ¨¡å¼å¯è§†åŒ–")
        time_cols = self._find_time_columns(sample_data)

        if time_cols:
            self._create_time_series_chart(sample_data, time_cols[0])
        else:
            numeric_cols = sample_data.select_dtypes(include=["number"]).columns
            if numeric_cols.any():
                self._create_plotly_chart(
                    px.histogram,
                    sample_data,
                    x=numeric_cols[0],
                    title=f"{numeric_cols[0]} åˆ†å¸ƒ",
                    nbins=20,
                )
                st.plotly_chart(st.session_state.last_chart, use_container_width=True)

    def _find_time_columns(self, data: pd.DataFrame) -> list:
        """Find time-related columns in the DataFrame.

        Args:
            data: DataFrame to analyze.

        Returns:
            List of column names that are time-related.
        """
        time_cols = []
        for col in data.columns:
            try:
                if (
                    pd.api.types.is_datetime64_any_dtype(data[col])
                    or pd.to_datetime(data[col], errors="coerce").notna().sum()
                    > len(data) * 0.5
                ):
                    time_cols.append(col)
            except Exception:
                continue
        return time_cols

    def _create_time_series_chart(self, data: pd.DataFrame, column: str) -> None:
        """Create a time series chart.

        Args:
            data: DataFrame containing the time column.
            column: Name of the time column.
        """
        try:
            time_data = pd.to_datetime(data[column], errors="coerce")
            if not time_data.isna().all():
                time_counts = time_data.dt.date.value_counts().sort_index()
                self._create_plotly_chart(
                    px.line,
                    x=time_counts.index,
                    y=time_counts.values,
                    title=f"{column} æ—¶é—´è¶‹åŠ¿",
                    labels={"x": "æ—¥æœŸ", "y": "æ•°é‡"},
                )
                st.plotly_chart(st.session_state.last_chart, use_container_width=True)
        except Exception as e:
            st.warning(f"æ— æ³•å¤„ç†æ—¶é—´å­—æ®µ {column}: {e}")

    def _show_comparison_visualizations(
        self, sample_data: pd.DataFrame, query: str
    ) -> None:
        """Display comparison visualizations.

        Args:
            sample_data: DataFrame to visualize.
            query: User query.
        """
        st.markdown("#### ğŸ“Š å¯¹æ¯”åˆ†æå¯è§†åŒ–")
        categorical_cols = sample_data.select_dtypes(include=["object"]).columns
        numeric_cols = sample_data.select_dtypes(include=["number"]).columns

        if categorical_cols.any() and numeric_cols.any():
            self._create_plotly_chart(
                px.box,
                sample_data,
                x=categorical_cols[0],
                y=numeric_cols[0],
                title=f"{categorical_cols[0]} vs {numeric_cols[0]} å¯¹æ¯”",
            )
            st.plotly_chart(st.session_state.last_chart, use_container_width=True)
        else:
            if categorical_cols.any():
                value_counts = sample_data[categorical_cols[0]].value_counts()
                self._create_plotly_chart(
                    px.bar,
                    x=value_counts.index,
                    y=value_counts.values,
                    title=f"{categorical_cols[0]} åˆ†å¸ƒ",
                    labels={"x": categorical_cols[0], "y": "æ•°é‡"},
                )
                st.plotly_chart(st.session_state.last_chart, use_container_width=True)
            elif numeric_cols.any():
                self._create_plotly_chart(
                    px.histogram,
                    sample_data,
                    x=numeric_cols[0],
                    title=f"{numeric_cols[0]} åˆ†å¸ƒ",
                    nbins=20,
                )
                st.plotly_chart(st.session_state.last_chart, use_container_width=True)

    def _create_plotly_chart(self, chart_func: Callable, *args, **kwargs) -> None:
        """Create a Plotly chart with consistent styling and store in session state.

        Args:
            chart_func: Plotly Express chart function (e.g., px.bar, px.histogram).
            *args: Positional arguments for the chart function.
            **kwargs: Keyword arguments for the chart function, including title and other configurations.
        """
        try:
            kwargs.setdefault("height", 400)
            fig = chart_func(*args, **kwargs)
            fig.update_layout(
                margin=dict(l=20, r=20, t=50, b=20),
                showlegend=True,
                font=dict(size=12),
                title_x=0.5,
            )
            st.session_state.last_chart = fig
        except Exception as e:
            logger.error(f"Failed to create Plotly chart: {e}")
            st.warning(f"åˆ›å»ºå›¾è¡¨å¤±è´¥: {e}")

    def _handle_pandasai_response(
        self, response: Any, sample_data: pd.DataFrame, query: str
    ) -> bool:
        """Handle PandasAI response and attempt to display charts.

        Args:
            response: PandasAI response object.
            sample_data: DataFrame analyzed.
            query: User query.

        Returns:
            Boolean indicating if charts were displayed.
        """
        try:
            if isinstance(response, (go.Figure, dict)) and "data" in response:
                st.plotly_chart(response, use_container_width=True)
                return True
            elif (
                isinstance(response, (list, tuple))
                and len(response) > 0
                and isinstance(response[0], go.Figure)
            ):
                st.plotly_chart(response[0], use_container_width=True)
                return True
            else:
                st.info("æœªæ£€æµ‹åˆ°å›¾è¡¨ä¿¡æ¯ï¼Œåˆ›å»ºåŸºç¡€å¯è§†åŒ–")
                self._create_fallback_charts(sample_data, query)
                return True
        except Exception as e:
            logger.warning(f"Failed to handle PandasAI response: {e}")
            st.warning(f"å¤„ç†PandasAIå“åº”å¤±è´¥: {e}")
            self._create_fallback_charts(sample_data, query)
            return True

    def _create_fallback_charts(self, sample_data: pd.DataFrame, query: str) -> None:
        """Create fallback charts when AI analysis fails.

        Args:
            sample_data: DataFrame to visualize.
            query: User query.
        """
        try:
            st.info(TEXTS["fallback_info"])
            numeric_cols = sample_data.select_dtypes(include=["number"]).columns
            categorical_cols = sample_data.select_dtypes(include=["object"]).columns

            query_lower = query.lower()
            if "æ—¶é•¿" in query_lower or "duration" in query_lower:
                if "æ—¶é•¿" in sample_data.columns:
                    self._create_plotly_chart(
                        px.histogram,
                        sample_data,
                        x="æ—¶é•¿",
                        title="ä¼šè®®æ—¶é•¿åˆ†å¸ƒ",
                        labels={"æ—¶é•¿": "æ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰", "count": "ä¼šè®®æ•°é‡"},
                        nbins=20,
                        color_discrete_sequence=["#1f77b4"],
                    )
                    st.plotly_chart(
                        st.session_state.last_chart, use_container_width=True
                    )
                elif "duration_minutes" in sample_data.columns:
                    self._create_plotly_chart(
                        px.histogram,
                        sample_data,
                        x="duration_minutes",
                        title="ä¼šè®®æ—¶é•¿åˆ†å¸ƒ",
                        labels={
                            "duration_minutes": "æ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰",
                            "count": "ä¼šè®®æ•°é‡",
                        },
                        nbins=20,
                        color_discrete_sequence=["#1f77b4"],
                    )
                    st.plotly_chart(
                        st.session_state.last_chart, use_container_width=True
                    )
                elif numeric_cols.any():
                    self._create_plotly_chart(
                        px.histogram,
                        sample_data,
                        x=numeric_cols[0],
                        title=f"{numeric_cols[0]} åˆ†å¸ƒ",
                        nbins=20,
                    )
                    st.plotly_chart(
                        st.session_state.last_chart, use_container_width=True
                    )

            elif "çŠ¶æ€" in query_lower or "status" in query_lower:
                if "çŠ¶æ€" in sample_data.columns:
                    status_counts = sample_data["çŠ¶æ€"].value_counts()
                    self._create_plotly_chart(
                        px.pie,
                        values=status_counts.values,
                        names=status_counts.index,
                        title="çŠ¶æ€åˆ†å¸ƒ",
                        color_discrete_sequence=px.colors.qualitative.Set3,
                    )
                    st.plotly_chart(
                        st.session_state.last_chart, use_container_width=True
                    )
                elif categorical_cols.any():
                    value_counts = sample_data[categorical_cols[0]].value_counts()
                    self._create_plotly_chart(
                        px.bar,
                        x=value_counts.index,
                        y=value_counts.values,
                        title=f"{categorical_cols[0]} åˆ†å¸ƒ",
                        labels={"x": categorical_cols[0], "y": "æ•°é‡"},
                    )
                    st.plotly_chart(
                        st.session_state.last_chart, use_container_width=True
                    )
            else:
                if numeric_cols.any():
                    self._create_plotly_chart(
                        px.histogram,
                        sample_data,
                        x=numeric_cols[0],
                        title=f"{numeric_cols[0]} åˆ†å¸ƒ",
                        nbins=20,
                    )
                    st.plotly_chart(
                        st.session_state.last_chart, use_container_width=True
                    )
                elif categorical_cols.any():
                    value_counts = sample_data[categorical_cols[0]].value_counts()
                    self._create_plotly_chart(
                        px.bar,
                        x=value_counts.index,
                        y=value_counts.values,
                        title=f"{categorical_cols[0]} åˆ†å¸ƒ",
                        labels={"x": categorical_cols[0], "y": "æ•°é‡"},
                    )
                    st.plotly_chart(
                        st.session_state.last_chart, use_container_width=True
                    )
                else:
                    st.warning(TEXTS["no_visualizable_cols"])
        except Exception as e:
            logger.error(f"Failed to create fallback charts: {e}")
            st.warning(f"åˆ›å»ºå¤‡ç”¨å›¾è¡¨å¤±è´¥: {e}")

    def _create_merged_dataset(
        self,
        meetings_df: pd.DataFrame,
        tasks_df: pd.DataFrame,
        users_df: pd.DataFrame,
        rooms_df: pd.DataFrame,
    ) -> pd.DataFrame:
        """Create a merged dataset from all data sources with standardized data types.

        Args:
            meetings_df: Meetings DataFrame.
            tasks_df: Tasks DataFrame.
            users_df: Users DataFrame.
            rooms_df: Rooms DataFrame.

        Returns:
            Merged DataFrame with standardized columns.
        """
        merged_data = []
        default_values = {
            "æ•°æ®æº": str,
            "è®°å½•ID": str,
            "æ ‡é¢˜": str,
            "æ—¶é•¿": float,
            "çŠ¶æ€": str,
            "åˆ›å»ºæ—¶é—´": str,
            "ä¼šè®®å®¤": str,
            "ç»„ç»‡è€…": str,
            "ç±»å‹": str,
            "ä¼˜å…ˆçº§": str,
            "æˆªæ­¢æ—¥æœŸ": str,
            "è´Ÿè´£äºº": str,
            "éƒ¨é—¨": str,
            "ç”¨æˆ·å": str,
            "å§“å": str,
            "è§’è‰²": str,
            "é‚®ç®±": str,
            "åç§°": str,
            "å®¹é‡": float,
        }

        def safe_get(row, key, default=""):
            value = row.get(key, default)
            return str(value) if value is not None else default

        if not meetings_df.empty:
            for _, meeting in meetings_df.iterrows():
                merged_data.append(
                    {
                        "æ•°æ®æº": "ä¼šè®®",
                        "è®°å½•ID": safe_get(meeting, "id"),
                        "æ ‡é¢˜": safe_get(meeting, "title"),
                        "æ—¶é•¿": float(meeting.get("duration", 0)),
                        "çŠ¶æ€": safe_get(meeting, "status"),
                        "åˆ›å»ºæ—¶é—´": safe_get(meeting, "created_datetime"),
                        "ä¼šè®®å®¤": safe_get(meeting, "room_id"),
                        "ç»„ç»‡è€…": safe_get(meeting, "organizer_id"),
                        "ç±»å‹": "ä¼šè®®è®°å½•",
                    }
                )

        if not tasks_df.empty:
            for _, task in tasks_df.iterrows():
                merged_data.append(
                    {
                        "æ•°æ®æº": "ä»»åŠ¡",
                        "è®°å½•ID": safe_get(task, "id"),
                        "æ ‡é¢˜": safe_get(task, "title"),
                        "ä¼˜å…ˆçº§": safe_get(task, "priority"),
                        "çŠ¶æ€": safe_get(task, "status"),
                        "åˆ›å»ºæ—¶é—´": safe_get(task, "created_datetime"),
                        "æˆªæ­¢æ—¥æœŸ": safe_get(task, "deadline"),
                        "è´Ÿè´£äºº": safe_get(task, "assignee_id"),
                        "éƒ¨é—¨": safe_get(task, "department"),
                        "ç±»å‹": "ä»»åŠ¡è®°å½•",
                    }
                )

        if not users_df.empty:
            for _, user in users_df.iterrows():
                merged_data.append(
                    {
                        "æ•°æ®æº": "ç”¨æˆ·",
                        "è®°å½•ID": safe_get(user, "id"),
                        "ç”¨æˆ·å": safe_get(user, "username"),
                        "å§“å": safe_get(user, "name"),
                        "éƒ¨é—¨": safe_get(user, "department"),
                        "è§’è‰²": safe_get(user, "role"),
                        "é‚®ç®±": safe_get(user, "email"),
                        "ç±»å‹": "ç”¨æˆ·è®°å½•",
                    }
                )

        if not rooms_df.empty:
            for _, room in rooms_df.iterrows():
                merged_data.append(
                    {
                        "æ•°æ®æº": "ä¼šè®®å®¤",
                        "è®°å½•ID": safe_get(room, "id"),
                        "åç§°": safe_get(room, "name"),
                        "å®¹é‡": float(room.get("capacity", 0)),
                        "çŠ¶æ€": safe_get(room, "status"),
                        "ç±»å‹": "ä¼šè®®å®¤è®°å½•",
                    }
                )

        df = pd.DataFrame(merged_data)
        for col, dtype in default_values.items():
            if col in df.columns:
                df[col] = df[col].astype(dtype)
        return df

    def _get_built_in_queries(self, data_source: str) -> Dict[str, str]:
        """Return built-in query options based on data source.

        Args:
            data_source: Selected data source.

        Returns:
            Dictionary of built-in query options.
        """
        queries = {}
        if data_source == "å…¨éƒ¨æ•°æ®":
            queries = {
                "è·¨æ•°æ®æºç»¼åˆåˆ†æ": "åˆ†ææ‰€æœ‰æ•°æ®æºçš„æ•´ä½“æƒ…å†µï¼ŒåŒ…æ‹¬å„æ•°æ®æºçš„è®°å½•æ•°é‡ã€åˆ†å¸ƒç‰¹å¾ï¼Œä»¥åŠæ•°æ®è´¨é‡è¯„ä¼°ã€‚ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨å±•ç¤ºæ•°æ®æºåˆ†å¸ƒå’Œå…³é”®æŒ‡æ ‡å¯¹æ¯”ã€‚",
                "ä¸šåŠ¡æ•ˆç‡æ·±åº¦åˆ†æ": "æ·±å…¥åˆ†æä¼šè®®æ—¶é•¿åˆ†å¸ƒã€ä»»åŠ¡å®Œæˆç‡ã€ç”¨æˆ·æ´»è·ƒåº¦ç­‰å…³é”®ä¸šåŠ¡æŒ‡æ ‡ã€‚è®¡ç®—æ•ˆç‡è¯„åˆ†ï¼Œè¯†åˆ«æ•ˆç‡ç“¶é¢ˆï¼Œå¹¶æä¾›ä¼˜åŒ–å»ºè®®ã€‚ç”Ÿæˆç›¸å…³å›¾è¡¨æ”¯æŒåˆ†æç»“æœã€‚",
                "æ•°æ®å…³è”æ€§æŒ–æ˜": "åˆ†æä¼šè®®ã€ä»»åŠ¡ã€ç”¨æˆ·ã€ä¼šè®®å®¤ä¹‹é—´çš„æ½œåœ¨å…³è”å…³ç³»ã€‚è¯†åˆ«æ•°æ®é—´çš„ä¾èµ–æ€§å’Œå½±å“å› å­ï¼Œå‘ç°ä¸šåŠ¡æ¨¡å¼ã€‚ä½¿ç”¨çƒ­åŠ›å›¾å’Œç½‘ç»œå›¾å±•ç¤ºå…³è”å¼ºåº¦ã€‚",
            }
        elif data_source == "ä¼šè®®æ•°æ®":
            queries = {
                "ä¼šè®®æ—¶é•¿åˆ†å¸ƒ": "åˆ†æä¼šè®®æ—¶é•¿çš„åˆ†å¸ƒæƒ…å†µï¼Œå±•ç¤ºä¸»è¦çš„æ—¶é•¿åŒºé—´ã€‚",
                "ä¼šè®®æ•°é‡è¶‹åŠ¿": "ç»Ÿè®¡æ¯æœˆçš„ä¼šè®®æ•°é‡å˜åŒ–è¶‹åŠ¿ã€‚",
                "ä¼šè®®å®¤ä½¿ç”¨ç»Ÿè®¡": "ç»Ÿè®¡å„ä¼šè®®å®¤çš„ä½¿ç”¨æ¬¡æ•°ã€‚",
            }
        elif data_source == "ä»»åŠ¡æ•°æ®":
            queries = {
                "ä»»åŠ¡å®Œæˆç‡ç»Ÿè®¡": "ç»Ÿè®¡ä»»åŠ¡çš„å®Œæˆæƒ…å†µï¼Œè®¡ç®—å®Œæˆç‡ã€‚",
                "ä»»åŠ¡ä¼˜å…ˆçº§åˆ†å¸ƒ": "åˆ†æä¸åŒä¼˜å…ˆçº§ä»»åŠ¡çš„åˆ†å¸ƒæƒ…å†µã€‚",
                "éƒ¨é—¨ä»»åŠ¡ç»Ÿè®¡": "ç»Ÿè®¡å„éƒ¨é—¨çš„ä»»åŠ¡åˆ†é…æƒ…å†µã€‚",
            }
        elif data_source == "ç”¨æˆ·æ•°æ®":
            queries = {
                "ç”¨æˆ·è§’è‰²åˆ†å¸ƒ": "åˆ†æç”¨æˆ·åœ¨ä¸åŒè§’è‰²çš„åˆ†å¸ƒæƒ…å†µã€‚",
                "éƒ¨é—¨äººå‘˜ç»Ÿè®¡": "ç»Ÿè®¡å„éƒ¨é—¨çš„äººå‘˜åˆ†å¸ƒæƒ…å†µã€‚",
                "ç”¨æˆ·æ´»è·ƒåº¦": "åˆ†æç”¨æˆ·çš„æ´»è·ƒç¨‹åº¦ã€‚",
            }
        elif data_source == "ä¼šè®®å®¤æ•°æ®":
            queries = {
                "ä¼šè®®å®¤å®¹é‡åˆ†å¸ƒ": "åˆ†æä¼šè®®å®¤å®¹é‡çš„åˆ†å¸ƒæƒ…å†µã€‚",
                "ä¼šè®®å®¤çŠ¶æ€ç»Ÿè®¡": "ç»Ÿè®¡ä¸åŒçŠ¶æ€ä¼šè®®å®¤çš„æ•°é‡ã€‚",
                "ä¼šè®®å®¤ä½¿ç”¨ç‡": "åˆ†æä¼šè®®å®¤çš„ä½¿ç”¨æ•ˆç‡ã€‚",
            }
        return queries
