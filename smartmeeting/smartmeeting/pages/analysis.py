"""
PandasAI Demo Page Module
Contains the PandasAI demo page implementation for the smart meeting system
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from typing import Optional, Dict, Any, Callable, List
from datetime import datetime
import time
import logging
import re
from smartmeeting.llm import setup_pandasai_llm, create_pandasai_agent

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Localization dictionary for easy text management
TEXTS = {
    "header": "æ™ºèƒ½åˆ†æ",
    "ai_enabled": "âœ… AI åˆ†æå·²å¯ç”¨",
    "ai_init_failed": "âŒ AI Agentåˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•",
    "no_data": "ğŸ“­ æš‚æ— æ•°æ®ï¼Œè¯·å…ˆåˆ›å»ºä¸€äº›æ•°æ®",
    "data_overview": "#### ğŸ“Š æ•°æ®æ¦‚è§ˆ",
    "data_preview": "#### ğŸ“‹ æ•°æ®é¢„è§ˆ",
    "analysis_query": "#### ğŸ¤– æ™ºèƒ½åˆ†ææŸ¥è¯¢",
    "select_query": "è¯·é€‰æ‹©...",
    "built_in_query": "**ğŸ“ å†…ç½®æŸ¥è¯¢ï¼ˆæ¨èï¼‰**",
    "custom_query": "**âœï¸ è‡ªå®šä¹‰æŸ¥è¯¢**",
    "query_placeholder": "ä¾‹å¦‚ï¼šåˆ†æä¼šè®®æ—¶é•¿åˆ†å¸ƒã€ç»Ÿè®¡ä»»åŠ¡å®Œæˆç‡ã€æŸ¥çœ‹ç”¨æˆ·æ´»è·ƒåº¦ç­‰",
    "query_help": "ç”¨è‡ªç„¶è¯­è¨€æè¿°æ‚¨æƒ³è¦çš„åˆ†æå†…å®¹",
    "start_analysis": "ğŸš€ å¼€å§‹åˆ†æ",
    "no_query": "âš ï¸ è¯·é€‰æ‹©å†…ç½®æŸ¥è¯¢æˆ–è¾“å…¥è‡ªå®šä¹‰æŸ¥è¯¢",
    "analysis_running": "âš ï¸ åˆ†ææ­£åœ¨è¿›è¡Œä¸­ï¼Œè¯·ç¨å€™...",
    "ai_analyzing": "ğŸ¤– AIæ­£åœ¨åˆ†ææ•°æ®...",
    "ai_executing": "ğŸ¤– æ­£åœ¨æ‰§è¡ŒAIåˆ†æ...",
    "generating_visuals": "ğŸ¤– æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–...",
    "analysis_complete": "âœ… AI åˆ†æå®Œæˆï¼",
    "analysis_failed": "âŒ AI åˆ†æå¤±è´¥ï¼Œè¯·é‡è¯•",
    "ai_not_initialized": "âŒ AI Agentæœªåˆå§‹åŒ–ï¼Œè¯·è”ç³»ç®¡ç†å‘˜",
    "error_occurred": "âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {error}",
    "fallback_info": "åˆ›å»ºåŸºç¡€å¯è§†åŒ–å›¾è¡¨...",
    "no_visualizable_cols": "æ•°æ®ä¸­æ²¡æœ‰å¯ç”¨çš„æ•°å€¼æˆ–åˆ†ç±»å­—æ®µæ¥åˆ›å»ºå›¾è¡¨",
    "plotly_chart_created": "ğŸ“Š å·²ç”Ÿæˆäº¤äº’å¼å›¾è¡¨",
    "analysis_insights": "#### ğŸ” åˆ†ææ´å¯Ÿ",
    "chart_generation_failed": "âš ï¸ å›¾è¡¨ç”Ÿæˆå¤±è´¥ï¼Œæ˜¾ç¤ºåŸºç¡€ç»Ÿè®¡ä¿¡æ¯",
    "no_charts_generated": "âš ï¸ æœªç”Ÿæˆå›¾è¡¨ï¼Œä½¿ç”¨å¤‡ç”¨å¯è§†åŒ–æ–¹æ¡ˆ",
}


class AnalysisPage:
    """PandasAI demo page implementation with enhanced functionality for smart meeting system analysis"""

    def __init__(self, data_manager, auth_manager, ui_components):
        """Initialize the AnalysisPage with required components.

        Args:
            data_manager: Data manager instance for accessing data sources.
            auth_manager: Authentication manager instance.
            ui_components: UI components for rendering the interface.
        """
        self.data_manager = data_manager
        self.auth_manager = auth_manager
        self.ui = ui_components
        # Initialize session state
        if "analysis_running" not in st.session_state:
            st.session_state.analysis_running = False
        if "last_charts" not in st.session_state:
            st.session_state.last_charts = []

    def perform_ai_analysis(
        self, query: str, sample_data: pd.DataFrame, llm: Any
    ) -> Optional[str]:
        """Perform AI-powered analysis using PandasAI with enhanced error handling and Plotly integration.

        Args:
            query: User query for analysis.
            sample_data: DataFrame containing the data to analyze.
            llm: Initialized LLM instance for PandasAI.

        Returns:
            Analysis result as a string or None if both AI and basic analysis fail.
        """
        if not isinstance(sample_data, pd.DataFrame) or sample_data.empty:
            st.error("æ— æ•ˆçš„æ•°æ®é›†ï¼Œè¯·æ£€æŸ¥æ•°æ®æº")
            return None

        try:
            if llm:
                result = self._perform_enhanced_pandasai_analysis(query, sample_data, llm)
                if result:
                    return result
                st.info("AIåˆ†ææ— ç»“æœï¼Œä½¿ç”¨åŸºç¡€åˆ†æ")
                return self._perform_basic_analysis(query, sample_data)
            return self._perform_basic_analysis(query, sample_data)
        except Exception as e:
            logger.error(f"AI analysis failed: {e}")
            st.error(TEXTS["error_occurred"].format(error=str(e)))
            try:
                return self._perform_basic_analysis(query, sample_data)
            except Exception as fallback_error:
                logger.error(f"Basic analysis failed: {fallback_error}")
                st.error(f"åŸºç¡€åˆ†æä¹Ÿå¤±è´¥: {fallback_error}")
                return None

    def _perform_enhanced_pandasai_analysis(
        self, query: str, sample_data: pd.DataFrame, llm: Any
    ) -> Optional[str]:
        """Perform intelligent analysis using PandasAI with enhanced Plotly integration and error handling.

        Args:
            query: User query for analysis.
            sample_data: DataFrame containing the data to analyze.
            llm: Initialized LLM instance for PandasAI.

        Returns:
            Analysis result as a string or None if analysis fails.
        """
        try:
            agent = create_pandasai_agent(sample_data, llm)
            if not agent:
                st.warning("AIæ™ºèƒ½ä½“åˆ›å»ºå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ")
                return self._perform_basic_analysis(query, sample_data)

            # Enhanced prompt with strict Plotly requirements
            enhanced_prompt = f"""è¯·ç”¨ä¸­æ–‡åˆ†æä»¥ä¸‹æ•°æ®ï¼š{query}

ä¸¥æ ¼è¦æ±‚ï¼š
1. åˆ†æç»“æœå¿…é¡»ç”¨ä¸­æ–‡å±•ç¤º
2. æä¾›ç®€æ´æ˜äº†çš„æ´å¯Ÿå’Œç»“è®º
3. å¿…é¡»ç”Ÿæˆ1-2ä¸ªæœ€ç›¸å…³çš„plotlyå›¾è¡¨
4. å›¾è¡¨æ ‡é¢˜ã€è½´æ ‡ç­¾ã€å›¾ä¾‹å¿…é¡»ä½¿ç”¨ä¸­æ–‡
5. ä¸¥æ ¼ä½¿ç”¨plotly.expressæˆ–plotly.graph_objectsåˆ›å»ºå›¾è¡¨
6. ç»å¯¹ä¸è¦ä½¿ç”¨matplotlibã€seabornæˆ–å…¶ä»–åº“
7. ä¸è¦ä½¿ç”¨.show()ã€write_html()æˆ–save()æ–¹æ³•
8. ç›´æ¥è¿”å›plotlyå›¾è¡¨å¯¹è±¡
9. ç¡®ä¿å›¾è¡¨å…·æœ‰äº¤äº’æ€§å’Œç¾è§‚æ€§

æ•°æ®åˆ—ä¿¡æ¯ï¼š
{list(sample_data.columns)}

ç¤ºä¾‹ä»£ç æ ¼å¼ï¼š
import plotly.express as px
import plotly.graph_objects as go

# åˆ›å»ºå›¾è¡¨
fig = px.bar(data, x='åˆ—å', y='åˆ—å', title='ä¸­æ–‡æ ‡é¢˜')
fig.update_layout(
    title_x=0.5,
    font=dict(size=12),
    showlegend=True
)
return fig

è¯·æ ¹æ®æŸ¥è¯¢å†…å®¹ç”Ÿæˆç›¸åº”çš„åˆ†æç»“æœå’Œå›¾è¡¨ã€‚"""

            start_time = time.time()
            timeout = 90  # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°90ç§’
            
            with st.spinner(TEXTS["ai_analyzing"]):
                response = agent.chat(enhanced_prompt)

            if time.time() - start_time > timeout:
                st.warning("AIåˆ†æè¶…æ—¶ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ")
                return self._perform_basic_analysis(query, sample_data)

            # Enhanced response handling
            charts_displayed = self._handle_enhanced_pandasai_response(
                response, sample_data, query
            )
            
            if not charts_displayed:
                st.info(TEXTS["no_charts_generated"])
                self._create_enhanced_fallback_charts(sample_data, query)

            return self._extract_text_analysis(response) if response else None

        except Exception as e:
            logger.warning(f"Enhanced PandasAI analysis failed: {e}")
            st.warning(f"AIåˆ†æå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ: {e}")
            return self._perform_basic_analysis(query, sample_data)

    def _perform_basic_analysis(
        self, query: str, sample_data: pd.DataFrame
    ) -> Optional[str]:
        """Perform basic analysis when PandasAI is unavailable with enhanced Plotly integration.

        Args:
            query: User query for analysis.
            sample_data: DataFrame containing the data to analyze.

        Returns:
            Analysis result as a string or None if analysis fails.
        """
        try:
            # Create appropriate charts based on query
            self._create_smart_fallback_chart(sample_data, query)
            
            query_lower = query.lower()
            if any(k in query_lower for k in ["ç»Ÿè®¡", "æ¦‚è§ˆ", "ç»Ÿè®¡ä¿¡æ¯"]):
                return self._generate_enhanced_statistical_analysis(sample_data)
            elif any(k in query_lower for k in ["å›¾è¡¨", "å¯è§†åŒ–", "å›¾å½¢"]):
                return self._generate_enhanced_visualization_analysis(sample_data)
            elif any(k in query_lower for k in ["è¶‹åŠ¿", "å˜åŒ–"]):
                return self._generate_enhanced_trend_analysis(sample_data)
            elif "åˆ†å¸ƒ" in query_lower:
                return self._generate_enhanced_distribution_analysis(sample_data)
            elif any(k in query_lower for k in ["å…³è”", "å…³ç³»"]):
                return self._generate_enhanced_correlation_analysis(sample_data)
            elif any(k in query_lower for k in ["æ•ˆç‡", "æ€§èƒ½"]):
                return self._generate_enhanced_efficiency_analysis(sample_data)
            return self._generate_enhanced_general_analysis(sample_data, query)
        except Exception as e:
            logger.error(f"Basic analysis failed: {e}")
            st.error(f"åŸºç¡€åˆ†æå¤±è´¥: {e}")
            return None

    def _generate_enhanced_statistical_analysis(self, data: pd.DataFrame) -> str:
        """Generate enhanced statistical analysis in Chinese with better insights.

        Args:
            data: DataFrame to analyze.

        Returns:
            Enhanced statistical analysis as a markdown string.
        """
        analysis = "## ğŸ“Š æ•°æ®ç»Ÿè®¡åˆ†æ\n\n"
        analysis += f"- **æ€»è®°å½•æ•°**: {len(data):,}\n"
        analysis += f"- **å­—æ®µæ•°**: {len(data.columns)}\n"
        analysis += f"- **æ•°æ®å®Œæ•´æ€§**: {((data.count().sum() / (len(data) * len(data.columns))) * 100):.1f}%\n\n"

        numeric_cols = data.select_dtypes(include=["number"]).columns
        if numeric_cols.any():
            analysis += "### ğŸ“ˆ æ•°å€¼å‹å­—æ®µç»Ÿè®¡\n"
            stats = data[numeric_cols].describe()
            analysis += f"- **æ•°å€¼å­—æ®µ**: {', '.join(numeric_cols)}\n"
            analysis += f"- **å¹³å‡å€¼èŒƒå›´**: {stats.loc['mean'].min():.2f} - {stats.loc['mean'].max():.2f}\n"
            analysis += f"- **æ ‡å‡†å·®èŒƒå›´**: {stats.loc['std'].min():.2f} - {stats.loc['std'].max():.2f}\n"
            analysis += f"- **æ•°æ®èŒƒå›´**: {stats.loc['min'].min():.2f} - {stats.loc['max'].max():.2f}\n\n"

        categorical_cols = data.select_dtypes(include=["object"]).columns
        if categorical_cols.any():
            analysis += "### ğŸ“‹ åˆ†ç±»å‹å­—æ®µç»Ÿè®¡\n"
            for col in categorical_cols[:5]:  # Show more columns
                unique_count = data[col].nunique()
                null_count = data[col].isnull().sum()
                analysis += f"- **{col}**: {unique_count} ä¸ªå”¯ä¸€å€¼"
                if null_count > 0:
                    analysis += f" (ç¼ºå¤±å€¼: {null_count})"
                analysis += "\n"

        # Add data quality insights
        analysis += "\n### ğŸ” æ•°æ®è´¨é‡æ´å¯Ÿ\n"
        total_cells = len(data) * len(data.columns)
        missing_cells = data.isnull().sum().sum()
        completeness = ((total_cells - missing_cells) / total_cells) * 100
        analysis += f"- **æ•°æ®å®Œæ•´æ€§**: {completeness:.1f}%\n"
        analysis += f"- **ç¼ºå¤±å€¼æ€»æ•°**: {missing_cells:,}\n"
        
        if missing_cells > 0:
            missing_cols = data.columns[data.isnull().any()].tolist()
            analysis += f"- **åŒ…å«ç¼ºå¤±å€¼çš„å­—æ®µ**: {', '.join(missing_cols[:3])}\n"

        return analysis

    def _generate_statistical_analysis(self, data: pd.DataFrame) -> str:
        """Generate statistical analysis in Chinese (legacy method for backward compatibility).

        Args:
            data: DataFrame to analyze.

        Returns:
            Statistical analysis as a markdown string.
        """
        return self._generate_enhanced_statistical_analysis(data)

    def _generate_enhanced_visualization_analysis(self, data: pd.DataFrame) -> str:
        """Generate enhanced visualization analysis suggestions in Chinese.

        Args:
            data: DataFrame to analyze.

        Returns:
            Enhanced visualization suggestions as a markdown string.
        """
        analysis = "## ğŸ“ˆ æ•°æ®å¯è§†åŒ–åˆ†æ\n\n"
        numeric_cols = data.select_dtypes(include=["number"]).columns
        categorical_cols = data.select_dtypes(include=["object"]).columns

        if numeric_cols.any():
            analysis += "### ğŸ“Š æ•°å€¼å‹æ•°æ®å¯è§†åŒ–å»ºè®®\n"
            analysis += "- **ç›´æ–¹å›¾**: æŸ¥çœ‹æ•°å€¼åˆ†å¸ƒå’Œé›†ä¸­è¶‹åŠ¿\n"
            analysis += "- **ç®±çº¿å›¾**: è¯†åˆ«å¼‚å¸¸å€¼å’Œæ•°æ®åˆ†å¸ƒç‰¹å¾\n"
            analysis += "- **å¯†åº¦å›¾**: äº†è§£æ•°æ®åˆ†å¸ƒå½¢çŠ¶\n"
            if len(numeric_cols) >= 2:
                analysis += "- **æ•£ç‚¹å›¾**: åˆ†æå˜é‡é—´çš„ç›¸å…³æ€§\n"
                analysis += "- **çƒ­åŠ›å›¾**: å±•ç¤ºå¤šå˜é‡ç›¸å…³æ€§çŸ©é˜µ\n"

        if categorical_cols.any():
            analysis += "\n### ğŸ“‹ åˆ†ç±»å‹æ•°æ®å¯è§†åŒ–å»ºè®®\n"
            analysis += "- **æŸ±çŠ¶å›¾**: æ˜¾ç¤ºç±»åˆ«é¢‘æ¬¡å’Œæ’åº\n"
            analysis += "- **é¥¼å›¾**: æ˜¾ç¤ºæ¯”ä¾‹åˆ†å¸ƒå’Œå æ¯”\n"
            analysis += "- **æ¡å½¢å›¾**: é€‚åˆç±»åˆ«è¾ƒå¤šçš„æ•°æ®\n"

        # Add specific recommendations based on data content
        analysis += "\n### ğŸ¯ é’ˆå¯¹æ€§å»ºè®®\n"
        if "æ—¶é•¿" in data.columns or "duration" in data.columns:
            analysis += "- **æ—¶é•¿åˆ†æ**: å»ºè®®ä½¿ç”¨ç›´æ–¹å›¾æŸ¥çœ‹æ—¶é•¿åˆ†å¸ƒ\n"
        if "çŠ¶æ€" in data.columns or "status" in data.columns:
            analysis += "- **çŠ¶æ€åˆ†æ**: å»ºè®®ä½¿ç”¨é¥¼å›¾æˆ–æŸ±çŠ¶å›¾æŸ¥çœ‹çŠ¶æ€åˆ†å¸ƒ\n"
        if "æ—¶é—´" in data.columns or "date" in data.columns:
            analysis += "- **æ—¶é—´åˆ†æ**: å»ºè®®ä½¿ç”¨æŠ˜çº¿å›¾æŸ¥çœ‹è¶‹åŠ¿å˜åŒ–\n"

        return analysis

    def _generate_visualization_analysis(self, data: pd.DataFrame) -> str:
        """Generate visualization analysis suggestions in Chinese (legacy method for backward compatibility).

        Args:
            data: DataFrame to analyze.

        Returns:
            Visualization suggestions as a markdown string.
        """
        return self._generate_enhanced_visualization_analysis(data)

    def _generate_enhanced_trend_analysis(self, data: pd.DataFrame) -> str:
        """Generate enhanced trend analysis in Chinese.

        Args:
            data: DataFrame to analyze.

        Returns:
            Enhanced trend analysis as a markdown string.
        """
        analysis = "## ğŸ“ˆ è¶‹åŠ¿åˆ†æ\n\n"
        time_columns = self._find_time_columns(data)
        
        if time_columns:
            analysis += f"### ğŸ•’ å‘ç°æ—¶é—´ç›¸å…³å­—æ®µ\n"
            analysis += f"- **æ—¶é—´å­—æ®µ**: {', '.join(time_columns)}\n\n"
            
            # Analyze the first time column
            time_col = time_columns[0]
            try:
                data[time_col] = pd.to_datetime(data[time_col], errors='coerce')
                data_filtered = data.dropna(subset=[time_col])
                
                if not data_filtered.empty:
                    # Calculate time range
                    min_date = data_filtered[time_col].min()
                    max_date = data_filtered[time_col].max()
                    date_range = (max_date - min_date).days
                    
                    analysis += f"### ğŸ“… æ—¶é—´èŒƒå›´åˆ†æ\n"
                    analysis += f"- **å¼€å§‹æ—¶é—´**: {min_date.strftime('%Y-%m-%d')}\n"
                    analysis += f"- **ç»“æŸæ—¶é—´**: {max_date.strftime('%Y-%m-%d')}\n"
                    analysis += f"- **æ—¶é—´è·¨åº¦**: {date_range} å¤©\n"
                    
                    # Monthly trend
                    monthly_counts = data_filtered.groupby(data_filtered[time_col].dt.to_period('M')).size()
                    analysis += f"- **æœˆåº¦è®°å½•æ•°**: {monthly_counts.mean():.1f} æ¡/æœˆ\n"
                    
                    # Trend direction
                    if len(monthly_counts) > 1:
                        trend = "ä¸Šå‡" if monthly_counts.iloc[-1] > monthly_counts.iloc[0] else "ä¸‹é™"
                        analysis += f"- **æ•´ä½“è¶‹åŠ¿**: {trend}\n"
                    
                    analysis += "\n### ğŸ’¡ è¶‹åŠ¿åˆ†æå»ºè®®\n"
                    analysis += "- ä½¿ç”¨æŠ˜çº¿å›¾æŸ¥çœ‹æ—¶é—´åºåˆ—å˜åŒ–\n"
                    analysis += "- åˆ†æå­£èŠ‚æ€§æ¨¡å¼å’Œå‘¨æœŸæ€§å˜åŒ–\n"
                    analysis += "- è¯†åˆ«å¼‚å¸¸æ—¶é—´ç‚¹å’Œè¶‹åŠ¿è½¬æŠ˜ç‚¹\n"
                else:
                    analysis += "âš ï¸ æ—¶é—´æ•°æ®æ ¼å¼å¼‚å¸¸ï¼Œæ— æ³•è¿›è¡Œè¯¦ç»†åˆ†æã€‚\n"
            except Exception as e:
                analysis += f"âš ï¸ æ—¶é—´æ•°æ®å¤„ç†å¤±è´¥: {str(e)}\n"
        else:
            analysis += "### âš ï¸ æœªå‘ç°æ—¶é—´å­—æ®µ\n"
            analysis += "å½“å‰æ•°æ®ä¸­æ²¡æœ‰æ˜æ˜¾çš„æ—¶é—´ç›¸å…³å­—æ®µï¼Œæ— æ³•è¿›è¡Œè¶‹åŠ¿åˆ†æã€‚\n"
            analysis += "å»ºè®®æ£€æŸ¥æ•°æ®ä¸­æ˜¯å¦åŒ…å«æ—¥æœŸã€æ—¶é—´æˆ³ç­‰æ—¶é—´ä¿¡æ¯ã€‚\n"
            
        return analysis

    def _generate_trend_analysis(self, data: pd.DataFrame) -> str:
        """Generate trend analysis in Chinese (legacy method for backward compatibility).

        Args:
            data: DataFrame to analyze.

        Returns:
            Trend analysis as a markdown string.
        """
        return self._generate_enhanced_trend_analysis(data)

    def _generate_enhanced_distribution_analysis(self, data: pd.DataFrame) -> str:
        """Generate enhanced distribution analysis in Chinese.

        Args:
            data: DataFrame to analyze.

        Returns:
            Enhanced distribution analysis as a markdown string.
        """
        analysis = "## ğŸ“Š åˆ†å¸ƒåˆ†æ\n\n"
        numeric_cols = data.select_dtypes(include=["number"]).columns
        categorical_cols = data.select_dtypes(include=["object"]).columns

        if numeric_cols.any():
            analysis += "### ğŸ“ˆ æ•°å€¼å‹æ•°æ®åˆ†å¸ƒ\n"
            for col in numeric_cols[:5]:  # Show more columns
                stats = data[col].describe()
                null_count = data[col].isnull().sum()
                analysis += f"- **{col}**:\n"
                analysis += f"  - å‡å€¼: {stats['mean']:.2f}\n"
                analysis += f"  - æ ‡å‡†å·®: {stats['std']:.2f}\n"
                analysis += f"  - æœ€å°å€¼: {stats['min']:.2f}\n"
                analysis += f"  - æœ€å¤§å€¼: {stats['max']:.2f}\n"
                if null_count > 0:
                    analysis += f"  - ç¼ºå¤±å€¼: {null_count}\n"
                analysis += "\n"

        if categorical_cols.any():
            analysis += "### ğŸ“‹ åˆ†ç±»å‹æ•°æ®åˆ†å¸ƒ\n"
            for col in categorical_cols[:5]:  # Show more columns
                value_counts = data[col].value_counts()
                null_count = data[col].isnull().sum()
                analysis += f"- **{col}**:\n"
                analysis += f"  - æœ€å¤šå€¼: '{value_counts.index[0]}' ({value_counts.iloc[0]}æ¬¡, {value_counts.iloc[0]/len(data)*100:.1f}%)\n"
                analysis += f"  - å”¯ä¸€å€¼æ•°é‡: {len(value_counts)}\n"
                if null_count > 0:
                    analysis += f"  - ç¼ºå¤±å€¼: {null_count}\n"
                analysis += "\n"

        # Add distribution insights
        analysis += "### ğŸ” åˆ†å¸ƒç‰¹å¾æ´å¯Ÿ\n"
        if numeric_cols.any():
            # Check for skewness
            for col in numeric_cols[:3]:
                skewness = data[col].skew()
                if abs(skewness) > 1:
                    skew_type = "å³å" if skewness > 0 else "å·¦å"
                    analysis += f"- **{col}**: åˆ†å¸ƒ{skew_type} (ååº¦: {skewness:.2f})\n"
                else:
                    analysis += f"- **{col}**: åˆ†å¸ƒç›¸å¯¹å¯¹ç§° (ååº¦: {skewness:.2f})\n"

        if categorical_cols.any():
            # Check for balanced distribution
            for col in categorical_cols[:3]:
                value_counts = data[col].value_counts()
                if len(value_counts) <= 5:  # Only for small number of categories
                    max_ratio = value_counts.iloc[0] / value_counts.iloc[-1]
                    if max_ratio > 5:
                        analysis += f"- **{col}**: åˆ†å¸ƒä¸å‡è¡¡ï¼Œä¸»è¦ç±»åˆ«å æ¯”è¿‡é«˜\n"
                    else:
                        analysis += f"- **{col}**: åˆ†å¸ƒç›¸å¯¹å‡è¡¡\n"

        return analysis

    def _generate_distribution_analysis(self, data: pd.DataFrame) -> str:
        """Generate distribution analysis in Chinese (legacy method for backward compatibility).

        Args:
            data: DataFrame to analyze.

        Returns:
            Distribution analysis as a markdown string.
        """
        return self._generate_enhanced_distribution_analysis(data)

    def _generate_enhanced_correlation_analysis(self, data: pd.DataFrame) -> str:
        """Generate enhanced correlation analysis in Chinese.

        Args:
            data: DataFrame to analyze.

        Returns:
            Enhanced correlation analysis as a markdown string.
        """
        analysis = "## ğŸ”— å…³è”å…³ç³»åˆ†æ\n\n"
        numeric_cols = data.select_dtypes(include=["number"]).columns

        if len(numeric_cols) >= 2:
            # Create correlation matrix
            corr_matrix = data[numeric_cols].corr()
            
            # Create heatmap using the new display method
            fig = px.imshow(
                corr_matrix,
                title="æ•°å€¼å­—æ®µç›¸å…³æ€§çƒ­åŠ›å›¾",
                color_continuous_scale="RdBu",
                aspect="auto",
                height=500,
            )
            fig.update_layout(
                title_x=0.5,
                font=dict(size=12),
                showlegend=True
            )
            self._display_plotly_chart(fig, "ç›¸å…³æ€§çƒ­åŠ›å›¾")

            analysis += "### ğŸ“Š ç›¸å…³æ€§åˆ†æç»“æœ\n"
            analysis += f"- **åˆ†æå­—æ®µ**: {len(numeric_cols)} ä¸ªæ•°å€¼å­—æ®µ\n"
            analysis += f"- **ç›¸å…³æ€§çŸ©é˜µ**: {len(numeric_cols)}Ã—{len(numeric_cols)} çŸ©é˜µ\n\n"
            
            # Find strong correlations
            strong_corr = []
            moderate_corr = []
            
            for i in range(len(corr_matrix.columns)):
                for j in range(i + 1, len(corr_matrix.columns)):
                    corr_value = corr_matrix.iloc[i, j]
                    var1, var2 = corr_matrix.columns[i], corr_matrix.columns[j]
                    
                    if abs(corr_value) > 0.7:
                        strong_corr.append((var1, var2, corr_value))
                    elif abs(corr_value) > 0.3:
                        moderate_corr.append((var1, var2, corr_value))

            if strong_corr:
                analysis += "### ğŸ”¥ å¼ºç›¸å…³æ€§å‘ç°\n"
                for var1, var2, corr in strong_corr:
                    direction = "æ­£ç›¸å…³" if corr > 0 else "è´Ÿç›¸å…³"
                    analysis += f"- **{var1}** ä¸ **{var2}**: {corr:.3f} ({direction})\n"
                analysis += "\n"

            if moderate_corr:
                analysis += "### ğŸ”¶ ä¸­ç­‰ç›¸å…³æ€§å‘ç°\n"
                for var1, var2, corr in moderate_corr[:5]:  # Limit to top 5
                    direction = "æ­£ç›¸å…³" if corr > 0 else "è´Ÿç›¸å…³"
                    analysis += f"- **{var1}** ä¸ **{var2}**: {corr:.3f} ({direction})\n"
                analysis += "\n"

            if not strong_corr and not moderate_corr:
                analysis += "### â„¹ï¸ ç›¸å…³æ€§åˆ†æç»“æœ\n"
                analysis += "- æœªå‘ç°æ˜æ˜¾çš„ç›¸å…³æ€§å…³ç³»\n"
                analysis += "- å„æ•°å€¼å­—æ®µç›¸å¯¹ç‹¬ç«‹\n"

            # Add insights
            analysis += "### ğŸ’¡ ç›¸å…³æ€§åˆ†ææ´å¯Ÿ\n"
            if strong_corr:
                analysis += "- å­˜åœ¨å¼ºç›¸å…³æ€§ï¼Œå»ºè®®è¿›ä¸€æ­¥åˆ†æå› æœå…³ç³»\n"
                analysis += "- å¯è€ƒè™‘ç‰¹å¾é€‰æ‹©æˆ–é™ç»´å¤„ç†\n"
            elif moderate_corr:
                analysis += "- å­˜åœ¨ä¸­ç­‰ç›¸å…³æ€§ï¼Œå¯è¿›è¡Œåˆ†ç»„åˆ†æ\n"
            else:
                analysis += "- å­—æ®µé—´ç‹¬ç«‹æ€§è¾ƒå¥½ï¼Œé€‚åˆè¿›è¡Œå¤šå˜é‡åˆ†æ\n"
                
        else:
            analysis += "### âš ï¸ æ•°å€¼å­—æ®µä¸è¶³\n"
            analysis += "å½“å‰æ•°æ®ä¸­æ•°å€¼å­—æ®µå°‘äº2ä¸ªï¼Œæ— æ³•è¿›è¡Œç›¸å…³æ€§åˆ†æã€‚\n"
            analysis += "å»ºè®®æ£€æŸ¥æ•°æ®ä¸­æ˜¯å¦åŒ…å«è¶³å¤Ÿçš„æ•°å€¼å‹å­—æ®µã€‚\n"

        return analysis

    def _generate_correlation_analysis(self, data: pd.DataFrame) -> str:
        """Generate correlation analysis in Chinese (legacy method for backward compatibility).

        Args:
            data: DataFrame to analyze.

        Returns:
            Correlation analysis as a markdown string.
        """
        return self._generate_enhanced_correlation_analysis(data)

    def _generate_efficiency_analysis(self, data: pd.DataFrame) -> str:
        """Generate efficiency analysis in Chinese.

        Args:
            data: DataFrame to analyze.

        Returns:
            Efficiency analysis as a markdown string.
        """
        analysis = "## âš¡ æ•ˆç‡æ€§èƒ½åˆ†æ\n\n"

        if "æ•°æ®æº" in data.columns:
            source_counts = data["æ•°æ®æº"].value_counts()
            fig = self._create_plotly_chart(
                px.bar,
                x=source_counts.index,
                y=source_counts.values,
                title="å„æ•°æ®æºè®°å½•åˆ†å¸ƒ",
                labels={"x": "æ•°æ®æº", "y": "è®°å½•æ•°"},
                color=source_counts.values,
                color_continuous_scale="viridis",
                height=400,
            )
            st.plotly_chart(fig, use_container_width=True)

            analysis += "### æ•°æ®æºæ•ˆç‡åˆ†æ\n"
            analysis += f"- æ€»è®°å½•æ•°: {len(data)}\n"
            analysis += f"- æ•°æ®æºåˆ†å¸ƒ: {', '.join([f'{k}({v})' for k, v in source_counts.items()])}\n"
            for source, count in source_counts.items():
                percentage = (count / len(data)) * 100
                analysis += f"- {source}: {count} æ¡è®°å½• ({percentage:.1f}%)\n"

        elif "æ—¶é•¿" in data.columns:
            duration_stats = data["æ—¶é•¿"].describe()
            fig = self._create_plotly_chart(
                px.histogram,
                data,
                x="æ—¶é•¿",
                title="ä¼šè®®æ—¶é•¿åˆ†å¸ƒ",
                nbins=20,
                color_discrete_sequence=["#1f77b4"],
                height=400,
            )
            st.plotly_chart(fig, use_container_width=True)

            analysis += "### ä¼šè®®æ—¶é•¿æ•ˆç‡åˆ†æ\n"
            analysis += f"- å¹³å‡æ—¶é•¿: {duration_stats['mean']:.1f} åˆ†é’Ÿ\n"
            analysis += f"- æœ€çŸ­æ—¶é•¿: {duration_stats['min']:.1f} åˆ†é’Ÿ\n"
            analysis += f"- æœ€é•¿æ—¶é•¿: {duration_stats['max']:.1f} åˆ†é’Ÿ\n"
            analysis += f"- æ—¶é•¿æ ‡å‡†å·®: {duration_stats['std']:.1f} åˆ†é’Ÿ\n"
            analysis += "- **æ•ˆç‡å»ºè®®**: " + (
                "å¹³å‡ä¼šè®®æ—¶é•¿è¾ƒé•¿ï¼Œå»ºè®®ä¼˜åŒ–ä¼šè®®æµç¨‹\n"
                if duration_stats["mean"] > 60
                else "ä¼šè®®æ—¶é•¿åˆç†ï¼Œæ•ˆç‡è‰¯å¥½\n"
            )

        elif "çŠ¶æ€" in data.columns:
            status_counts = data["çŠ¶æ€"].value_counts()
            fig = self._create_plotly_chart(
                px.pie,
                values=status_counts.values,
                names=status_counts.index,
                title="ä»»åŠ¡çŠ¶æ€åˆ†å¸ƒ",
                color_discrete_sequence=px.colors.qualitative.Set3,
                height=400,
            )
            st.plotly_chart(fig, use_container_width=True)

            total_tasks = len(data)
            completed_tasks = status_counts.get("å®Œæˆ", 0)
            completion_rate = (
                (completed_tasks / total_tasks) * 100 if total_tasks > 0 else 0
            )
            analysis += "### ä»»åŠ¡å®Œæˆæ•ˆç‡åˆ†æ\n"
            analysis += f"- æ€»ä»»åŠ¡æ•°: {total_tasks}\n"
            analysis += f"- å·²å®Œæˆä»»åŠ¡: {completed_tasks}\n"
            analysis += f"- å®Œæˆç‡: {completion_rate:.1f}%\n"
            analysis += "- **æ•ˆç‡è¯„ä¼°**: " + (
                "ä»»åŠ¡å®Œæˆç‡ä¼˜ç§€\n"
                if completion_rate >= 80
                else (
                    "ä»»åŠ¡å®Œæˆç‡è‰¯å¥½\n"
                    if completion_rate >= 60
                    else "ä»»åŠ¡å®Œæˆç‡éœ€è¦æ”¹è¿›\n"
                )
            )

        return analysis

    def _generate_general_analysis(self, data: pd.DataFrame, query: str) -> str:
        """Generate general analysis based on query.

        Args:
            data: DataFrame to analyze.
            query: User query for analysis.

        Returns:
            General analysis as a markdown string.
        """
        analysis = f"### ğŸ¤– AI åˆ†æç»“æœ\n\né’ˆå¯¹æŸ¥è¯¢: **{query}**\n\n"
        analysis += "### æ•°æ®æ´å¯Ÿ\n"
        analysis += f"- æ•°æ®é›†åŒ…å« {len(data)} æ¡è®°å½•\n"
        analysis += f"- æ¶µç›– {len(data.columns)} ä¸ªå­—æ®µ\n"

        numeric_cols = data.select_dtypes(include=["number"]).columns
        if numeric_cols.any():
            analysis += f"- åŒ…å« {len(numeric_cols)} ä¸ªæ•°å€¼å‹å­—æ®µ\n"
            st.markdown("#### ğŸ“Š æ•°å€¼å­—æ®µåˆ†å¸ƒ")
            for col in numeric_cols[:2]:
                fig = self._create_plotly_chart(
                    px.histogram, data, x=col, title=f"{col} åˆ†å¸ƒ", nbins=20
                )
                st.plotly_chart(fig, use_container_width=True)

        categorical_cols = data.select_dtypes(include=["object"]).columns
        if categorical_cols.any():
            analysis += f"- åŒ…å« {len(categorical_cols)} ä¸ªåˆ†ç±»å‹å­—æ®µ\n"
            st.markdown("#### ğŸ“ˆ åˆ†ç±»å­—æ®µåˆ†å¸ƒ")
            for col in categorical_cols[:2]:
                value_counts = data[col].value_counts()
                fig = self._create_plotly_chart(
                    px.bar,
                    x=value_counts.index,
                    y=value_counts.values,
                    title=f"{col} åˆ†å¸ƒ",
                    labels={"x": col, "y": "æ•°é‡"},
                    color=value_counts.values,
                    color_continuous_scale="viridis",
                )
                st.plotly_chart(fig, use_container_width=True)

        analysis += "\n### å»ºè®®\n"
        analysis += "- å°è¯•æ›´å…·ä½“çš„æŸ¥è¯¢ï¼Œå¦‚'æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯'æˆ–'ç”Ÿæˆå›¾è¡¨'\n"
        analysis += "- ä½¿ç”¨å†…ç½®æŸ¥è¯¢è·å–å¸¸ç”¨åˆ†æç»“æœ\n"

        return analysis

    def show(self) -> None:
        """Display the main analysis page."""
        self.ui.create_header(TEXTS["header"])
        llm = setup_pandasai_llm()

        if llm:
            st.success(TEXTS["ai_enabled"])
        else:
            st.error(TEXTS["ai_init_failed"])
            return

        data_sources = ["ä¼šè®®æ•°æ®", "ä»»åŠ¡æ•°æ®", "ç”¨æˆ·æ•°æ®", "ä¼šè®®å®¤æ•°æ®", "å…¨éƒ¨æ•°æ®"]
        selected_source = st.selectbox("é€‰æ‹©æ•°æ®æº", data_sources, index=0)

        sample_data = self._get_selected_data(selected_source)
        if sample_data.empty:
            st.info(TEXTS["no_data"])
            return

        self._show_data_overview(sample_data)
        self._show_data_preview(sample_data)
        self._show_analysis_interface(sample_data, llm, selected_source)

    def _get_selected_data(self, selected_source: str) -> pd.DataFrame:
        """Get data based on selected source.

        Args:
            selected_source: Selected data source name.

        Returns:
            DataFrame containing the selected data.
        """
        data_mapping = {
            "å…¨éƒ¨æ•°æ®": self._get_merged_data,
            "ä¼šè®®æ•°æ®": lambda: self.data_manager.get_dataframe("meetings"),
            "ä»»åŠ¡æ•°æ®": lambda: self.data_manager.get_dataframe("tasks"),
            "ç”¨æˆ·æ•°æ®": lambda: self.data_manager.get_dataframe("users"),
            "ä¼šè®®å®¤æ•°æ®": lambda: self.data_manager.get_dataframe("rooms"),
        }
        return data_mapping.get(selected_source, lambda: pd.DataFrame())()

    def _get_merged_data(self) -> pd.DataFrame:
        """Get merged dataset from all sources.

        Returns:
            Merged DataFrame.
        """
        meetings_df = self.data_manager.get_dataframe("meetings")
        tasks_df = self.data_manager.get_dataframe("tasks")
        users_df = self.data_manager.get_dataframe("users")
        rooms_df = self.data_manager.get_dataframe("rooms")
        return self._create_merged_dataset(meetings_df, tasks_df, users_df, rooms_df)

    def _show_data_overview(self, sample_data: pd.DataFrame) -> None:
        """Display data overview.

        Args:
            sample_data: DataFrame to display overview for.
        """
        st.markdown(TEXTS["data_overview"])
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("æ€»è®°å½•æ•°", len(sample_data))
        with col2:
            st.metric("å­—æ®µæ•°", len(sample_data.columns))
        with col3:
            st.metric(
                "æ•°å€¼å­—æ®µ", len(sample_data.select_dtypes(include=["number"]).columns)
            )
        with col4:
            st.metric(
                "åˆ†ç±»å­—æ®µ", len(sample_data.select_dtypes(include=["object"]).columns)
            )

        st.markdown("---")

    def _show_data_preview(self, sample_data: pd.DataFrame) -> None:
        """Display data preview.

        Args:
            sample_data: DataFrame to display preview for.
        """
        st.markdown(TEXTS["data_preview"])
        with st.expander("æŸ¥çœ‹æ•°æ®è¯¦æƒ…", expanded=True):
            st.dataframe(sample_data.head(8), use_container_width=True)
        st.markdown("---")

    def _show_analysis_interface(
        self, sample_data: pd.DataFrame, llm: Any, selected_source: str
    ) -> None:
        """Display analysis query interface.

        Args:
            sample_data: DataFrame to analyze.
            llm: Initialized LLM instance.
            selected_source: Selected data source.
        """
        st.markdown(TEXTS["analysis_query"])
        query = self._get_user_query(selected_source)

        if st.button(TEXTS["start_analysis"], type="primary", use_container_width=True):
            self._execute_analysis(query, sample_data, llm)

    def _get_user_query(self, selected_source: str) -> str:
        """Get user query from built-in or custom input.

        Args:
            selected_source: Selected data source.

        Returns:
            User query string.
        """
        built_in_queries = self._get_built_in_queries(selected_source)
        col1, col2 = st.columns([1, 1])

        with col1:
            st.markdown(TEXTS["built_in_query"])
            selected_built_in = st.selectbox(
                TEXTS["select_query"],
                [TEXTS["select_query"]] + list(built_in_queries.keys()),
                help=TEXTS["query_help"],
            )
            query = (
                built_in_queries.get(selected_built_in, "")
                if selected_built_in != TEXTS["select_query"]
                else ""
            )
            if query:
                st.markdown(f"**æŸ¥è¯¢å†…å®¹ï¼š** {query}")

        with col2:
            st.markdown(TEXTS["custom_query"])
            custom_query = st.text_area(
                TEXTS["custom_query"],
                placeholder=TEXTS["query_placeholder"],
                height=100,
                help=TEXTS["query_help"],
            )
            if custom_query:
                query = custom_query

        return query

    def _execute_analysis(
        self, query: str, sample_data: pd.DataFrame, llm: Any
    ) -> None:
        """Execute analysis with progress indicators.

        Args:
            query: User query for analysis.
            sample_data: DataFrame to analyze.
            llm: Initialized LLM instance.
        """
        if not query:
            st.warning(TEXTS["no_query"])
            return

        if st.session_state.analysis_running:
            st.warning(TEXTS["analysis_running"])
            return

        st.session_state.analysis_running = True
        progress_bar = st.progress(0)
        status_text = st.empty()

        try:
            status_text.text(TEXTS["ai_analyzing"])
            progress_bar.progress(25)

            if llm:
                status_text.text(TEXTS["ai_executing"])
                progress_bar.progress(50)
                analysis_result = self.perform_ai_analysis(query, sample_data, llm)
                progress_bar.progress(75)
                status_text.text(TEXTS["generating_visuals"])

                if analysis_result:
                    progress_bar.progress(100)
                    status_text.text(TEXTS["analysis_complete"])
                    progress_bar.empty()
                    status_text.empty()
                    st.success(TEXTS["analysis_complete"])
                    self._display_analysis_results(analysis_result, sample_data, query)
                else:
                    progress_bar.empty()
                    status_text.empty()
                    st.error(TEXTS["analysis_failed"])
            else:
                progress_bar.empty()
                status_text.empty()
                st.error(TEXTS["ai_not_initialized"])
        except Exception as e:
            progress_bar.empty()
            status_text.empty()
            st.error(TEXTS["error_occurred"].format(error=str(e)))
        finally:
            st.session_state.analysis_running = False

    def _display_analysis_results(
        self, analysis_result: str, sample_data: pd.DataFrame, query: str
    ) -> None:
        """Display analysis results and appropriate visualizations.

        Args:
            analysis_result: Analysis result as a string.
            sample_data: DataFrame analyzed.
            query: User query.
        """
        st.markdown(analysis_result)
        self._show_appropriate_visualizations(sample_data, query)

    def _show_appropriate_visualizations(
        self, sample_data: pd.DataFrame, query: str
    ) -> None:
        """Display visualizations based on query type.

        Args:
            sample_data: DataFrame to visualize.
            query: User query.
        """
        query_lower = query.lower()
        visualization_mapping: Dict[str, Callable] = {
            "ç»Ÿè®¡": self._show_statistical_visualizations,
            "æ¦‚è§ˆ": self._show_statistical_visualizations,
            "åˆ†å¸ƒ": self._show_statistical_visualizations,
            "åˆ†æ": self._show_statistical_visualizations,
            "æ•ˆç‡": self._show_efficiency_visualizations,
            "æ€§èƒ½": self._show_efficiency_visualizations,
            "å®Œæˆç‡": self._show_efficiency_visualizations,
            "åˆ©ç”¨ç‡": self._show_efficiency_visualizations,
            "å…³è”": self._show_correlation_visualizations,
            "å…³ç³»": self._show_correlation_visualizations,
            "ç›¸å…³æ€§": self._show_correlation_visualizations,
            "å½±å“": self._show_correlation_visualizations,
            "è¶‹åŠ¿": self._show_temporal_visualizations,
            "æ—¶é—´": self._show_temporal_visualizations,
            "æ¨¡å¼": self._show_temporal_visualizations,
            "å˜åŒ–": self._show_temporal_visualizations,
            "å¯¹æ¯”": self._show_comparison_visualizations,
            "æ¯”è¾ƒ": self._show_comparison_visualizations,
            "å·®å¼‚": self._show_comparison_visualizations,
            "æ’å": self._show_comparison_visualizations,
        }

        executed_methods = set()
        chart_count = 0
        max_charts = 2

        for keyword, method in visualization_mapping.items():
            if (
                keyword in query_lower
                and method not in executed_methods
                and chart_count < max_charts
            ):
                method(sample_data, query)
                executed_methods.add(method)
                chart_count += 1

    def _show_statistical_visualizations(
        self, sample_data: pd.DataFrame, query: str
    ) -> None:
        """Display statistical visualizations.

        Args:
            sample_data: DataFrame to visualize.
            query: User query.
        """
        st.markdown("#### ğŸ“ˆ ç»Ÿè®¡å¯è§†åŒ–")
        numeric_cols = sample_data.select_dtypes(include=["number"]).columns
        categorical_cols = sample_data.select_dtypes(include=["object"]).columns

        if numeric_cols.any():
            self._create_plotly_chart(
                px.histogram,
                sample_data,
                x=numeric_cols[0],
                title=f"{numeric_cols[0]} åˆ†å¸ƒ",
                nbins=20,
                color_discrete_sequence=["#1f77b4"],
            )
            st.plotly_chart(st.session_state.last_chart, use_container_width=True)
        elif categorical_cols.any():
            value_counts = sample_data[categorical_cols[0]].value_counts()
            self._create_plotly_chart(
                px.bar,
                x=value_counts.index,
                y=value_counts.values,
                title=f"{categorical_cols[0]} åˆ†å¸ƒ",
                labels={"x": categorical_cols[0], "y": "æ•°é‡"},
                color=value_counts.values,
                color_continuous_scale="viridis",
            )
            st.plotly_chart(st.session_state.last_chart, use_container_width=True)

    def _show_efficiency_visualizations(
        self, sample_data: pd.DataFrame, query: str
    ) -> None:
        """Display efficiency visualizations.

        Args:
            sample_data: DataFrame to visualize.
            query: User query.
        """
        st.markdown("#### âš¡ æ•ˆç‡åˆ†æå¯è§†åŒ–")
        if "æ•°æ®æº" in sample_data.columns:
            self._show_data_source_efficiency(sample_data)
        elif "æ—¶é•¿" in sample_data.columns:
            self._show_duration_efficiency(sample_data)
        elif "çŠ¶æ€" in sample_data.columns:
            self._show_status_efficiency(sample_data)
        else:
            numeric_cols = sample_data.select_dtypes(include=["number"]).columns
            if numeric_cols.any():
                self._create_plotly_chart(
                    px.histogram,
                    sample_data,
                    x=numeric_cols[0],
                    title=f"{numeric_cols[0]} æ•ˆç‡åˆ†å¸ƒ",
                    nbins=20,
                )
                st.plotly_chart(st.session_state.last_chart, use_container_width=True)

    def _show_data_source_efficiency(self, sample_data: pd.DataFrame) -> None:
        """Display data source efficiency visualization.

        Args:
            sample_data: DataFrame containing data source information.
        """
        source_efficiency = sample_data["æ•°æ®æº"].value_counts()
        self._create_plotly_chart(
            px.pie,
            values=source_efficiency.values,
            names=source_efficiency.index,
            title="å„æ•°æ®æºè®°å½•åˆ†å¸ƒ",
            color_discrete_sequence=px.colors.qualitative.Set3,
        )
        st.plotly_chart(st.session_state.last_chart, use_container_width=True)

    def _show_duration_efficiency(self, sample_data: pd.DataFrame) -> None:
        """Display duration efficiency visualization and metrics.

        Args:
            sample_data: DataFrame containing duration information.
        """
        duration_stats = sample_data["æ—¶é•¿"].describe()
        efficiency_score = min(100, max(0, 100 - (duration_stats["mean"] - 30) * 2))
        col1, col2 = st.columns(2)

        with col1:
            st.metric("å¹³å‡æ—¶é•¿", f"{duration_stats['mean']:.1f} åˆ†é’Ÿ")
            st.metric("æ•ˆç‡è¯„åˆ†", f"{efficiency_score:.1f}/100")
        with col2:
            st.metric("æœ€çŸ­æ—¶é•¿", f"{duration_stats['min']:.1f} åˆ†é’Ÿ")
            st.metric("æœ€é•¿æ—¶é•¿", f"{duration_stats['max']:.1f} åˆ†é’Ÿ")

        self._create_plotly_chart(
            px.histogram,
            sample_data,
            x="æ—¶é•¿",
            title="ä¼šè®®æ—¶é•¿åˆ†å¸ƒ",
            nbins=20,
            color_discrete_sequence=["#1f77b4"],
        )
        st.plotly_chart(st.session_state.last_chart, use_container_width=True)

    def _show_status_efficiency(self, sample_data: pd.DataFrame) -> None:
        """Display status efficiency visualization and metrics.

        Args:
            sample_data: DataFrame containing status information.
        """
        status_counts = sample_data["çŠ¶æ€"].value_counts()
        completion_rate = (status_counts.get("å®Œæˆ", 0) / len(sample_data)) * 100
        col1, col2 = st.columns(2)

        with col1:
            st.metric("æ€»ä»»åŠ¡æ•°", len(sample_data))
            st.metric("å®Œæˆç‡", f"{completion_rate:.1f}%")
        with col2:
            st.metric("å·²å®Œæˆ", status_counts.get("å®Œæˆ", 0))
            st.metric("è¿›è¡Œä¸­", status_counts.get("è¿›è¡Œä¸­", 0))

        self._create_plotly_chart(
            px.pie,
            values=status_counts.values,
            names=status_counts.index,
            title="ä»»åŠ¡çŠ¶æ€åˆ†å¸ƒ",
            color_discrete_sequence=px.colors.qualitative.Set3,
        )
        st.plotly_chart(st.session_state.last_chart, use_container_width=True)

    def _show_correlation_visualizations(
        self, sample_data: pd.DataFrame, query: str
    ) -> None:
        """Display correlation visualizations.

        Args:
            sample_data: DataFrame to visualize.
            query: User query.
        """
        st.markdown("#### ğŸ”— å…³è”å…³ç³»å¯è§†åŒ–")
        numeric_cols = sample_data.select_dtypes(include=["number"]).columns

        if len(numeric_cols) >= 2:
            self._create_plotly_chart(
                px.imshow,
                sample_data[numeric_cols].corr(),
                title="æ•°å€¼å­—æ®µç›¸å…³æ€§çƒ­åŠ›å›¾",
                color_continuous_scale="RdBu",
                aspect="auto",
                height=500,
            )
            st.plotly_chart(st.session_state.last_chart, use_container_width=True)
        else:
            categorical_cols = sample_data.select_dtypes(include=["object"]).columns
            if categorical_cols.any():
                value_counts = sample_data[categorical_cols[0]].value_counts()
                self._create_plotly_chart(
                    px.bar,
                    x=value_counts.index,
                    y=value_counts.values,
                    title=f"{categorical_cols[0]} åˆ†å¸ƒ",
                    labels={"x": categorical_cols[0], "y": "æ•°é‡"},
                )
                st.plotly_chart(st.session_state.last_chart, use_container_width=True)

    def _show_temporal_visualizations(
        self, sample_data: pd.DataFrame, query: str
    ) -> None:
        """Display temporal visualizations.

        Args:
            sample_data: DataFrame to visualize.
            query: User query.
        """
        st.markdown("#### ğŸ“… æ—¶é—´æ¨¡å¼å¯è§†åŒ–")
        time_cols = self._find_time_columns(sample_data)

        if time_cols:
            self._create_time_series_chart(sample_data, time_cols[0])
        else:
            numeric_cols = sample_data.select_dtypes(include=["number"]).columns
            if numeric_cols.any():
                self._create_plotly_chart(
                    px.histogram,
                    sample_data,
                    x=numeric_cols[0],
                    title=f"{numeric_cols[0]} åˆ†å¸ƒ",
                    nbins=20,
                )
                st.plotly_chart(st.session_state.last_chart, use_container_width=True)

    def _find_time_columns(self, data: pd.DataFrame) -> list:
        """Find time-related columns in the DataFrame.

        Args:
            data: DataFrame to analyze.

        Returns:
            List of column names that are time-related.
        """
        time_cols = []
        for col in data.columns:
            try:
                if (
                    pd.api.types.is_datetime64_any_dtype(data[col])
                    or pd.to_datetime(data[col], errors="coerce").notna().sum()
                    > len(data) * 0.5
                ):
                    time_cols.append(col)
            except Exception:
                continue
        return time_cols

    def _create_time_series_chart(self, data: pd.DataFrame, column: str) -> None:
        """Create a time series chart.

        Args:
            data: DataFrame containing the time column.
            column: Name of the time column.
        """
        try:
            time_data = pd.to_datetime(data[column], errors="coerce")
            if not time_data.isna().all():
                time_counts = time_data.dt.date.value_counts().sort_index()
                self._create_plotly_chart(
                    px.line,
                    x=time_counts.index,
                    y=time_counts.values,
                    title=f"{column} æ—¶é—´è¶‹åŠ¿",
                    labels={"x": "æ—¥æœŸ", "y": "æ•°é‡"},
                )
                st.plotly_chart(st.session_state.last_chart, use_container_width=True)
        except Exception as e:
            st.warning(f"æ— æ³•å¤„ç†æ—¶é—´å­—æ®µ {column}: {e}")

    def _show_comparison_visualizations(
        self, sample_data: pd.DataFrame, query: str
    ) -> None:
        """Display comparison visualizations.

        Args:
            sample_data: DataFrame to visualize.
            query: User query.
        """
        st.markdown("#### ğŸ“Š å¯¹æ¯”åˆ†æå¯è§†åŒ–")
        categorical_cols = sample_data.select_dtypes(include=["object"]).columns
        numeric_cols = sample_data.select_dtypes(include=["number"]).columns

        if categorical_cols.any() and numeric_cols.any():
            self._create_plotly_chart(
                px.box,
                sample_data,
                x=categorical_cols[0],
                y=numeric_cols[0],
                title=f"{categorical_cols[0]} vs {numeric_cols[0]} å¯¹æ¯”",
            )
            st.plotly_chart(st.session_state.last_chart, use_container_width=True)
        else:
            if categorical_cols.any():
                value_counts = sample_data[categorical_cols[0]].value_counts()
                self._create_plotly_chart(
                    px.bar,
                    x=value_counts.index,
                    y=value_counts.values,
                    title=f"{categorical_cols[0]} åˆ†å¸ƒ",
                    labels={"x": categorical_cols[0], "y": "æ•°é‡"},
                )
                st.plotly_chart(st.session_state.last_chart, use_container_width=True)
            elif numeric_cols.any():
                self._create_plotly_chart(
                    px.histogram,
                    sample_data,
                    x=numeric_cols[0],
                    title=f"{numeric_cols[0]} åˆ†å¸ƒ",
                    nbins=20,
                )
                st.plotly_chart(st.session_state.last_chart, use_container_width=True)

    def _create_plotly_chart(self, chart_func: Callable, *args, **kwargs) -> None:
        """Create a Plotly chart with consistent styling and store in session state.

        Args:
            chart_func: Plotly Express chart function (e.g., px.bar, px.histogram).
            *args: Positional arguments for the chart function.
            **kwargs: Keyword arguments for the chart function, including title and other configurations.
        """
        try:
            kwargs.setdefault("height", 400)
            fig = chart_func(*args, **kwargs)
            fig.update_layout(
                margin=dict(l=20, r=20, t=50, b=20),
                showlegend=True,
                font=dict(size=12),
                title_x=0.5,
            )
            st.session_state.last_chart = fig
        except Exception as e:
            logger.error(f"Failed to create Plotly chart: {e}")
            st.warning(f"åˆ›å»ºå›¾è¡¨å¤±è´¥: {e}")

    def _handle_enhanced_pandasai_response(
        self, response: Any, sample_data: pd.DataFrame, query: str
    ) -> bool:
        """Enhanced handler for PandasAI response with better Plotly chart detection and display.

        Args:
            response: PandasAI response object.
            sample_data: DataFrame analyzed.
            query: User query.

        Returns:
            Boolean indicating if charts were displayed.
        """
        try:
            charts_found = False
            
            # Clear previous charts
            st.session_state.last_charts = []
            
            # Handle different response types
            if isinstance(response, (go.Figure, dict)):
                if isinstance(response, dict) and "data" in response:
                    fig = go.Figure(response)
                    self._display_plotly_chart(fig, "AIç”Ÿæˆå›¾è¡¨")
                    charts_found = True
                elif isinstance(response, go.Figure):
                    self._display_plotly_chart(response, "AIç”Ÿæˆå›¾è¡¨")
                    charts_found = True
                    
            elif isinstance(response, (list, tuple)):
                for item in response:
                    if isinstance(item, go.Figure):
                        self._display_plotly_chart(item, "AIç”Ÿæˆå›¾è¡¨")
                        charts_found = True
                    elif isinstance(item, dict) and "data" in item:
                        fig = go.Figure(item)
                        self._display_plotly_chart(fig, "AIç”Ÿæˆå›¾è¡¨")
                        charts_found = True
                        
            # Try to extract charts from string response
            if not charts_found and isinstance(response, str):
                charts_found = self._extract_charts_from_string(response, sample_data, query)
                
            if charts_found:
                st.success(TEXTS["plotly_chart_created"])
                
            return charts_found
            
        except Exception as e:
            logger.warning(f"Failed to handle enhanced PandasAI response: {e}")
            st.warning(f"å¤„ç†AIå“åº”å¤±è´¥: {e}")
            return False

    def _extract_charts_from_string(self, response_str: str, sample_data: pd.DataFrame, query: str) -> bool:
        """Extract and create charts from string response containing chart code.

        Args:
            response_str: String response that may contain chart code.
            sample_data: DataFrame to use for chart creation.
            query: User query.

        Returns:
            Boolean indicating if charts were created.
        """
        try:
            # Look for plotly code patterns in the response
            plotly_patterns = [
                r'px\.(bar|line|scatter|histogram|box|violin|pie|area|heatmap)\([^)]+\)',
                r'go\.(Figure|Scatter|Bar|Histogram|Box|Violin|Pie|Heatmap)\([^)]+\)',
                r'fig\s*=\s*(px|go)\.[^)]+\)'
            ]
            
            for pattern in plotly_patterns:
                if re.search(pattern, response_str):
                    # Create fallback chart based on query content
                    return self._create_smart_fallback_chart(sample_data, query)
                    
            return False
            
        except Exception as e:
            logger.warning(f"Failed to extract charts from string: {e}")
            return False

    def _handle_pandasai_response(
        self, response: Any, sample_data: pd.DataFrame, query: str
    ) -> bool:
        """Handle PandasAI response and attempt to display charts.

        Args:
            response: PandasAI response object.
            sample_data: DataFrame analyzed.
            query: User query.

        Returns:
            Boolean indicating if charts were displayed.
        """
        try:
            if isinstance(response, (go.Figure, dict)) and "data" in response:
                st.plotly_chart(response, use_container_width=True)
                return True
            elif (
                isinstance(response, (list, tuple))
                and len(response) > 0
                and isinstance(response[0], go.Figure)
            ):
                st.plotly_chart(response[0], use_container_width=True)
                return True
            else:
                st.info("æœªæ£€æµ‹åˆ°å›¾è¡¨ä¿¡æ¯ï¼Œåˆ›å»ºåŸºç¡€å¯è§†åŒ–")
                self._create_enhanced_fallback_charts(sample_data, query)
                return True
        except Exception as e:
            logger.warning(f"Failed to handle PandasAI response: {e}")
            st.warning(f"å¤„ç†PandasAIå“åº”å¤±è´¥: {e}")
            self._create_enhanced_fallback_charts(sample_data, query)
            return True

    def _create_enhanced_fallback_charts(self, sample_data: pd.DataFrame, query: str) -> None:
        """Create enhanced fallback charts with better error handling.

        Args:
            sample_data: DataFrame to visualize.
            query: User query.
        """
        try:
            st.info(TEXTS["fallback_info"])
            
            if self._create_smart_fallback_chart(sample_data, query):
                st.success("å·²ç”Ÿæˆå¤‡ç”¨å¯è§†åŒ–å›¾è¡¨")
            else:
                st.warning(TEXTS["no_visualizable_cols"])
                
        except Exception as e:
            logger.error(f"Failed to create enhanced fallback charts: {e}")
            st.warning(f"åˆ›å»ºå¤‡ç”¨å›¾è¡¨å¤±è´¥: {e}")

    def _create_fallback_charts(self, sample_data: pd.DataFrame, query: str) -> None:
        """Create fallback charts when AI analysis fails (legacy method for backward compatibility).

        Args:
            sample_data: DataFrame to visualize.
            query: User query.
        """
        self._create_enhanced_fallback_charts(sample_data, query)

    def _create_smart_fallback_chart(self, sample_data: pd.DataFrame, query: str) -> bool:
        """Create intelligent fallback charts based on query content and data structure.

        Args:
            sample_data: DataFrame to visualize.
            query: User query.

        Returns:
            Boolean indicating if charts were created.
        """
        try:
            query_lower = query.lower()
            numeric_cols = sample_data.select_dtypes(include=["number"]).columns.tolist()
            categorical_cols = sample_data.select_dtypes(include=["object"]).columns.tolist()
            
            charts_created = False
            
            # Duration analysis
            if any(keyword in query_lower for keyword in ["æ—¶é•¿", "duration", "æ—¶é—´", "time"]):
                duration_cols = [col for col in sample_data.columns if any(word in col.lower() for word in ["æ—¶é•¿", "duration", "æ—¶é—´", "time"])]
                if duration_cols:
                    self._create_duration_chart(sample_data, duration_cols[0])
                    charts_created = True
                elif numeric_cols:
                    self._create_duration_chart(sample_data, numeric_cols[0])
                    charts_created = True
                    
            # Status analysis
            elif any(keyword in query_lower for keyword in ["çŠ¶æ€", "status", "å®Œæˆ", "complete"]):
                status_cols = [col for col in sample_data.columns if any(word in col.lower() for word in ["çŠ¶æ€", "status", "å®Œæˆ", "complete"])]
                if status_cols:
                    self._create_status_chart(sample_data, status_cols[0])
                    charts_created = True
                elif categorical_cols:
                    self._create_status_chart(sample_data, categorical_cols[0])
                    charts_created = True
                    
            # Distribution analysis
            elif any(keyword in query_lower for keyword in ["åˆ†å¸ƒ", "distribution", "ç»Ÿè®¡", "statistics"]):
                if numeric_cols:
                    self._create_distribution_chart(sample_data, numeric_cols[0])
                    charts_created = True
                elif categorical_cols:
                    self._create_distribution_chart(sample_data, categorical_cols[0])
                    charts_created = True
                    
            # Trend analysis
            elif any(keyword in query_lower for keyword in ["è¶‹åŠ¿", "trend", "å˜åŒ–", "change"]):
                time_cols = self._find_time_columns(sample_data)
                if time_cols:
                    self._create_trend_chart(sample_data, time_cols[0])
                    charts_created = True
                    
            # Default chart
            if not charts_created:
                if numeric_cols:
                    self._create_distribution_chart(sample_data, numeric_cols[0])
                    charts_created = True
                elif categorical_cols:
                    self._create_distribution_chart(sample_data, categorical_cols[0])
                    charts_created = True
                    
            return charts_created
            
        except Exception as e:
            logger.error(f"Failed to create smart fallback chart: {e}")
            return False

    def _create_duration_chart(self, data: pd.DataFrame, column: str) -> None:
        """Create duration analysis chart.

        Args:
            data: DataFrame containing the data.
            column: Column name for duration data.
        """
        try:
            fig = px.histogram(
                data, 
                x=column, 
                title=f"{column}åˆ†å¸ƒåˆ†æ",
                labels={column: f"{column}ï¼ˆåˆ†é’Ÿï¼‰", "count": "é¢‘æ¬¡"},
                nbins=20,
                color_discrete_sequence=["#1f77b4"]
            )
            fig.update_layout(
                title_x=0.5,
                font=dict(size=12),
                showlegend=True,
                height=400
            )
            self._display_plotly_chart(fig, f"{column}åˆ†å¸ƒ")
        except Exception as e:
            logger.error(f"Failed to create duration chart: {e}")

    def _create_status_chart(self, data: pd.DataFrame, column: str) -> None:
        """Create status analysis chart.

        Args:
            data: DataFrame containing the data.
            column: Column name for status data.
        """
        try:
            status_counts = data[column].value_counts()
            fig = px.pie(
                values=status_counts.values,
                names=status_counts.index,
                title=f"{column}åˆ†å¸ƒåˆ†æ",
                color_discrete_sequence=px.colors.qualitative.Set3
            )
            fig.update_layout(
                title_x=0.5,
                font=dict(size=12),
                height=400
            )
            self._display_plotly_chart(fig, f"{column}åˆ†å¸ƒ")
        except Exception as e:
            logger.error(f"Failed to create status chart: {e}")

    def _create_distribution_chart(self, data: pd.DataFrame, column: str) -> None:
        """Create distribution analysis chart.

        Args:
            data: DataFrame containing the data.
            column: Column name for the data to analyze.
        """
        try:
            if data[column].dtype in ['int64', 'float64']:
                fig = px.histogram(
                    data, 
                    x=column, 
                    title=f"{column}åˆ†å¸ƒåˆ†æ",
                    nbins=20,
                    color_discrete_sequence=["#1f77b4"]
                )
            else:
                value_counts = data[column].value_counts()
                fig = px.bar(
                    x=value_counts.index,
                    y=value_counts.values,
                    title=f"{column}åˆ†å¸ƒåˆ†æ",
                    labels={"x": column, "y": "æ•°é‡"},
                    color_discrete_sequence=["#1f77b4"]
                )
            
            fig.update_layout(
                title_x=0.5,
                font=dict(size=12),
                showlegend=True,
                height=400
            )
            self._display_plotly_chart(fig, f"{column}åˆ†å¸ƒ")
        except Exception as e:
            logger.error(f"Failed to create distribution chart: {e}")

    def _create_trend_chart(self, data: pd.DataFrame, column: str) -> None:
        """Create trend analysis chart.

        Args:
            data: DataFrame containing the data.
            column: Column name for time data.
        """
        try:
            # Try to convert to datetime if possible
            try:
                data[column] = pd.to_datetime(data[column], errors='coerce')
                data_filtered = data.dropna(subset=[column])
                
                if not data_filtered.empty:
                    # Group by date and count
                    daily_counts = data_filtered.groupby(data_filtered[column].dt.date).size().reset_index()
                    daily_counts.columns = ['date', 'count']
                    
                    fig = px.line(
                        daily_counts,
                        x='date',
                        y='count',
                        title=f"{column}è¶‹åŠ¿åˆ†æ",
                        labels={"date": "æ—¥æœŸ", "count": "æ•°é‡"},
                        color_discrete_sequence=["#1f77b4"]
                    )
                    fig.update_layout(
                        title_x=0.5,
                        font=dict(size=12),
                        showlegend=True,
                        height=400
                    )
                    self._display_plotly_chart(fig, f"{column}è¶‹åŠ¿")
                    return
            except:
                pass
                
            # Fallback to simple count
            value_counts = data[column].value_counts().head(10)
            fig = px.bar(
                x=value_counts.index,
                y=value_counts.values,
                title=f"{column}åˆ†å¸ƒåˆ†æ",
                labels={"x": column, "y": "æ•°é‡"},
                color_discrete_sequence=["#1f77b4"]
            )
            fig.update_layout(
                title_x=0.5,
                font=dict(size=12),
                showlegend=True,
                height=400
            )
            self._display_plotly_chart(fig, f"{column}åˆ†å¸ƒ")
            
        except Exception as e:
            logger.error(f"Failed to create trend chart: {e}")

    def _display_plotly_chart(self, fig: go.Figure, title: str) -> None:
        """Display a Plotly chart with consistent styling.

        Args:
            fig: Plotly figure object.
            title: Chart title.
        """
        try:
            # Ensure consistent styling
            fig.update_layout(
                margin=dict(l=20, r=20, t=50, b=20),
                showlegend=True,
                font=dict(size=12),
                title_x=0.5,
                height=400
            )
            
            # Store in session state
            st.session_state.last_charts.append(fig)
            
            # Display the chart
            st.plotly_chart(fig, use_container_width=True)
            
        except Exception as e:
            logger.error(f"Failed to display Plotly chart: {e}")
            st.warning(f"æ˜¾ç¤ºå›¾è¡¨å¤±è´¥: {e}")

    def _extract_text_analysis(self, response: Any) -> str:
        """Extract text analysis from PandasAI response.

        Args:
            response: PandasAI response object.

        Returns:
            Extracted text analysis.
        """
        try:
            if isinstance(response, str):
                return response
            elif hasattr(response, '__str__'):
                return str(response)
            else:
                return "AIåˆ†æå®Œæˆï¼Œè¯·æŸ¥çœ‹ä¸Šæ–¹ç”Ÿæˆçš„å›¾è¡¨ã€‚"
        except Exception as e:
            logger.error(f"Failed to extract text analysis: {e}")
            return "AIåˆ†æå®Œæˆï¼Œè¯·æŸ¥çœ‹ä¸Šæ–¹ç”Ÿæˆçš„å›¾è¡¨ã€‚"

    def _create_merged_dataset(
        self,
        meetings_df: pd.DataFrame,
        tasks_df: pd.DataFrame,
        users_df: pd.DataFrame,
        rooms_df: pd.DataFrame,
    ) -> pd.DataFrame:
        """Create a merged dataset from all data sources with standardized data types.

        Args:
            meetings_df: Meetings DataFrame.
            tasks_df: Tasks DataFrame.
            users_df: Users DataFrame.
            rooms_df: Rooms DataFrame.

        Returns:
            Merged DataFrame with standardized columns.
        """
        merged_data = []
        default_values = {
            "æ•°æ®æº": str,
            "è®°å½•ID": str,
            "æ ‡é¢˜": str,
            "æ—¶é•¿": float,
            "çŠ¶æ€": str,
            "åˆ›å»ºæ—¶é—´": str,
            "ä¼šè®®å®¤": str,
            "ç»„ç»‡è€…": str,
            "ç±»å‹": str,
            "ä¼˜å…ˆçº§": str,
            "æˆªæ­¢æ—¥æœŸ": str,
            "è´Ÿè´£äºº": str,
            "éƒ¨é—¨": str,
            "ç”¨æˆ·å": str,
            "å§“å": str,
            "è§’è‰²": str,
            "é‚®ç®±": str,
            "åç§°": str,
            "å®¹é‡": float,
        }

        def safe_get(row, key, default=""):
            value = row.get(key, default)
            return str(value) if value is not None else default

        if not meetings_df.empty:
            for _, meeting in meetings_df.iterrows():
                merged_data.append(
                    {
                        "æ•°æ®æº": "ä¼šè®®",
                        "è®°å½•ID": safe_get(meeting, "id"),
                        "æ ‡é¢˜": safe_get(meeting, "title"),
                        "æ—¶é•¿": float(meeting.get("duration", 0)),
                        "çŠ¶æ€": safe_get(meeting, "status"),
                        "åˆ›å»ºæ—¶é—´": safe_get(meeting, "created_datetime"),
                        "ä¼šè®®å®¤": safe_get(meeting, "room_id"),
                        "ç»„ç»‡è€…": safe_get(meeting, "organizer_id"),
                        "ç±»å‹": "ä¼šè®®è®°å½•",
                    }
                )

        if not tasks_df.empty:
            for _, task in tasks_df.iterrows():
                merged_data.append(
                    {
                        "æ•°æ®æº": "ä»»åŠ¡",
                        "è®°å½•ID": safe_get(task, "id"),
                        "æ ‡é¢˜": safe_get(task, "title"),
                        "ä¼˜å…ˆçº§": safe_get(task, "priority"),
                        "çŠ¶æ€": safe_get(task, "status"),
                        "åˆ›å»ºæ—¶é—´": safe_get(task, "created_datetime"),
                        "æˆªæ­¢æ—¥æœŸ": safe_get(task, "deadline"),
                        "è´Ÿè´£äºº": safe_get(task, "assignee_id"),
                        "éƒ¨é—¨": safe_get(task, "department"),
                        "ç±»å‹": "ä»»åŠ¡è®°å½•",
                    }
                )

        if not users_df.empty:
            for _, user in users_df.iterrows():
                merged_data.append(
                    {
                        "æ•°æ®æº": "ç”¨æˆ·",
                        "è®°å½•ID": safe_get(user, "id"),
                        "ç”¨æˆ·å": safe_get(user, "username"),
                        "å§“å": safe_get(user, "name"),
                        "éƒ¨é—¨": safe_get(user, "department"),
                        "è§’è‰²": safe_get(user, "role"),
                        "é‚®ç®±": safe_get(user, "email"),
                        "ç±»å‹": "ç”¨æˆ·è®°å½•",
                    }
                )

        if not rooms_df.empty:
            for _, room in rooms_df.iterrows():
                merged_data.append(
                    {
                        "æ•°æ®æº": "ä¼šè®®å®¤",
                        "è®°å½•ID": safe_get(room, "id"),
                        "åç§°": safe_get(room, "name"),
                        "å®¹é‡": float(room.get("capacity", 0)),
                        "çŠ¶æ€": safe_get(room, "status"),
                        "ç±»å‹": "ä¼šè®®å®¤è®°å½•",
                    }
                )

        df = pd.DataFrame(merged_data)
        for col, dtype in default_values.items():
            if col in df.columns:
                df[col] = df[col].astype(dtype)
        return df

    def _get_built_in_queries(self, data_source: str) -> Dict[str, str]:
        """Return built-in query options based on data source.

        Args:
            data_source: Selected data source.

        Returns:
            Dictionary of built-in query options.
        """
        queries = {}
        if data_source == "å…¨éƒ¨æ•°æ®":
            queries = {
                "è·¨æ•°æ®æºç»¼åˆåˆ†æ": "åˆ†ææ‰€æœ‰æ•°æ®æºçš„æ•´ä½“æƒ…å†µï¼ŒåŒ…æ‹¬å„æ•°æ®æºçš„è®°å½•æ•°é‡ã€åˆ†å¸ƒç‰¹å¾ï¼Œä»¥åŠæ•°æ®è´¨é‡è¯„ä¼°ã€‚ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨å±•ç¤ºæ•°æ®æºåˆ†å¸ƒå’Œå…³é”®æŒ‡æ ‡å¯¹æ¯”ã€‚",
                "ä¸šåŠ¡æ•ˆç‡æ·±åº¦åˆ†æ": "æ·±å…¥åˆ†æä¼šè®®æ—¶é•¿åˆ†å¸ƒã€ä»»åŠ¡å®Œæˆç‡ã€ç”¨æˆ·æ´»è·ƒåº¦ç­‰å…³é”®ä¸šåŠ¡æŒ‡æ ‡ã€‚è®¡ç®—æ•ˆç‡è¯„åˆ†ï¼Œè¯†åˆ«æ•ˆç‡ç“¶é¢ˆï¼Œå¹¶æä¾›ä¼˜åŒ–å»ºè®®ã€‚ç”Ÿæˆç›¸å…³å›¾è¡¨æ”¯æŒåˆ†æç»“æœã€‚",
                "æ•°æ®å…³è”æ€§æŒ–æ˜": "åˆ†æä¼šè®®ã€ä»»åŠ¡ã€ç”¨æˆ·ã€ä¼šè®®å®¤ä¹‹é—´çš„æ½œåœ¨å…³è”å…³ç³»ã€‚è¯†åˆ«æ•°æ®é—´çš„ä¾èµ–æ€§å’Œå½±å“å› å­ï¼Œå‘ç°ä¸šåŠ¡æ¨¡å¼ã€‚ä½¿ç”¨çƒ­åŠ›å›¾å’Œç½‘ç»œå›¾å±•ç¤ºå…³è”å¼ºåº¦ã€‚",
            }
        elif data_source == "ä¼šè®®æ•°æ®":
            queries = {
                "ä¼šè®®æ—¶é•¿åˆ†å¸ƒ": "åˆ†æä¼šè®®æ—¶é•¿çš„åˆ†å¸ƒæƒ…å†µï¼Œå±•ç¤ºä¸»è¦çš„æ—¶é•¿åŒºé—´ã€‚",
                "ä¼šè®®æ•°é‡è¶‹åŠ¿": "ç»Ÿè®¡æ¯æœˆçš„ä¼šè®®æ•°é‡å˜åŒ–è¶‹åŠ¿ã€‚",
                "ä¼šè®®å®¤ä½¿ç”¨ç»Ÿè®¡": "ç»Ÿè®¡å„ä¼šè®®å®¤çš„ä½¿ç”¨æ¬¡æ•°ã€‚",
            }
        elif data_source == "ä»»åŠ¡æ•°æ®":
            queries = {
                "ä»»åŠ¡å®Œæˆç‡ç»Ÿè®¡": "ç»Ÿè®¡ä»»åŠ¡çš„å®Œæˆæƒ…å†µï¼Œè®¡ç®—å®Œæˆç‡ã€‚",
                "ä»»åŠ¡ä¼˜å…ˆçº§åˆ†å¸ƒ": "åˆ†æä¸åŒä¼˜å…ˆçº§ä»»åŠ¡çš„åˆ†å¸ƒæƒ…å†µã€‚",
                "éƒ¨é—¨ä»»åŠ¡ç»Ÿè®¡": "ç»Ÿè®¡å„éƒ¨é—¨çš„ä»»åŠ¡åˆ†é…æƒ…å†µã€‚",
            }
        elif data_source == "ç”¨æˆ·æ•°æ®":
            queries = {
                "ç”¨æˆ·è§’è‰²åˆ†å¸ƒ": "åˆ†æç”¨æˆ·åœ¨ä¸åŒè§’è‰²çš„åˆ†å¸ƒæƒ…å†µã€‚",
                "éƒ¨é—¨äººå‘˜ç»Ÿè®¡": "ç»Ÿè®¡å„éƒ¨é—¨çš„äººå‘˜åˆ†å¸ƒæƒ…å†µã€‚",
                "ç”¨æˆ·æ´»è·ƒåº¦": "åˆ†æç”¨æˆ·çš„æ´»è·ƒç¨‹åº¦ã€‚",
            }
        elif data_source == "ä¼šè®®å®¤æ•°æ®":
            queries = {
                "ä¼šè®®å®¤å®¹é‡åˆ†å¸ƒ": "åˆ†æä¼šè®®å®¤å®¹é‡çš„åˆ†å¸ƒæƒ…å†µã€‚",
                "ä¼šè®®å®¤çŠ¶æ€ç»Ÿè®¡": "ç»Ÿè®¡ä¸åŒçŠ¶æ€ä¼šè®®å®¤çš„æ•°é‡ã€‚",
                "ä¼šè®®å®¤ä½¿ç”¨ç‡": "åˆ†æä¼šè®®å®¤çš„ä½¿ç”¨æ•ˆç‡ã€‚",
            }
        return queries
